---
lang: es
---

# Estudio de caso

```{r echo=FALSE, message=FALSE, warning=FALSE}
#setwd("C:/Users/chaca/Documents/Tesis/Quarto_archivos/Tesis/Tesis_escrita" )
library(scales)
library(later)
library(tidyverse)
library(scales)
library(stats)
library(ggplot2)
library(graphics)
library(plotly)

#library(webshot)
#library(htmlwidgets)
library(purrr)
library(rlang)
library(promises)
library(readxl)
library(readr)

library(tseries)
library(tswge)

library(datasets)
library(tswge)


datos_clima <- read_csv("C:/Users/chaca/Documents/Tesis/Quarto_archivos/Tesis/Tesis_escrita/datos_clima_wsu.csv", 
                        col_types = cols(`Date Time` = col_datetime(format = "%d.%m.%Y %H:%M:%S")))


df_clima <- data.frame(datos_clima)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#                Funciones graficas 
grafico <- function(Datos_historicos,date1,date2, simulaciones_convolucional,mediana_convolucional,simulaciones_LSTM,mediana_LSTM) {
  
  
  #indice_final <- length(Datos_historicos) - 7*144
  #indice_ultimo_dato <- seq(indice_final, indice_final + length(mediana_convolucional) -1)
  minimos_convolucional <- apply(simulaciones_convolucional, 1, min)
  maximos_convolucional <- apply(simulaciones_convolucional, 1, max)
  
  
  minimos_LSTM <- apply(simulaciones_LSTM, 1, min)
  maximos_LSTM <- apply(simulaciones_LSTM, 1, max)
  
  fig1 <- plot_ly() %>%
    add_trace(x = ~date1, y = ~Datos_historicos, type = "scatter", mode = "lines", name = "Datos historicos", line = list(color = "#0F0F0F"),showlegend = FALSE) %>%
    layout(title = "  ",xaxis  = list(title = " ",tickfont = list(size = 10)),yaxis = list(title = "Temperatura (°F)"),showlegend = FALSE) %>%
    add_trace(x = ~date2, y = ~mediana_LSTM, type = 'scatter', mode = 'lines', name = 'Mediana del pronóstico (LSTM)', line = list(color = 'blue'),showlegend = FALSE) %>%  
    add_ribbons(x = ~date2, ymin = minimos_LSTM, ymax = maximos_LSTM, fillcolor = '#FFB5C5', opacity = 0.5,name = "Pronósticos (LSTM)", line = list(color = 'rgba(0,0,0,0)'),showlegend = FALSE) %>%
    add_trace(x = ~date2 , y = ~mediana_convolucional, type = 'scatter', mode = 'lines', name = 'Mediana del pronóstico (CNN)', line = list(color = 'red'),showlegend = FALSE) %>%  
    add_ribbons(x = ~date2, ymin = minimos_convolucional, ymax = maximos_convolucional, fillcolor = '#97FFFF', opacity = 0.4,name = "Pronósticos (CNN)", line = list(color = 'rgba(0,0,0,0)'),showlegend = FALSE) 
  # %>% 
  #   layout(legend = list(
  #     orientation = "h",  # Horizontal
  #     x = 0.5,            # Centro horizontal
  #     xanchor = "center", # Anclar al centro
  #     y = -0.2            # Por encima del gráfico
  #   ),showlegend = FALSE)
  # 
  return(fig1)
}



grafico_2 <- function(Datos_historicos,date1,date2, simulaciones_convolucional,mediana_convolucional,simulaciones_LSTM,mediana_LSTM) {
  
  
  #indice_final <- length(Datos_historicos3) - 4*144
  #indice_ultimo_dato <- seq(indice_final, indice_final + length(mediana_convolucional) -1)
  minimos_convolucional <- apply(simulaciones_convolucional, 1, min)
  maximos_convolucional <- apply(simulaciones_convolucional, 1, max)
  
  minimos_LSTM <- apply(simulaciones_LSTM, 1, min)
  maximos_LSTM <- apply(simulaciones_LSTM, 1, max)
  
 fig1 <- plot_ly() %>%
    add_trace(x = ~date1, y = ~Datos_historicos, type = "scatter", mode = "lines", name = "Datos historicos", line = list(color = "#0F0F0F")) %>%
    layout(title = "  ",xaxis  = list(title = " ",tickfont = list(size = 10)),yaxis = list(title = "Temperatura (°F)")) %>%
    add_trace(x = ~date2, y = ~mediana_LSTM, type = 'scatter', mode = 'lines', name = 'Mediana del pronóstico (LSTM)', line = list(color = 'blue')) %>%  
    add_ribbons(x = ~date2, ymin = minimos_LSTM, ymax = maximos_LSTM, fillcolor = '#97FFFF', opacity = 0.4,name = "Pronósticos (LSTM)", line = list(color = 'rgba(0,0,0,0)')) %>%
    add_trace(x = ~date2 , y = ~mediana_convolucional, type = 'scatter', mode = 'lines', name = 'Mediana del pronóstico (CNN)', line = list(color = 'red')) %>%  
    add_ribbons(x = ~date2, ymin = minimos_convolucional, ymax = maximos_convolucional, fillcolor = '#97FFFF', opacity = 0.4,name = "Pronósticos (CNN)", line = list(color = 'rgba(0,0,0,0)'))%>% 
    layout(legend = list(
      orientation = "h",  # Horizontal
      x = 0.5,            # Centro horizontal
      xanchor = "center", # Anclar al centro
      y = -0.2            # Por encima del gráfico
    ))
  
  return(fig1)
}



grafico2 <- function(Datos_historicos,date1,date2, simulaciones_convolucional,mediana_convolucional,simulaciones_LSTM,mediana_LSTM) {
  
  
  #indice_final <- length(Datos_historicos3) - 4*144
  #indice_ultimo_dato <- seq(indice_final, indice_final + length(mediana_convolucional) -1)
  minimos_convolucional <- apply(simulaciones_convolucional, 1, min)
  maximos_convolucional <- apply(simulaciones_convolucional, 1, max)
  
  minimos_LSTM <- apply(simulaciones_LSTM, 1, min)
  maximos_LSTM <- apply(simulaciones_LSTM, 1, max)
  
  fig1 <- plot_ly() %>%
    add_trace(x = ~date1, y = ~Datos_historicos, type = "scatter", mode = "lines", name = "Datos historicos", line = list(color = "black")) %>%
    layout(title = "  ",
           xaxis  = list(title = " ",tickfont = list(size = 10)),
           yaxis = list(title = "Temperatura (°F)")) %>%
    add_trace(x = ~date2, y = ~mediana_LSTM, type = 'scatter', mode = 'lines', name = 'Mediana del pronóstico (LSTM)', line = list(color = 'blue')) %>%  
    add_ribbons(x = ~date2, ymin = minimos_LSTM, ymax = maximos_LSTM, fillcolor = '#FFB5C5', opacity = 0.5,name = "Pronósticos (LSTM)", line = list(color = 'rgba(0,0,0,0)')) %>%
    add_trace(x = ~date2 , y = ~mediana_convolucional, type = 'scatter', mode = 'lines', name = 'Mediana del pronóstico (CNN)', line = list(color = 'red')) %>%  
    add_ribbons(x = ~date2, ymin = minimos_convolucional, ymax = maximos_convolucional, fillcolor = '#97FFFF', opacity = 0.4,name = "Pronósticos (CNN)", line = list(color = 'rgba(0,0,0,0)'))%>% 
    layout(legend = list(
      orientation = "h",  # Horizontal
      x = 0.5,            # Centro horizontal
      xanchor = "center", # Anclar al centro
      y = -0.03            # Por encima del gráfico
    ))
  
  return(fig1)
}



annotations = list( 
  list( 
    x = -0.05,  
    y = 1.0,  
    text = "180 días",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE,
    font = list(
      size = 12,        # Tamaño del texto
      color = "black",  # Color del texto
      family = "Arial", # Familia de la fuente
      bold = TRUE       # Negrita
    )
  ),  
  list( 
    x = 0.52,  
    y = 1.0,  
    text = " 90 días",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE,
    font = list(
      size = 12,        # Tamaño del texto
      color = "black",  # Color del texto
      family = "Arial", # Familia de la fuente
      bold = TRUE       # Negrita
    )
  ),  
  list( 
    x = -0.05,  
    y = 0.45,  
    text = "30 días",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE,
    font = list(
      size = 12,        # Tamaño del texto
      color = "black",  # Color del texto
      family = "Arial", # Familia de la fuente
      bold = TRUE       # Negrita
    )
  ),
  list( 
    x = 0.52,  
    y = 0.45,  
    text = "15 días",  
    xref = "paper",  
    yref = "paper",  
    xanchor = "center",  
    yanchor = "bottom",  
    showarrow = FALSE,
    font = list(
      size = 12,        # Tamaño del texto
      color = "black",  # Color del texto
      family = "Arial", # Familia de la fuente
      bold = TRUE       # Negrita
    )
  ))
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#setwd("C:/Users/chaca/Documents/Tesis/Quarto_archivos/Tesis/Tesis_escrita" )


```

## Descripción del problema

La modelación de las variables climaticas permite el entendimiento y la generación del pronóstico climático de una región para la planificación territorial, agricultura, ecología, análisis y la conservación de los recursos naturales.

En el presente estudio, se utilizó un conjunto de datos climáticos que fueron consultados del 01 de Enero del 2009 al 01 de Enero del 2012. Con la finalidad de comprobar la utilidad y eficacia de dos modelos adecuados de redes neuronales: LTSM y la red neuronal convolucional (CNN). Para el pronóstico de datos climáticos modelados como series de tiempo.

### Origen de los datos

::: {style="text-align: justify"}
Se emplea un conjunto de datos con información climática que fue grabada con el objetivo de ser analizada en la estación climática en el Instituto de Biogeoquimica Max Planck en Jena, Alemania. El mismo contiene todas las variables medidas con su correspondiente instrumento (tal como temperatura del aire, presión atmosférica, humedad, dirección del viento, etc) grabadas cada 10 minutos, a lo largo de varios años. El cual está disponible para su descarga en <https://www.bgc-jena.mpg.de/wetter/weather_data.html> .

De los 14 datos diferentes, se seleccionan 5 teniendo en cuenta factores como su rango y sus patrones estacionales.

Las variables seleccionadas son las siguientes:

-   $p( mbar )$ - Presión del aire.

-   $T( ° C )$ - Temperatura del aire.

-   $rh( \% )$ - Humedad relativa.

-   $rho(g/m^3$) - Densidad del aire

-   $wv(m/s)$ - Velocidad del viento.

<!-- Se presentan las 5 variables en su serie temporal. -->
:::

## Limpieza y procesamiento de datos

::: {style="text-align: justify"}
Los datos recopilados fueron sometidos a un proceso exhaustivo de limpieza y preprocesamiento. <!-- Para conformar la base de datos que se utilizo,  --> En este paso se detectó el intervalo de tiempo en el que mejor se comportarán los datos históricos, por ello se asignó un conjunto de datos históricos omitiendo los primeros 7 días, así como la estandarización y normalización de las 5 variables mas relevantes. Esto con el objetivo de obtener un mejor pronóstico de los datos a futuro.
:::

## Pronóstico mediante red neuronales

### Modelamiento y pronóstico mediante redes neuronales para series de tiempo unidimensionales

::: {style="text-align: justify"}
Se presentan las gráficas de los datos históricos de las 5 variables elegidas.
:::

:::: {.content-visible when-format="html"}
::: {#fig-Temperatura_ts}
```{r echo=TRUE, message=FALSE, warning=FALSE}

Temp<-df_clima$T..degC.
Temp <-Temp +273.15
Datos_historicos <- Temp 
X<- df_clima$Date.Time
fig <- plot_ly() %>%
  add_trace(x = ~X, y = ~Datos_historicos, type = "scatter", mode = "lines", name = "Temperatura", line = list(color = '#63B8FF')) %>%
  layout(title = " ",
         xaxis = list(title = " "),
         yaxis = list(title = "Temperatura (°F)")) 
fig

```

Serie de tiempo de la Temperatura (° F) del 01 de Enero del 2009 al 01 de Enero del 2012.
:::
::::

:::: {.content-visible when-format="html"}
::: {#fig-paire_ts}
```{r echo=TRUE, message=FALSE, warning=FALSE}

p_aire <-df_clima$p..mbar. #presion del aire
X<- df_clima$Date.Time
fig <- plot_ly() %>%
  add_trace(x = ~X, y = ~p_aire, type = "scatter", mode = "lines", name = "presión aire", line = list(color = '#63B8FF')) %>%
  layout(title = " ",
         xaxis = list(title = " "),
         yaxis = list(title = "mbar")) 
fig

```

Serie de tiempo de la presión del aire p (mbar) del 01 de Enero del 2009 al 01 de Enero del 2012.
:::
::::

:::: {.content-visible when-format="html"}
::: {#fig-hrelativa_ts}
```{r echo=TRUE, message=FALSE, warning=FALSE}
h_relativa<-df_clima$rh.... #humedad relativa
X<- df_clima$Date.Time
fig <- plot_ly() %>%
  add_trace(x = ~X, y = ~h_relativa, type = "scatter", mode = "lines", name = "Humedad relativa", line = list(color = '#63B8FF')) %>%
  layout(title = " ",
         xaxis = list(title = " "),
         yaxis = list(title = "Porcentaje")) 
fig

```

Serie de tiempo de la humedad relativa rh (%) del 01 de Enero del 2009 al 01 de Enero del 2012.
:::
::::

:::: {.content-visible when-format="html"}
::: {#fig-daire_ts}
```{r echo=TRUE, message=FALSE, warning=FALSE}
d_aire<-df_clima$rho..g.m..3. # Densidad del aire 
X<- df_clima$Date.Time
fig <- plot_ly() %>%
  add_trace(x = ~X, y = ~d_aire, type = "scatter", mode = "lines", name = "Humedad relativa", line = list(color = '#63B8FF')) %>%
  layout(title = " ",
         xaxis = list(title = " "),
         yaxis = list(title = "g /m³")) 
fig

```

Serie de tiempo de la densidad del aire rho ($g /m^3$) del 01 de Enero del 2009 al 01 de Enero del 2012.
:::
::::

:::: {.content-visible when-format="html"}
::: {#fig-viento_ts}
```{r echo=TRUE, message=FALSE, warning=FALSE}
v_viento <-df_clima$wv..m.s. # Velocidad del viento
X<- df_clima$Date.Time
fig <- plot_ly() %>%
  add_trace(x = ~X, y = ~v_viento, type = "scatter", mode = "lines", name = "Humedad relativa", line = list(color = '#63B8FF')) %>%
  layout(title = " ",
         xaxis = list(title = " "),
         yaxis = list(title = "g/m")) 
fig

```

Serie de tiempo de la velocidad del viento wv ($m/s$) del 01 de Enero del 2009 al 01 de Enero del 2012.
:::
::::

::: {.content-visible when-format="pdf"}
```{r, echo=FALSE}
#| label: fig-Temperatura_tspdf
#| fig-cap: "Serie de tiempo de la Temperatura(° F) del 01 de Enero del 2009 al 01 de Enero del 2012."
 
fig <- ggplot(data = df_clima, aes(x = X, y = Datos_historicos)) +
  geom_line(color = '#63B8FF') +
  labs(title = "", x = "", y = "Temperatura (° F)") +
  theme_minimal()
plot(fig)
```
:::

::: {.content-visible when-format="pdf"}
```{r, echo=FALSE}
#| label: fig-paire_tspdf
#| fig-cap: "Serie de tiempo de la presión del aire p(mbar) del 01 de Enero del 2009 al 01 de Enero del 2012."
 
fig <- ggplot(data = df_clima, aes(x = X, y = p_aire)) +
  geom_line(color = '#63B8FF') +
  labs(title = "", x = "", y = "mbar") +
  theme_minimal()
plot(fig)
```
:::

::: {.content-visible when-format="pdf"}
```{r, echo=FALSE}
#| label: fig-hrelativa_tspdf
#| fig-cap: "Serie de tiempo de la humedad relativa rh (%) del 01 de Enero del 2009 al 01 de Enero del 2012."
 
fig <- ggplot(data = df_clima, aes(x = X, y = h_relativa)) +
  geom_line(color = '#63B8FF') +
  labs(title = "", x = "", y = "porcentaje") +
  theme_minimal()
plot(fig)
```
:::

::: {.content-visible when-format="pdf"}
```{r, echo=FALSE}
#| label: fig-daire_tspdf
#| fig-cap: "Serie de tiempo de la densidad del aire rho($g /m^3$) del 01 de Enero del 2009 al 01 de Enero del 2012."
 
fig <- ggplot(data = df_clima, aes(x = X, y = d_aire)) +
  geom_line(color = '#63B8FF') +
  labs(title = "", x = "", y = "g/ m³") +
  theme_minimal()
plot(fig)
```
:::

::: {.content-visible when-format="pdf"}
```{r, echo=FALSE}
#| label: fig-viento_tspdf
#| fig-cap: "Serie de tiempo de la velocidad del viento wv($m/ s$) del 01 de Enero del 2009 al 01 de Enero del 2012."
 
fig <- ggplot(data = df_clima, aes(x = X, y = v_viento)) +
  geom_line(color = '#63B8FF') +
  labs(title = "", x = "", y = "m/ s") +
  theme_minimal()
plot(fig)
```
:::

::: {.content-visible when-format="pdf" style="text-align: justify"}
\newpage
:::

#### Estacionalidad

::: {style="text-align: justify"}
Con el propósito de llevar a cabo una inspección visual y analítica de los datos y al mismo tiempo una descripción preliminar, se busca identificar los patrones de estacionalidad anual y diaria. Esto se puede apreciar claramente en los gráficos de [autocorrelación](series.qmd#sec-autocorrelación). Para calcular la autocorrelación en R se utiliza la función acf(). Esta función proporciona estimaciones gráficamente de la autocorrelación que se puede representar el conjunto de datos históricos de la Temperatura (° F).
:::

::: {.content-visible when-format="pdf" style="text-align: justify"}
El código que genera la autocorrelación es el siguiente :
:::

::: {#fig-Temp200}
```{r,echo=TRUE, message=FALSE, warning=FALSE}
acf(df_clima$T..degC., lag.max = 200, 
    main = "Autocorrelación de Temperatura")

```

Autocorrelación de los primeros 200 datos correspondiente a la Temperatura (° F) en su serie temporal.
:::

::: {style="text-align: justify"}
En @fig-Temp200 se observa que la autocorrelación los primeros 200 datos correspondiente a la Temperatura (° F) vistas como serie temporal. Teniendo en cuenta que el intervalo temporal entre observaciones es de 10 minutos, el patrón cíclico que se observa cada 144 observaciones corresponde al transcurso de 24 horas.
:::

::: {#fig-Temp1000}
```{r,echo=TRUE, message=FALSE, warning=FALSE}
acf(df_clima$T..degC., lag.max = 1000, 
    main = "Autocorrelación de Temperatura")

```

Autocorrelación de los primeros 1000 datos correspondiente a la Temperatura (° F) en su serie temporal.
:::

::: {style="text-align: justify"}
En @fig-Temp200 se observa que la autocorrelación los primeros 1000 datos correspondiente a la Temperatura (° F) en su serie temporal.
:::

::: {#fig-Temp100000}
```{r,echo=TRUE, message=FALSE, warning=FALSE}
acf(df_clima$T..degC., lag.max = 100000, 
    main = "Autocorrelación de Temperatura")

```

Autocorrelación de los primeros 100000 datos correspondiente a la Temperatura (° F) en su serie temporal.
:::

::: {style="text-align: justify"}
En la @fig-Temp100000 podemos deducir que los datos históricos siguen un patrón cíclico que se observa es aproximadamente cada 52000 observaciones, es decir, corresponde al transcurso de un año.
:::

#### Prueba KPSS (Kwiatkowski-Phillips-Schmidt-Shin)

::: {style="text-align: justify"}
A continuación, se emplea la prueba de Kwiatkowski-Phillips-Schmidt-Shin ([KPSS](series.qmd#sec-KPSS)) para examinar la presencia de estacionariedad en la serie temporal. Este test fué utilizado con la finalidad de identificar la existencia de [raices unitarias](series.qmd#sec-raices-unitarias) en la serie, lo cual permite inferir la presencia o ausencia de [estacionariedad](series.qmd#sec-series-estacionales) en los datos analizados.
:::

La hipótesis nula y la alternativa para la prueba KPSS son:

$$H_0:  El \ modelo \ es \ estacionario
\ \ \qquad H_1: El \  modelo \  no \ es \  estacionario$$

```{r,echo=TRUE, message=FALSE, warning=FALSE}
#library(tseries)
Temperatura_ts <-datos_clima$`T (degC)`[1:105120] #Temperatura
kpss.test(Temperatura_ts, null = "Trend")
```

::: {style="text-align: justify"}
La hipótesis nula $H_0$ no asume la presencia de raíces unitarias, lo que indica no estacionariedad en la serie, al obtener un KPSS estadístico superior que el nivel de significancia establecido el cual es de $5 \%$ ($0.05$), se rechaza la hipótesis nula, sugiriendo la ausencia de estacionariedad en la serie de tiempo de Temperatura (° F). Por lo que vamos a utilizar técnicas para obtener la estacionariedad de la serie de tiempo.

Luego, para hacer estacionarios los datos se aplicaron las siguientes transformaciones:
:::

#### Diferenciación

::: {style="text-align: justify"}
Se aplicó las diferencias a los datos de Temperatura (° F) para buscar la estacionalidad de la serie de Tiempo.
:::

::: {#fig-Temp_diferencias}
```{r,echo=TRUE, message=FALSE, warning=FALSE}
#library(tswge)
d_Temperatura = artrans.wge(Temperatura_ts,phi.tr= 1)
```

Diferencias de los datos de Temperatura (° F) en su serie temporal.
:::

::: {style="text-align: justify"}
En la @fig-Temp_diferencias se observa que después de aplicar diferencias a los datos de Temperatura (° F) observamos que la serie presenta estacionalidad.
:::

<!-- y de la prueba Kpss en la cual no se rechaza (la serie es estacionaria). -->

```{r,echo=TRUE, message=FALSE, warning=FALSE}
#library(tseries)
#d2_Temperatura = artrans.wge(d_Temperatura,phi.tr= 1)
kpss.test(d_Temperatura, null = "Trend")
```

::: {style="text-align: justify"}
Al aplicar la prueba KPSS a las diferencias a los datos de Temperatura (°F) en su serie de tiempo, se obtiene un kpss estadístico menor devuelto por el test, no se rechaza la hipótesis nula, confirmando la estacionariedad en la serie de tiempo de la Temperatura (°F).
:::

#### Estandarización

::: {style="text-align: justify"}
Para que los datos sean comparables, es necesario estandarizarlos. Se ajustan los datos históricos en su serie de tiempo para que su media sea 0 y su desviación estándar sea 1.
:::

```{r echo=FALSE, message=FALSE, warning=FALSE, attr.output='style="max-height: 300px;"'}
E_temperatura <- scale(d_Temperatura)
E_temperatura[1:100]
```

#### Normalización

::: {style="text-align: justify"}
Esta transformación modifica la escala de los datos a un nuevo rango entre 0 y 1.
:::

```{r echo=FALSE, message=FALSE, warning=FALSE, attr.output='style="max-height: 300px;"'}
normalizar <- function(vector) {
  min_value <- 0
  max_value <- 1
  min_vector <- min(vector)
  max_vector <- max(vector)
  vector_normalizado <- (vector - min_vector) / (max_vector - min_vector) * (max_value - min_value) + min_value
  return(vector_normalizado)
}

normalizar(E_temperatura[1:100])
```

::: {style="text-align: justify"}
Luego del ajuste preliminar de los datos históricos en su serie de tiempo, se realizó una separación de los datos en dos grupos. Uno para entrenamiento y otro para testeo.
:::

## Implementación de la red neuronal LSTM {#sec-implementación-de-la-red-neuronal-lstm}

::: {style="text-align: justify"}
En esta parte, se realizó el siguiente ajuste para su implementación en lenguaje Python dentro del alterno [Colaboratory](Estadistica.qmd#sec-colab) de los servicios gratuitos de google.
:::

### Pronóstico mediante técnica rodante

De las los 144 datos por día. En cada paso, se actualiza la secuencia de entrada eliminando el valor más antiguo y agregando el último pronóstico como el valor más reciente. Esto se ilustra esquemáticamente en la @fig-rodante, donde $n$ es la longitud rodante de la secuencia de entrada y $T$ es la longitud de la serie Temporal.

::: {#fig-rodante}
$$
\begin{split}
y:\text{Observado}\quad &\quad \hat{y}:\text{Pronosticado}\\
y_{T-n+1}\quad y_{T-n+2}\quad y_{T-n+3}\quad&\cdots\quad y_{T-2}\quad y_{T-1}\quad y_T\quad \to\quad \color{orange}{\hat{y}_{T+1}}\\
y_{T-n+2}\quad y_{T-n+3}\quad y_{T-n+4}\quad&\cdots\quad y_{T-1}\quad y_{T}\quad \color{orange}{\hat{y}_{T+1}}\quad \to\quad \color{orange}{\hat{y}_{T+2}}\\
y_{T-n+3}\quad y_{T-n+4}\quad y_{T-n+5}\quad&\cdots\quad y_{T}\quad \color{orange}{\hat{y}_{T+1}}\quad \color{orange}{\hat{y}_{T+2}}\quad \to\quad \color{orange}{\hat{y}_{T+3}}\\
y_{T-n+4}\quad y_{T-n+5}\quad y_{T-n+6} \quad & \cdots\quad\color{orange}{\hat{y}_{T+1}}\quad\color{orange}{\hat{y}_{T+2}}\quad\color{orange}{\hat{y}_{T+3}}  \to\quad \color{orange}{\hat{y}_{T+4}}\\
&\ddots \\
\end{split}
$$
:::

### Entrenamiento y calibración del modelo LSTM

::: {style="text-align: justify"}
Se procede al entrenamiento del modelo LSTM. La cantidad de capas ocultas son 3. La primera capa LSTM, es una capas LSTM con 50 unidades (neuronas). La segunda capa LSTM posee las mismas propiedades que la capa anterior. Y la tercera capa, es una una capa densa de salida. El tamaño del lote (batch size) es de 157, indica el número de muestras que se usarán para actualizar los pesos del modelo en cada paso de entrenamiento. Esta configuración se llevó a cabo con una función de activación [Adam](redes.qmd#sec-Adam), ejecutando 100 iteraciones para el entrenamiento de la red neuronal. La función de pérdida utilizada es el error cuadrático medio ([MSE](series.qmd#sec-MSE)).

A continuación se exhibe el código utilizado.
:::

```{python,echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE }
# univariate cnn example
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler
pd.options.mode.chained_assignment = None
tf.random.set_seed(0)



from google.colab import drive
drive.mount('/content/drive')

# Leer set de datos
ruta = '/content/drive/My Drive/Colab Notebooks/'
df = pd.read_csv(ruta+'datos_clima_wsu.csv')
Times = df['Date Time'] # Date
Temperatura = df['T(C°)'] #Valiable
#Tamaño de los Datos históricos
Temperatura = Temperatura[(7*144):(22*144)] 
Temperatura = Temperatura + 273.15 
y = pd.DataFrame({'Times': Times, 'Temperatura': Temperatura})
# Convertir la columna 'fecha' al formato datetime de pandas
y['Times'] = pd.to_datetime(y['Times'], format='%d.%m.%Y %H:%M:%S')

# Establecer la columna 'fecha' como el índice de la serie de tiempo
y.set_index('Times', inplace=True)
y = y['Temperatura'].fillna(method='ffill')
y = y.values.reshape(-1, 1)
# Escalamos los datos
scaler = MinMaxScaler(feature_range=(0, 1))
scaler = scaler.fit(y)
y = scaler.transform(y)
```

::: {.content-visible when-format="pdf" style="text-align: justify"}
``` python
# CNN para datos univariados 
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler
pd.options.mode.chained_assignment = None
tf.random.set_seed(0)

import matplotlib.pyplot as plt

# Grafica el Loss
def train_and_plot_loss(model, X, y, epochs=100, verbose=2):
    history = model.fit(X, Y, epochs=100, 
    batch_size=314, verbose=2, shuffle=False)


    # Graficar el loss
    plt.plot(history.history['loss'])
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.show()

from google.colab import drive
drive.mount('/content/drive')

# Leer set de datos
ruta = '/content/drive/My Drive/Colab Notebooks/'
df = pd.read_csv(ruta+'datos_clima_wsu.csv')
Times = df['Date Time'] # Date
Temperatura = df['T(C°)'] #Valiable
#Tamaño de los Datos historicos
Temperatura = Temperatura[(7*144):(22*144)] 
Temperatura = Temperatura + 273.15 
y = pd.DataFrame({'Times': Times, 'Temperatura': Temperatura})
# Convertir la columna 'fecha' al formato datetime de pandas
y['Times'] = pd.to_datetime(y['Times'], format='%d.%m.%Y %H:%M:%S')

# Establecer la columna 'fecha' como el índice de la serie de tiempo
y.set_index('Times', inplace=True)
y = y['Temperatura'].fillna(method='ffill')
y = y.values.reshape(-1, 1)
# Escalamiento de  los datos
scaler = MinMaxScaler(feature_range=(0, 1))
scaler = scaler.fit(y)
y = scaler.transform(y)

# generar las secuencias de entrada y salida
n_lookback = 6*144  #Secuancia de entrada
# Secuancia de salida (o Número de predicciones)
n_forecast = 144*4 

# Inicializar DataFrame para almacenar los resultados
resultados_df = pd.DataFrame()
k = 50
# Genera (k) simulaciones de la predicción
for repeticion in range(k):
    X = []
    Y = []

    for i in range(n_lookback, len(y) - n_forecast + 1):
        X.append(y[i - n_lookback: i])
        Y.append(y[i: i + n_forecast])

    X = np.array(X)
    Y = np.array(Y)

    # Crea el modelo
    model = Sequential()
    model.add(LSTM(units=50, return_sequences=True,
              input_shape=(n_lookback, 1)))
    model.add(LSTM(units=50))
    model.add(Dense(n_forecast))
    model.compile(loss='mean_squared_error', optimizer='adam')
    #Entrenamiento del modelo
    train_and_plot_loss(model, X, y, epochs=100, verbose=2)
    

    # Genera los pronósticos
    X_ = y[-n_lookback:]
    X_ = X_.reshape(1, n_lookback, 1)

    Y_ = model.predict(X_).reshape(-1, 1)
    Y_ = scaler.inverse_transform(Y_)

    # Agregar resultados al DataFrame
    resultados_df[f'Repeticion_{repeticion + 1}'] = Y_.flatten()

# Mostrar el DataFrame con los resultados
print(resultados_df)
```
:::

![Gráfica de la función de pérdida para la red neuronal LSTM](LOSS_LSTM.png){#fig-loss_LSTM}

::: {style="text-align: justify"}
En la @fig-loss_LSTM se observa la trayectoria del valor de la [función de pérdida](redes.qmd#sec-función-de-perdida) en cada época del entrenamiento en la red neuronal LSTM.
:::

## Implementación de la red neuronal convolucional (CNN) {#sec-implementación-de-la-red-neuronal-cnn.}

::: {style="text-align: justify"}
En esta parte, se realizó el mismo ajuste que en la red neuronal LSTM para su implementación en Python dentro de un servidor gratuito de [Colaboratory](Estadistica.qmd#sec-colab).

Se procede al entrenamiento de la red neuronal convolucional (CNN). <!-- En esta parte se dividió en varios casos.  --> La cantidad de capas ocultas son 5 capas, de las cuales, la primera capa es una capa es convolucional unidimensional, donde va aprender a través de 64 mapas de características y con un tamaño de [kernel](redes.qmd#sec-kernel) de dimensión 5. La segunda capa es una Capa [Max-pooling](redes.qmd#sec-pooling) unidimensional, la tercera capa es una capa de aplanar ([flatten](redes.qmd#sec-fratten)), la cuarta capa es una capa Densa, la quinta capa es Densa (salida). Asimismo, se eligió la función de activación [ReLu](redes.qmd#sec-Relu), y el proceso de entrenamiento del modelo se ejecutó a lo largo de 25 iteraciones, 70 iteraciones y 100 iteraciones según los datos históricos.

A continuación se exhibe el código utilizado.
:::

```{python,echo=TRUE, message=FALSE, warning=FALSE, eval = FALSE }
# univariate cnn example
from numpy import array
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense
from tensorflow.keras.optimizers import RMSprop
import matplotlib.pyplot as plt
from keras import backend as K

import numpy as np
import pandas as pd
import yfinance as yf
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler 


# split a univariate sequence into samples
def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps
        # check if we are beyond the sequence
        if end_ix > len(sequence)-1:
            break
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return array(X), array(y)


def train_and_plot_loss(model, X, y, epochs=20, verbose=1):
    history = model.fit(X, y, epochs=epochs, verbose=verbose)
    # Graficar el loss
    plt.plot(history.history['loss'])
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.show()

    
    
from google.colab import drive
drive.mount('/content/drive')


# Leer set de datos
ruta = '/content/drive/My Drive/Colab Notebooks/'
df = pd.read_csv(ruta+'datos_clima_wsu.csv')

Temperatura = df['T(C°)'] #Valiable
#Tamaño de los Datos historicos
Temperatura = Temperatura[(7*144):(37*144)] 
Temperatura = Temperatura + 273.15 

# Escalar los datos entre 0 y 1
scaler = MinMaxScaler(feature_range=(0, 1))
Datos_historicos = scaler.fit_transform(Temperatura.values.reshape(-1, 1))


```

::: {.content-visible when-format="pdf" style="text-align: justify"}
``` python
# univariate cnn example
from numpy import array
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense
from tensorflow.keras.optimizers import RMSprop
import matplotlib.pyplot as plt
from keras import backend as K

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler    


#Divide una secuencia univariada en muestras
def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        # Encuentra el final de este patrón
        end_ix = i + n_steps
        #Comprueba si se está más allá de la secuencia
        if end_ix > len(sequence)-1:
            break
        #Reune las partes de entrada y salida del patrón
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return array(X), array(y)

def train_and_plot_loss(model, X, y, epochs=20, verbose=1):
    history = model.fit(X, y, epochs=epochs, verbose=verbose)
    # Graficar el loss
    plt.plot(history.history['loss'])
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.show()

    
#Ubica el Drive del archivo    
from google.colab import drive
drive.mount('/content/drive')


# Leer set de datos
ruta = '/content/drive/My Drive/Colab Notebooks/'
df = pd.read_csv(ruta+'datos_clima_wsu.csv')
Temperatura = df['T(C°)'] #Valiable
#Tamaño de los Datos históricos
Temperatura = Temperatura[(7*144):(37*144)] 
Temperatura = Temperatura + 273.15 

# Se escalan los datos entre 0 y 1
scaler = MinMaxScaler(feature_range=(0, 1))
Datos_historicos = scaler.fit_transform(Temperatura.values.reshape(-1, 1))
```

``` python
#Define la secuencia de entrada
raw_seq = Datos_historicos  
# Cantidad de pasos de tiempo
n_steps = 144
# se divide las muestras
X, y = split_sequence(raw_seq, n_steps)
n_features = 1
#[muestras, pasos de tiempo, características]
X = X.reshape((X.shape[0],X.shape[1], n_features))  
# Crear un modelo secuencial
model = Sequential()
model.add(Conv1D(64, kernel_size=5, 
  activation='relu',input_shape=(n_steps, n_features)))
model.add(MaxPooling1D(pool_size=5))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(1))
model.compile(optimizer=RMSprop(clipvalue=1.0), loss='mae')
# Entreniento
train_and_plot_loss(model, X, y, epochs=100, verbose=1)
```
:::

![Gráfica de la función de pérdida obtenida mediante una CNN con el conjunto de datos históricos de la variable Temperatura (°F).](loss_convolucional.png){#fig-loss_cnn}

::: {style="text-align: justify"}
En la @fig-loss_cnn se muestra la variación del valor de la [función de pérdida](redes.qmd#sec-función-de-perdida) a lo largo del entrenamiento de la red neuronal convolucional (CNN).
:::

::: {.content-visible when-format="pdf" style="text-align: justify"}
``` python
num_simulaciones = 50
simulaciones_df = pd.DataFrame()

prediccion = []
# Preparación de datos de entrada para la predicción
x_input = y[(144*28):(144*29)]
n = len(x_input)
n_steps = 144
n_features = 1
x_input =  x_input.reshape((1, n_steps, n_features))

# Predicción con el modelo entrenado
yhat = model.predict(x_input, verbose=0).reshape(-1,1)
aux= yhat
aux = scaler.inverse_transform(aux)


for sim in range(num_simulaciones):
    k = 144*4
    prediccion = []
    i = 0
    for _ in range(k):
        x_new = yhat[-n_steps:]
        x_input = np.append(x_input, x_new)
        x_input = x_input[-n_steps:]
        x_input = x_input.reshape((1, len(x_input), n_features))
        yhat = model.predict(x_input, verbose=0).reshape(-1,1)
        aux= yhat
        aux = scaler.inverse_transform(aux)
        prediccion.append(aux)
        print("Pronóstico para los próximos", i, "valores:", aux)
        i+= 1
    # Agregar los resultados de la simulación actual al DataFrame
    simulaciones_df[f'Simulacion_{sim+1}'] = prediccion
    del model
    raw_seq = Datos_historicos
    n_steps = 144
    X, y = split_sequence(raw_seq, n_steps)
    n_features = 1
    X = X.reshape((X.shape[0],X.shape[1], n_features))

    model = Sequential()
    model.add(Conv1D(64, kernel_size=5, activation='relu', 
    input_shape=(n_steps, n_features)))
    model.add(MaxPooling1D(pool_size=5))
    model.add(Flatten())
    model.add(Dense(50, activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer=RMSprop(clipvalue=1.0), loss='mae')
    # Entrenamiento del modelo
    model.fit(X, y, epochs=100, verbose=1)
    x_input = y[(144*28):(144*29)]
    n = len(x_input)
    n_steps = 144
    n_features = 1
    x_input =  x_input.reshape((1, n_steps, n_features))
    # Predicción con el modelo entrenado
    yhat = model.predict(x_input, verbose=0).reshape(-1, 1)

# Mostrar el DataFrame con los resultados de todas las simulaciones
print(simulaciones_df)
```
:::

## Comparación de resultados

::: {style="text-align: justify"}
De manera similar, la implementación de los modelos LSTM y CNN sigue la misma metodología para las cuatro variables restantes, abarcando desde la estandarización de los datos hasta el pronóstico de los días seleccionados.
:::

::: {.content-visible when-format="pdf" style="text-align: justify"}
\newpage
:::

## Resultados Finales del Estudio de Caso

::: {style="text-align: justify"}
Los pronósticos obtenidos de la red neuronal LSTM y la red neuronal CNN, fueron guardados en hojas de cálculo para facilitar su posterior análisis. La visualización de la similitud y la tendencia de los pronósticos con los datos históricos, se hará mediante gráficas y tablas. Las gráficas fueron realizados con Plotly, versión para R, una librería para la visualización de datos en gráficos interactivos.
:::

::: {style="text-align: justify"}
Para analizar el pronóstico, se utilizan datos históricos correspondientes a los periodos de 180 días (6 meses), 90 días (3 meses), 30 días (un mes) y 15 días. Es importante destacar que, para cada entrenamiento, se calibraron los parámetros del modelo LSTM y del modelo CNN de manera específica, teniendo en cuenta la longitud de los datos históricos utilizados.
:::

::: {style="text-align: justify"}
El estudio del comportamiento de los próximos 7 días posteriores a los 180 días (6 meses) de datos históricos, requirió la configuración de la [red neuronal convolucional](estudio.qmd#sec-implementación-de-la-red-neuronal-cnn), con 5 capas ocultas, se eligió la función de activación [ReLu](redes.qmd#sec-Relu) y el entrenamiento se ejecuta a 25 épocas para obtener 100 simulaciones. Por otro lado, con los mismos datos anteriores, se reconfiguró la [red neuronal LSTM](#sec-implementación-de-la-red-neuronal-lstm), con 3 capas ocultas tipo LSTM, se eligió el optimizador [Adam](redes.qmd#sec-Adam) con un tamaño de lote (batch size) de 314 y el entrenamiento se ejecuto a 25 épocas para obtener solo 10 simulaciones debido al largo tiempo de ejecución y que no se dispone de grandes recursos computacionales.

Para el pronóstico de 4 días, se utilizaron 90 días (3 meses) de datos históricos, que en el caso de la configuración de la [red neuronal convolucional](estudio.qmd#sec-implementación-de-la-red-neuronal-cnn), tiene 5 capas ocultas, se eligió la función de activación [ReLu](redes.qmd#sec-Relu) y fueron ejecutadas 70 épocas para obtener 50 simulaciones. En cambio, para el caso de la [red neuronal LSTM](estudio.qmd#sec-implementación-de-la-red-neuronal-lstm) se utilizaron 3 capas ocultas tipo LSTM se eligió el optimizador [Adam](redes.qmd#sec-Adam) con un tamaño de lote (batch size) de 314 y el entrenamiento se ejecutó a 70 épocas para obtener las mismas 50 simulaciones.

De manera similar, para ver el comportamiento de los próximos 4 días posteriores a los 30 días de datos históricos, se configuró la [red neuronal convolucional](estudio.qmd#sec-implementación-de-la-red-neuronal-cnn) con 5 capas ocultas, se eligió la función de activación [ReLu](redes.qmd#sec-Relu) y el entrenamiento se ejecutó 100 épocas con el fin de obtener 100 simulaciones. Por otro lado, la configuración de la [red neuronal LSTM](estudio.qmd#sec-implementación-de-la-red-neuronal-lstm) utiliza 3 capas ocultas tipo LSTM, se eligió el optimizador [Adam](redes.qmd#sec-Adam) con un tamaño de lote (batch size) de 157 y el entrenamiento se realizó durante 100 épocas para generar las mismas 100 simulaciones.

Para pronosticar los próximos 2 días, se tomaron 15 días de datos históricos. La configuración de la [red neuronal convolucional](estudio.qmd#sec-implementación-de-la-red-neuronal-cnn) tiene 5 capas ocultas, se eligió la función de activación [ReLu](redes.qmd#sec-Relu) y su entrenamiento se ejecutó por 40 épocas para obtener como en el caso anterior 100 simulaciones. Por otro lado, la [red neuronal LSTM](estudio.qmd#sec-implementación-de-la-red-neuronal-lstm) tiene 3 capas ocultas tipo LSTM, se eligió el optimizador [Adam](redes.qmd#sec-Adam) con un tamaño de lote (batch size) de 157 y el entrenamiento se ejecutó a 100 épocas con el fin de obtener las mismas 100 simulaciones.

Dado que el comportamiento de cada variable en su serie de tiempo es diferente, fué necesario hacer ajustes específicos en los parámetros para que la arquitectura de los modelos implementados fuera adecuada para realizar el pronóstico. Se tomó un número apropiado de épocas para que el valor en la función de pérdida fuera lo suficientemente pequeño, evitando así el [sobreentrenamiento del modelo](redes.qmd#sec-sobreentrenamiento) y asegurando la precisión en los pronósticos. Manteniendo al mismo tiempo las propiedades cíclicas de los datos históricos.
:::

::: {.content-visible when-format="html" style="text-align: justify"}
Todo lo anterior se resume en las siguientes gráficas @fig-Temperatura , @fig-pmbar , @fig-rh, @fig-rho, @fig-wv.
:::

::: {.content-visible when-format="pdf" style="text-align: justify"}
Todo lo anterior se resume en las siguientes gráficas @fig-Temperaturapdf , @fig-pmbarpdf , @fig-rhpdf, @fig-rhopdf, @fig-wvpdf.
:::

:::: {.content-visible when-format="html"}
::: {#fig-Temperatura}
```{r echo=FALSE, message=FALSE, warning=FALSE}
#                                   Temperatura
simulaciones_6meses_convolucional_7dias <- read_excel("simulaciones_6meses_convolucional_7dias_Temperatura.xlsx")
simulaciones_6meses_convolucional_7dias <- subset(simulaciones_6meses_convolucional_7dias, select = -c(Simulacion_7 ))
mediana_6meses_convolucional_Tem <- apply(simulaciones_6meses_convolucional_7dias, 1, median)
simulaciones_6meses_LSTM_7dias <- read_excel("10simulaciones_6meses_lstm_Temperatura_7dias.xlsx")
mediana_6meses_LSTM_Tem <- apply(simulaciones_6meses_LSTM_7dias, 1, median)
Temp <- datos_clima$`T (degC)`[(7*144):(194*144)]
Temp <-Temp +273.15
Datos_historicos6 <- Temp 




simulaciones_3meses_Conv_Tem <- read_excel("simulaciones_3mes_convolucional_Temp_4dias.xlsx")
simulaciones_3meses_Conv_Tem <- subset(simulaciones_3meses_Conv_Tem, select = -c(Simulacion_7,Simulacion_10,Simulacion_13,Simulacion_24,Simulacion_25,Simulacion_29,Simulacion_30,Simulacion_35,Simulacion_36,Simulacion_44,Simulacion_49 ))
mediana_3meses_Conv_Tem <- apply(simulaciones_3meses_Conv_Tem, 1, median)
simulaciones_3meses_lstm_4dias <- read_excel("simulaciones_3meses_lstm_4dias_Temp.xlsx")
mediana_3meses_LSTM_Tem <- apply(simulaciones_3meses_lstm_4dias, 1, median)



simulaciones_1mes_convolucional_Tem_4dias <- read_excel("simulaciones_1mes_convolucional_Tem_4dias.xlsx")
simulaciones_1mes_convolucional_Tem_4dias <- subset(simulaciones_1mes_convolucional_Tem_4dias, select = -c(Simulacion_5,Simulacion_9,Simulacion_12,Simulacion_17,Simulacion_23,Simulacion_28,Simulacion_32,Simulacion_35,Simulacion_43,Simulacion_44,Simulacion_55,Simulacion_59,Simulacion_62,Simulacion_67,Simulacion_73,Simulacion_78,Simulacion_82,Simulacion_85,Simulacion_93,Simulacion_94))
mediana_Tem_1mes_CNN <- apply(simulaciones_1mes_convolucional_Tem_4dias, 1, median)
simulaciones_1mes_lstm_Tem <- read_excel("simulaciones_1mes_lstm_Tem.xlsx")
mediana_Tem_1mes_LSTM <- apply(simulaciones_1mes_lstm_Tem, 1, median)



simulaciones_15dias_lstm <- read_excel("simulaciones_15dias_lstm_Temp.xlsx")
mediana_15dias_lstm_Tem <- apply(simulaciones_15dias_lstm, 1, median)
simulaciones_15dias_conv <- read_excel("simulaciones_15dias_convolucional_2dias_Tem.xlsx")
simulaciones_15dias_conv <- subset(simulaciones_15dias_conv, select = -c(Simulacion_88,Simulacion_88))
mediana_15dias_conv <- apply(simulaciones_15dias_conv, 1, median)

#View(simulaciones_1mes_convolucional_Tem_4dias)


Date <- datos_clima$`Date Time`[(7*144):(194*144)]
date1 <- datos_clima$`Date Time`[(187*144):(194*144-1)]
date2 <- datos_clima$`Date Time`[(97*144):(101*144-1)]
date3 <- datos_clima$`Date Time`[(37*144):(41*144-1)]
date4 <- datos_clima$`Date Time`[(22*144):(24*144-1)]


fig1<- grafico(Datos_historicos6,Date,date1,simulaciones_6meses_convolucional_7dias,mediana_6meses_convolucional_Tem,simulaciones_6meses_LSTM_7dias,mediana_6meses_LSTM_Tem  )

fig2 <-grafico(Datos_historicos6,Date,date2,simulaciones_3meses_Conv_Tem,mediana_3meses_Conv_Tem,simulaciones_3meses_lstm_4dias,mediana_3meses_LSTM_Tem)


fig3 <-grafico(Datos_historicos6,Date,date3,simulaciones_1mes_convolucional_Tem_4dias,mediana_Tem_1mes_CNN,simulaciones_1mes_lstm_Tem,mediana_Tem_1mes_LSTM)

fig4 <-grafico2(Datos_historicos6,Date,date4,simulaciones_15dias_conv,mediana_15dias_conv,simulaciones_15dias_lstm,mediana_15dias_lstm_Tem)


# 
# 
fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 2, margin = 0.04) %>%
  layout(showlegend = TRUE,annotations = annotations)
fig


```

Predicción de 7 días, 4 días y 2 días de la Temperatura (° F) utilizando la red neuronal convolucional y la red neuronal LSTM
:::
::::

::: {.content-visible when-format="html" style="text-align: justify"}
Los resultados en la Figura @fig-Temperatura de Temperatura (° F) indican que la mediana de los pronósticos a 7 días, 4 días y 2 días utilizando la red neuronal LSTM presenta una aproximación más precisa a los datos históricos que la pronosticada por la red neuronal convolucional.

<!-- Y también para los 4 días correspondientes a 08 de Abril del 2009 al 12 de Abril al 2009. -->

<!-- 08 de febrero del 2009 al 11 de Febrero del 2009. -->

<!-- 23 de Enero de 2009 al 25 de Junio de 2009. -->
:::

:::: {.content-visible when-format="html"}
::: {#fig-pmbar}
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(readxl)
#                                (pmbar)
p_aire6       <-df_clima$p..mbar.[(7*144):(194*144)]
simulaciones_6meses_convolucional_pmbar <- read_excel("simulaciones_6mes_convolucional_pmbar_7dias.xlsx")
mediana_6meses_convolucional_pmbar <- apply(simulaciones_6meses_convolucional_pmbar, 1, median)
simulaciones_6meses_LSTM_pmbar <- read_excel("10simulaciones_6meses_lstm_pmbar_7dias.xlsx")
mediana_6meses_LSTM_pmbar <- apply(simulaciones_6meses_LSTM_pmbar, 1, median)

simulaciones_3meses_convolucional_pmbar_4dias <- read_excel("simulaciones_3meses_convolucional_pmbar_4dias.xlsx")
simulaciones_3meses_convolucional_pmbar_4dias <- subset(simulaciones_3meses_convolucional_pmbar_4dias, select = -c(Simulacion_21,Simulacion_39))
mediana_3meses_convolucional_pmbar <- apply(simulaciones_3meses_convolucional_pmbar_4dias, 1, median)
simulaciones_3meses_LSTM_pmbar <- read_excel("50simulaciones_3meses_lstm_pmbar_4dias.xlsx")
mediana_3meses_LSTM_pmbar <- apply(simulaciones_3meses_LSTM_pmbar, 1, median)

simulaciones_1mes_lstm_mbar <- read_excel("simulaciones_1mes_lstm_mbar.xlsx")
mediana_1mes_mbar_LSTM <- apply(simulaciones_1mes_lstm_mbar, 1, median)
simulaciones_1mes_conv_mbar <- read_excel("simulaciones_1mes_convolucional_mbar_4dias.xlsx")
mediana_1mes_mbar_conv <- apply(simulaciones_1mes_conv_mbar, 1, median)

simulaciones_15dias_lstm_pmbar_2dias<- read_excel("simulaciones_15dias_lstm_pmbar_2dias.xlsx")
mediana_15dias_pmbar_LSTM <- apply(simulaciones_15dias_lstm_pmbar_2dias, 1, median)
simulaciones_15dias_convolucional_2dias_pmbar <- read_excel("simulaciones_15dias_convolucional_2dias_pmbar.xlsx")
mediana_15dias_mbar_conv <- apply(simulaciones_15dias_convolucional_2dias_pmbar, 1, median)



fig1<- grafico(p_aire6 ,Date,date1,simulaciones_6meses_convolucional_pmbar,mediana_6meses_convolucional_pmbar,simulaciones_6meses_LSTM_pmbar,mediana_6meses_LSTM_pmbar )

fig2 <-grafico(p_aire6,Date,date2,simulaciones_3meses_convolucional_pmbar_4dias,mediana_3meses_convolucional_pmbar,simulaciones_3meses_LSTM_pmbar,mediana_3meses_LSTM_pmbar )

fig3 <-grafico(p_aire6,Date,date3,simulaciones_1mes_conv_mbar,mediana_1mes_mbar_conv,simulaciones_1mes_lstm_mbar,mediana_1mes_mbar_LSTM )

fig4 <-grafico2(p_aire6,Date,date4,simulaciones_15dias_convolucional_2dias_pmbar,mediana_15dias_mbar_conv,simulaciones_15dias_lstm_pmbar_2dias,mediana_15dias_pmbar_LSTM )


# fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 2, margin = 0.05) %>%
#   layout(showlegend = TRUE, margin = list(b = 20),annotations = annotations)
# fig

fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 2, margin = 0.04) %>%
  layout(showlegend = TRUE,annotations = annotations)
fig


```

Predicción de 7 días, 4 días y 2 días de la presión del aire p(mbar) utilizando la red neuronal convolucional y la red neuronal LSTM.
:::
::::

:::: {.content-visible when-format="html"}
::: {#fig-rho}
```{r echo=FALSE, message=FALSE, warning=FALSE}
#                        (  rho  )
d_aire6         <-df_clima$rho..g.m..3.[(7*144):(194*144)]
simulaciones_6meses_convolucional_7dias <- read_excel("simulaciones_6meses_convolucional_7dias_rho.xlsx")
mediana_6meses_convolucional_rho <- apply(simulaciones_6meses_convolucional_7dias, 1, median)
simulaciones_6meses_LSTM <- read_excel("10simulaciones_6meses_lstm_rho_7dias.xlsx")
mediana_6meses_LSTM_rho <- apply(simulaciones_6meses_LSTM, 1, median)




simulaciones_3meses_convolucional_rho_4dias <- read_excel("simulaciones_3meses_convolucional_rho_4dias.xlsx")
simulaciones_3meses_convolucional_rho_4dias <- subset(simulaciones_3meses_convolucional_rho_4dias, select = -c(Simulacion_9,Simulacion_14,Simulacion_15,Simulacion_16,Simulacion_18,Simulacion_19,Simulacion_21,Simulacion_27,Simulacion_28,Simulacion_29,Simulacion_30,Simulacion_32,Simulacion_35,Simulacion_38,Simulacion_39,Simulacion_43,Simulacion_46,Simulacion_47,Simulacion_48,Simulacion_49 ))
mediana_3meses_convolucional_rho <- apply(simulaciones_3meses_convolucional_rho_4dias, 1, median)
simulaciones_3meses_lstm_rho_4dias <- read_excel("50simulaciones_3meses_lstm_rho_4dias.xlsx")
mediana_3meses_LSTM_rho <- apply(simulaciones_3meses_lstm_rho_4dias, 1, median)





simulaciones_1mes_lstm_rho <- read_excel("simulaciones_1mes_lstm_rho.xlsx")
mediana_1mes_rho_LSTM <- apply(simulaciones_1mes_lstm_rho, 1, median)
simulaciones_1mes_convolucional_rho <- read_excel("simulaciones_1mes_convolucional_rho_4dias .xlsx")
simulaciones_1mes_convolucional_rho <- subset(simulaciones_1mes_convolucional_rho, select = -c(Simulacion_2,Simulacion_3,Simulacion_4,Simulacion_10,Simulacion_14,Simulacion_15,Simulacion_18,Simulacion_22,Simulacion_24,Simulacion_26,Simulacion_27,Simulacion_28,Simulacion_30,Simulacion_31,Simulacion_32,Simulacion_34,Simulacion_35,Simulacion_36,Simulacion_37,Simulacion_40,Simulacion_44,Simulacion_46,Simulacion_47,Simulacion_50,Simulacion_66))
mediana_1mes_rho_conv <- apply(simulaciones_1mes_convolucional_rho, 1, median)


simulaciones_15dias_lstm_rho_2dias   <- read_excel("simulaciones_15dias_lstm_rho_2dias.xlsx")
mediana_15dias_rho_LSTM <- apply(simulaciones_15dias_lstm_rho_2dias, 1, median)
simulaciones_15dias_convolucional_rho_2dias <- read_excel("simulaciones_15dias_convolucional_rho_2dias.xlsx")
simulaciones_15dias_convolucional_rho_2dias <- subset(simulaciones_15dias_convolucional_rho_2dias, select = -c(Simulacion_6,Simulacion_7,Simulacion_9,Simulacion_10,Simulacion_12,Simulacion_16,Simulacion_23,Simulacion_25,Simulacion_28,Simulacion_32,Simulacion_33,Simulacion_34,Simulacion_38,Simulacion_41,Simulacion_43,Simulacion_47,Simulacion_48,Simulacion_49,Simulacion_50,Simulacion_62,Simulacion_63,Simulacion_65,Simulacion_66,Simulacion_69,Simulacion_74,Simulacion_80,Simulacion_81,Simulacion_83,Simulacion_85,Simulacion_86,Simulacion_92,Simulacion_93,Simulacion_95,Simulacion_96,Simulacion_98))
mediana_15dias_rho_conv <- apply(simulaciones_15dias_convolucional_rho_2dias, 1, median)



fig1<- grafico(d_aire6,Date,date1,simulaciones_6meses_convolucional_7dias,mediana_6meses_convolucional_rho,simulaciones_6meses_LSTM,mediana_6meses_LSTM_rho )
fig2 <-grafico(d_aire6,Date,date2,simulaciones_3meses_convolucional_rho_4dias,mediana_3meses_convolucional_rho,simulaciones_3meses_lstm_rho_4dias ,mediana_3meses_LSTM_rho )

fig3 <-grafico(d_aire6,Date,date3,simulaciones_1mes_convolucional_rho,mediana_1mes_rho_conv,simulaciones_1mes_lstm_rho,mediana_1mes_rho_LSTM )

fig4 <-grafico2(d_aire6,Date,date4,simulaciones_15dias_convolucional_rho_2dias ,mediana_15dias_rho_conv,simulaciones_15dias_lstm_rho_2dias,mediana_15dias_rho_LSTM )



# 
# fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 4, margin = 0.05) %>%
#   layout(showlegend = TRUE, margin = list(b = 20),annotations = annotations)
# fig

fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 2, margin = 0.04) %>%
  layout(showlegend = TRUE,annotations = annotations)
fig

```

Predicción de 7 días, 4 días y 2 días de la densidad del aire utilizando la red neuronal convolucional y la red neuronal LSTM.
:::
::::

:::: {.content-visible when-format="html"}
::: {#fig-rh}
```{r echo=FALSE, message=FALSE, warning=FALSE}
#                        (  rh )
h_relativa6   <-df_clima$rh....[(7*144):(194*144)] #humedad relativa
simulaciones_6meses_convolucional_7dias <- read_excel("simulaciones_6mes_convolucional_rh_7dias.xlsx")
mediana_6meses_convolucional_rh <- apply(simulaciones_6meses_convolucional_7dias, 1, median)
simulaciones_6meses_LSTM_rh <- read_excel("10simulaciones_6meses_lstm_rh_7dias.xlsx")
mediana_6meses_LSTM_rh <- apply(simulaciones_6meses_LSTM_rh, 1, median)

simulaciones_3meses_convolucional_rh_4dias <- read_excel("simulaciones_3meses_convolucional_rh_4dias.xlsx")
simulaciones_3meses_convolucional_rh_4dias <- subset(simulaciones_3meses_convolucional_rh_4dias, select = -c(Simulacion_13))
mediana_3meses_convolucional_rh <- apply(simulaciones_3meses_convolucional_rh_4dias, 1, median)
simulaciones_3meses_lstm_rh_4dias <- read_excel("50simulaciones_3meses_lstm_rh_4dias.xlsx")
mediana_3meses_LSTM_rh <- apply(simulaciones_3meses_lstm_rh_4dias, 1, median)

simulaciones_1mes_lstm_rh <- read_excel("simulaciones_1mes_lstm_rh.xlsx")
mediana_1mes_rh_LSTM <- apply(simulaciones_1mes_lstm_rh, 1, median)
simulaciones_1mes_conv_rh <- read_excel("simulaciones_1mes_convolucional_rh_4dias.xlsx")
mediana_1mes_rh_conv <- apply(simulaciones_1mes_conv_rh, 1, median)



simulaciones_15dias_lstm_rh_2dias <- read_excel("simulaciones_15dias_lstm_rh_2dias.xlsx")
mediana_15dias_rh_LSTM <- apply(simulaciones_15dias_lstm_rh_2dias, 1, median)
simulaciones_15dias_convolucional_rh_2dias <- read_excel("simulaciones_15dias_convolucional_rh_2dias.xlsx")
mediana_15dias_rh_conv <- apply(simulaciones_15dias_convolucional_rh_2dias, 1, median)

fig1<- grafico(h_relativa6 ,Date,date1, simulaciones_6meses_convolucional_7dias ,mediana_6meses_convolucional_rh ,simulaciones_6meses_LSTM_rh,mediana_6meses_LSTM_rh  )

fig2<- grafico(h_relativa6 ,Date,date2, simulaciones_3meses_convolucional_rh_4dias ,mediana_3meses_convolucional_rh ,simulaciones_3meses_lstm_rh_4dias,mediana_3meses_LSTM_rh  )

fig3 <- grafico(h_relativa6,Date,date3,simulaciones_1mes_conv_rh,mediana_1mes_rh_conv ,simulaciones_1mes_lstm_rh,mediana_1mes_rh_LSTM )

fig4 <- grafico2(h_relativa6,Date,date4,simulaciones_15dias_convolucional_rh_2dias,mediana_15dias_rh_conv,simulaciones_15dias_lstm_rh_2dias,mediana_15dias_rh_LSTM)

# fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 4, margin = 0.05) %>%
#   layout(showlegend = TRUE, margin = list(b = 20),annotations = annotations)
# fig

fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 2, margin = 0.04) %>%
  layout(showlegend = TRUE,annotations = annotations)
fig


```

Predicción de 7 días, 4 días y 2 días de la humedad relativa utilizando la red neuronal convolucional y la red neuronal LSTM
:::
::::

:::: {.content-visible when-format="html"}
::: {#fig-wv}
```{r echo=FALSE, message=FALSE, warning=FALSE}
#               (wv)
v_viento6      <-df_clima$wv..m.s.[(7*144):(194*144)]
simulaciones_6meses_convolucional_7dias <- read_excel("simulaciones_6meses_convolucional_7dias_wv.xlsx")
mediana_6meses_convolucional_wv <- apply(simulaciones_6meses_convolucional_7dias, 1, median)

simulaciones_6meses_LSTM_wv <- read_excel("10simulaciones_6meses_lstm_wv_7dias.xlsx")
mediana_6meses_LSTM_wv <- apply(simulaciones_6meses_LSTM_wv, 1, median)

simulaciones_3mes_Conv_wv <- read_excel("simulaciones_3mes_convolucional_wv_4dias.xlsx")
simulaciones_3mes_Conv_wv <- subset(simulaciones_3mes_Conv_wv, select = -c(Simulacion_2,Simulacion_34,Simulacion_10 ))
mediana_3meses_Conv_wv <- apply(simulaciones_3mes_Conv_wv, 1, median)
simulaciones_3mes_LSTM_wv <- read_excel("50simulaciones_3meses_lstm_wv_4dias.xlsx")
mediana_3meses_LSTM_wv <- apply(simulaciones_3mes_LSTM_wv, 1, median)

simulaciones_1mes_conv_wv <- read_excel("simulaciones_1mes_convolucional_wv_4dias.xlsx")
simulaciones_1mes_conv_wv <- subset(simulaciones_1mes_conv_wv, select = -c(Simulacion_25 ))
mediana_1mes_wv_conv <- apply(simulaciones_1mes_conv_wv, 1, median)
simulaciones_1mes_lstm_wv <- read_excel("simulaciones_1mes_lstm_wv.xlsx")
mediana_1mes_wv_LSTM <- apply(simulaciones_1mes_lstm_wv, 1, median)

simulaciones_15dias_convolucional_wv_2dias <- read_excel("simulaciones_15dias_convolucional_wv_2dias.xlsx")
mediana_15dias_wv_conv <- apply(simulaciones_15dias_convolucional_wv_2dias, 1, median)
simulaciones_15dias_lstm_wv_2dias <- read_excel("simulaciones_15dias_lstm_wv_2dias.xlsx")
mediana_15dias_wv_LSTM <- apply(simulaciones_15dias_lstm_wv_2dias, 1, median)

fig1 <- grafico(v_viento6,Date,date1,simulaciones_6meses_convolucional_7dias,mediana_6meses_convolucional_wv,simulaciones_6meses_LSTM_wv,mediana_6meses_LSTM_wv)

fig2 <- grafico(v_viento6,Date,date2,simulaciones_3mes_Conv_wv,mediana_3meses_Conv_wv,simulaciones_3mes_LSTM_wv,mediana_3meses_LSTM_wv )


fig3 <- grafico(v_viento6,Date,date3, simulaciones_1mes_conv_wv, mediana_1mes_wv_conv, simulaciones_1mes_lstm_wv,mediana_1mes_wv_LSTM )

fig4 <- grafico2(v_viento6,Date,date4,simulaciones_15dias_convolucional_wv_2dias,mediana_15dias_wv_conv,simulaciones_15dias_lstm_wv_2dias,mediana_15dias_wv_LSTM)


# 
# fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 4, margin = 0.05) %>%
#   layout(showlegend = TRUE, margin = list(b = 20),annotations = annotations)
# fig
fig <- subplot(fig1, fig2,fig3,fig4 ,nrows = 2, margin = 0.04) %>%
  layout(showlegend = TRUE,annotations = annotations)
fig

```

Predicción de 7 días, 4 días y 2 días de la velocidad del viento utilizando la red neuronal convolucional y la red neuronal LSTM
:::
::::

::: {.content-visible when-format="pdf"}
![Predicción de 7 días, 4 días y 2 días de la Temperatura (° F) utilizando la red neuronal convolucional y la red neuronal LSTM](Temperatura2.png){#fig-Temperaturapdf width="515"}
:::

::: {.content-visible when-format="pdf" style="text-align: justify"}
Los resultados en la Figura de Temperatura (@fig-Temperaturapdf) indican que la [mediana](Estadistica.qmd#sec-Mediana) de los pronósticos a 7 días, 4 días y 2 días utilizando la red neuronal LSTM presenta una aproximación más precisa a los datos históricos que la pronosticada por la red neuronal convolucional.
:::

::: {.content-visible when-format="pdf"}
![Predicción de 7 días, 4 días y 2 días de la presión del aire utilizando la red neuronal convolucional y la red neuronal LSTM.](PMBAR.png){#fig-pmbarpdf}
:::

::: {.content-visible when-format="pdf"}
![Predicción de 7 días, 4 días y 2 días de la densidad del aire utilizando la red neuronal convolucional y la red neuronal LSTM.](RHO.png){#fig-rhopdf}
:::

::: {.content-visible when-format="pdf"}
![Predicción de 7 días, 4 días y 2 días de la humedad relativa utilizando la red neuronal convolucional y la red neuronal LSTM](RH.png){#fig-rhpdf}
:::

::: {.content-visible when-format="pdf"}
![Predicción de 7 días, 4 días y 2 días de la velocidad del viento utilizando la red neuronal convolucional y la red neuronal LSTM](WV.png){#fig-wvpdf}
:::

::: {.content-visible when-format="pdf" style="text-align: justify"}
\newpage
:::

#### RMSE

::: {style="text-align: justify"}
Luego de obtener los valores pronosticados por las redes propuestas, se tomó la [mediana](Estadistica.qmd#sec-Mediana) de los pronósticos y se procedió a contrastarlos con el error cuadrático medio ([RMSE](series.qmd#sec-RMSE)). Esto permitió determinar el menor valor del error y así identificar diferencias de usa los modelos de redes. Los resultados obtenidos se muestran en @tbl-RMSE.
:::

|  |  |  |  |  |
|:--:|:--:|:--:|:--:|:--:|
|  |  | **RMSE** |  |  |
| **Datos históricos** | **180 días** | **90 días** | **30 días** | **15 días** |
| **Numero de días pronosticados** | 7 días | 4 días | 4 días | 2 días |
| **Temperatura (CNN)** | 7.748363 | 12.544 | 4.729259 | 5.89646 |
| **Temperatura (LSTM)** | 3.035672 | 7.350131 | 3.267742 | 4.281648 |
| **Velocidad del viento (CNN)** | 1.805565 | 1.525929 | 2.68279 | 3.638407 |
| **Velocidad del viento (LSTM)** | 1.415952 | 1.366431 | 2.711044 | 2.846553 |
| **Densidad del aire (CNN)** | 43.71869 | 24.26363 | 26.00116 | 69.96927 |
| **Densidad del aire (LSTM)** | 14.33086 | 43.15156 | 22.59924 | 38.28266 |
| **Humedad relativa (CNN)** | 23.77749 | 34.24427 | 21.69839 | 10.64634 |
| **Humedad relativa (LSTM)** | 10.83128 | 12.39585 | 13.42141 | 14.1402 |
| **Presión del aire (CNN)** | 9.351951 | 19.09469 | 17.30254 | 17.22759 |
| **Presión del aire (LSTM)** | 3.638899 | 3.289955 | 9.254557 | 22.74026 |

: RMSE de la mediana de los pronósticos para 5 variables. {#tbl-RMSE}

::: {style="text-align: justify"}
A través de la @tbl-RMSE, se observa inicialmente de que para estos datos meteorológicos, la red neuronal LSTM exhibe un error considerablemente menor en comparación con la red neuronal convolucional. Esto resulta en un pronóstico mas cercano a los valores reales, por lo tanto, se recomienda utilizar la red neuronal LSTM para llevar a cabo futuras predicciones.

En la @tbl-RMSE se observa que la red neuronal LSTM proporciona una mejor aproximación para la variable velocidad del viento, ya que el error cuadrático medio ([RMSE](series.qmd#sec-RMSE)) es significativamente menor en todos los pronóstico realizados en comparación con la red neuronal convolucional. Además, el mismo análisis en la @tbl-RMSE revela que, a medida que aumentan los datos históricos de la velocidad del viento, el RMSE tiende a disminuir.

Por otro lado, se observa en @tbl-RMSE que el pronóstico para la densidad del aire no es tan preciso, ya que presenta el ([RMSE](series.qmd#sec-RMSE)) más alto en comparación con las demás variables. En ambos modelos, tanto la red neuronal LSTM como la red neuronal convolucional, no logran una buena predicción en los días pronosticados, comparado con la gráfica del valor real. Esta diferencia en la precisión del pronóstico podría deberse a varios factores. Uno de los factores potenciales es una posible falla en los sensores de densidad del aire. Los sensores podrían estar proporcionando datos inconsistentes, lo que afectaría la capacidad de los modelos para aprender patrones precisos y hacer predicciones confiables. Además, es posible que haya fluctuaciones no detectadas en las condiciones ambientales o interferencias externas que impacten la precisión de los sensores.
:::
