[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Comparación de pronósticos de variables climaticas mediante adaptación de redes neuronales artificiales LSTM y convolucional.",
    "section": "",
    "text": "1 Resumen\n\nEsta tesis presenta un análisis comparativo de dos tipos de modelos de redes neuronales utilizados para el pronóstico de series temporales: las redes neuronales de memoria de corto y largo plazo (LSTM) y las redes neuronales convolucionales (CNN). El estudio adopta un enfoque integral que comienza con una revisión exhaustiva de los datos, abarcando desde la limpieza y preparación de los mismos hasta la aplicación de la teoría del análisis de series temporales. Además, se exploran en profundidad los fundamentos de las redes neuronales, proporcionando una base teórica sólida que permite entender las metodologías empleadas en el estudio. A través de esta comparación, se busca identificar las fortalezas y debilidades de cada modelo en el contexto del pronóstico de series temporales.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Resumen</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introducción",
    "section": "",
    "text": "La climatología es crucial para entender los patrones y cambios en el clima, lo cual es vital para la planificación y adaptación en diversos sectores, desde la agricultura hasta la gestión de desastres naturales. Debido a las variaciones climáticas a lo largo del tiempo, surge la necesidad de desarrollar la capacidad de predecir fenómenos climáticos para mejorar la planificación y la preparación ante estos eventos. Utilizando técnicas avanzadas de análisis de series temporales, los climatólogos pueden identificar patrones y tendencias en los datos históricos del clima, lo que permite hacer pronósticos más precisos sobre futuros eventos climáticos.\nEl análisis de series temporales permite desentrañar las tendencias y variaciones a lo largo del tiempo, proporcionando una base sólida para la predicción y toma de decisiones informadas. Las redes neuronales, con su capacidad para aprender y modelar relaciones complejas en grandes volúmenes de datos, han revolucionado la manera en que abordamos los pronósticos climáticos. Obtener pronósticos precisos no solo ayuda a mitigar los impactos negativos de eventos climáticos extremos, sino que también optimiza la gestión de recursos y promueve un desarrollo sostenible.\nLas red neuronal con memoria a corto y largo plazo (LSTM) y redes neuronales convolucionales (CNN) son arquitecturas especializadas en diferentes tareas de procesamiento de datos. La red neurona LSTM es una red recurrente que se utiliza principalmente para manejar secuencias de datos y es eficiente para modelar dependencias a largo plazo, como series temporales o texto. Por otro lado, las redes convolucionales están diseñadas para el procesamiento de datos con estructura de cuadrícula, como imágenes, y se destacan por su capacidad para extraer características espaciales a través de convoluciones. Tanto las redes LSTM como las redes convolucionales pueden implementarse utilizando las bibliotecas de aprendizaje profundo como Keras y TensorFlow, que proporcionan herramientas fáciles de usar para definir, entrenar y evaluar estos modelos. El proceso de entrenamiento de estos modelos consiste en ajustar los pesos a través de técnicas de optimización, mientras que el testeo implica evaluar el rendimiento en un conjunto de datos que no ha sido utilizado en el entrenamiento. La función de pérdida (loss) mide el error entre las predicciones del modelo y los valores reales, siendo clave para guiar el aprendizaje.\nEn el estudio del comportamiento atmosférico de una región determinada, resulta fundamental contar con instrumentos especializados para la recolección de datos climáticos. Una estación climática, que consiste en un conjunto de dispositivos que recopilan información sobre diversas variables climáticas para estudiar el comportamiento atmosférico en una región determinada. Las variables más comúnmente estudiadas incluyen la presión del aire, la temperatura, la humedad relativa, la velocidad del viento, y la densidad del aire. En este análisis, se seleccionaron las siguientes variables: presión del aire (p en mbar), temperatura del aire (T en °F), humedad relativa (rh en \\(\\%\\)), densidad del aire (rho en \\(g/m^3\\)), y velocidad del viento (wv en \\(m/s\\)). Estas variables fueron elegidas considerando su relevancia en la modelización climática, su rango de valores y patrones estacionales, los cuales juegan un papel clave en el comportamiento del clima a lo largo del tiempo.\nLa estructura de la tesis se organiza de la siguiente manera: en la Parte I se presentan los preliminares, que incluyen los conceptos fundamentales de estadística y probabilidad, así como definiciones clave que serán útiles para el desarrollo posterior de los temas. En la Parte II se introducen los conceptos de series de tiempo. La Parte III, en el Capítulo 5, aborda las herramientas de inteligencia artificial, explorando los tipos de aprendizaje automático, incluyendo el aprendizaje profundo. En el Capítulo 6, se presentan los conceptos básicos de climatología necesarios para la interpretación de gráficos.\nLa Parte IV, que abarca los Capítulos 7, 8 y 9 se centra en las redes neuronales, cubriendo su arquitectura, entrenamiento e implementación en Python, las cuales serán aplicadas en el estudio de caso. En la Parte V, se desarrolla el estudio de caso, describiendo la metodología utilizada para el pronóstico en ambos modelos. Finalmente, en el Capítulo 12, se exponen las conclusiones obtenidas a partir del estudio de caso.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "Objetivos.html",
    "href": "Objetivos.html",
    "title": "Objetivos",
    "section": "",
    "text": "Objetivo General",
    "crumbs": [
      "Objetivos"
    ]
  },
  {
    "objectID": "Objetivos.html#objetivo-general",
    "href": "Objetivos.html#objetivo-general",
    "title": "Objetivos",
    "section": "",
    "text": "Comparar el pronóstico obtenido a partir de datos históricos las variables climáticas, generados por la Red Neuronal Artificial (RNA) Long Short-Term Memory (LSTM) y la red neuronal convolucional (CNN), utilizando métricas de error relevantes para evaluar su desempeño.",
    "crumbs": [
      "Objetivos"
    ]
  },
  {
    "objectID": "Objetivos.html#objetivos-específicos",
    "href": "Objetivos.html#objetivos-específicos",
    "title": "Objetivos",
    "section": "Objetivos Específicos",
    "text": "Objetivos Específicos\n\n\n\nEvaluar y comparar el rendimiento de la Red Neuronal Artificial de memoria a corto y largo plazo (LSTM) y la Red Neuronal Convolucional (CNN).\nAnalizar y comparar los patrones, tendencias y propiedades de los datos históricos con pronósticos generados por las redes neuronales artificiales, para entender los factores que influyen en la generación de pronósticos.\nAbordar el uso de paqueterías en los lenguajes de programación de Python y R, que serán asociadas en las implementaciones de las redes neuronales mencionadas.",
    "crumbs": [
      "Objetivos"
    ]
  },
  {
    "objectID": "Probabilidad.html",
    "href": "Probabilidad.html",
    "title": "2  Nociones basicas de Probabilidad",
    "section": "",
    "text": "2.1 Probabilidad condicional\nEn ocasiones, no solo se analizan los resultados individuales de un espacio muestral \\(\\Omega\\), sino también distintas agrupaciones o combinaciones de dichos resultados, que son precisamente los eventos. En lugar de enfocarse en un resultado específico del espacio muestral, puede ser de mayor interés la ocurrencia de ciertos eventos relacionados con el experimento.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Nociones basicas de Probabilidad</span>"
    ]
  },
  {
    "objectID": "Probabilidad.html#probabilidad-condicional",
    "href": "Probabilidad.html#probabilidad-condicional",
    "title": "2  Nociones basicas de Probabilidad",
    "section": "",
    "text": "En ocasiones resulta relevante describir la probabilidad de que ocurra un evento dado que ya se conoce la ocurrencia de otro evento, en la teoría de probabilidad es lo que se conoce como la probabilidad condicional.\n\n\n\nDefinición 2.7 (Probabilidad condicional) Sean \\(A\\) y \\(B\\) dos eventos de \\(\\mathfrak{F}\\) de un espacio de probabilidad \\((\\Omega, \\mathfrak{F}, P)\\). La probabilidad de \\(A\\) dado \\(B\\), que se denota por \\(P(A/B)\\), y se define como \\[\nP(A/B) = \\dfrac{P(A \\cap B ) }{P(B) } , \\  \\ \\ \\ \\ \\text{si} \\ \\ P(B)&gt;0.\n\\tag{2.1}\\]\n\n\nA continuación, se presentan las propiedades fundamentales de la probabilidad condicional:\nSea \\((\\Omega, \\mathcal{F}, P)\\) un espacio de probabilidad, y sea \\(A \\in \\mathcal{F}\\) tal que \\(P(A) &gt; 0\\). Entonces:\n\n\\(P(A \\mid A) = 1\\).\nSi \\(A \\cap B = \\emptyset\\), entonces \\(P(B \\mid A) = 0\\).\n\\(P(B \\cap C \\mid A) = P(B \\mid A \\cap C) P(C \\mid A)\\) si \\(P(A \\cap C) &gt; 0\\).\nSi \\(A_1, A_2, \\dots, A_n \\in \\mathcal{F}\\) con \\(P(A_1 \\cap A_2 \\cap \\dots \\cap A_{n-1}) &gt; 0\\) entonces \\[ P(A_1 \\cap A_2 \\cap \\dots \\cap A_n) = P(A_1) P(A_2 | A_1) P(A_3 \\mid A_1 \\cap A_2) \\cdots P(A_n \\mid A_1 \\cap A_2 \\cap \\dots \\cap A_{n-1}).\\]\n\n\n\nEn el siguiente ejemplo, se muestra cómo calcular la probabilidad condicional para dos eventos.\n\n\n\n\n\n\n\nEjemplo de lanzamiento simultáneo de dos dados\n\n\n\n\n\nSe lanzan dos dados juntos una vez. Se busca calcular la probabilidad de que al menos uno de los resultados sea 6, dado que los resultados obtenidos son diferentes.\nDefinamos los siguientes eventos:\n\\(A\\): El evento “los resultados son diferentes”.\n\\(B\\): El evento “al menos uno de los resultados es 6”.\nFormalmente, estos eventos se pueden describir de la siguiente manera : \\[\nA = \\{(a, b) : a, b \\in \\{1, 2, \\dots, 6\\}, a \\neq b \\}\n\\] y \\[\nB = \\{(a, 6) : a \\in \\{1, 2, \\dots, 6\\}\\} \\cup \\{(6, b) : b \\in \\{1, 2, \\dots, 6\\}\\}.\n\\]\nPara calcular la probabilidad condicionada \\(P(B | A)\\), se utiliza la fórmula de la probabilidad condicionada:\n\\[\nP(B | A) = \\frac{P(A \\cap B)}{P(A)}.\n\\]\nPrimero, se calcula el número de elementos en \\(A\\). Como hay 6 posibles valores para cada dado, pero los resultados no deben ser iguales, el número total de resultados posibles en \\(A\\) es:\n\\[\n|A| = 6 \\times 6 - 6 = 30.\n\\]\nLuego,se obtiene el número de elementos en \\(A \\cap B\\), es decir, aquellos pares en los que al menos uno de los dados es un 6 y los resultados son diferentes. Hay 5 combinaciones posibles donde el primer dado no es 6 y el segundo es 6, y otras 5 donde el primer dado es 6 y el segundo no lo es. Por lo tanto, el número de elementos en \\(A \\cap B\\) es:\n\\[\n|A \\cap B| = 5 + 5 = 10.\n\\]\nFinalmente, la probabilidad condicionada es:\n\\[\nP(B | A) = \\frac{10}{30} = \\frac{1}{3}.\n\\]\n\n\n\n\nSi bien, la probabilidad condicional ajusta la probabilidad de un evento en función de información adicional, también proporciona una base esencial para entender la independencia de eventos. Este concepto se fundamenta en la idea de que la probabilidad de un evento no se ve afectada por la ocurrencia de otro, lo cual puede identificarse a través de la probabilidad condicional. Así, además de modificar las probabilidades en función de nueva información, la probabilidad condicional permite clarificar cuándo dos eventos son realmente independientes.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Nociones basicas de Probabilidad</span>"
    ]
  },
  {
    "objectID": "Probabilidad.html#independencia-de-eventos",
    "href": "Probabilidad.html#independencia-de-eventos",
    "title": "2  Nociones basicas de Probabilidad",
    "section": "2.2 Independencia de eventos",
    "text": "2.2 Independencia de eventos\n\nDefinición 2.8 (Independecia de eventos) Se dice que dos eventos \\(A\\) y \\(B\\) son independientes si y solo si se cumple alguna de las siguientes condiciones:\n\\[\nP(A|B)= P(A)\n\\tag{2.2}\\]\n\\[\nP(B|A)= P(B)\n\\tag{2.3}\\]\n\\[\nP(A \\cap B) = P(A) P(B)\n\\tag{2.4}\\]\n\n\nPor el contrario, si la condiciones (2.2), (2.3), (2.4) no se cumple, se dice que los eventos son dependientes.\nLa condición \\(P(B|A) = P(B)\\) significa que el evento \\(B\\) es independiente del evento \\(A\\), lo que representa que la probabilidad de que ocurra \\(B\\) no cambia aunque se sepa que ha ocurrido \\(A\\). Esta independencia implica que el conocimiento de uno de los eventos no proporciona información sobre el otro.\nLa condición en (2.3) implica que \\(P(A|B) = P(A)\\), y viceversa.\n\n\nDefinición 2.9 (Independencia de varios eventos) Para un espacio de probabilidad dado \\((\\Omega, \\mathfrak{F}, P)\\), sean \\(A_1,A_2, \\cdot , A_n\\) Los eventos \\(A_1,A_2, \\cdot , A_n\\) de \\(\\mathfrak{F}\\). Se definen como independientes si y solo si \\[P\\left(\\bigcap\\limits_{i=1}^n A_i\\right)=\\prod\\limits_{i=1}^n P(A_i).\n\\]\n\n\nDefinición 2.10 (sigma-álgebra) Dada una colección \\(\\mathcal{F}\\) de subconjuntos de \\(\\Omega\\) se llama una \\(\\sigma-\\text{álgebra}\\) sobre \\(\\Omega\\) si:\n\n\\(\\Omega \\in \\mathcal{F}\\).\nSi \\(A \\in \\mathcal{F}\\), entonces \\(A^c \\in \\mathcal{F}\\).\nSi \\(A_1, A_2, \\dots \\in \\mathcal{F}\\), entonces \\(\\bigcup_{i=1}^{\\infty} A_i \\in \\mathcal{F}\\).\n\n\nLos elementos de \\(\\mathcal{F}\\) se llaman eventos.\n\nEjemplo 2.1  \n\n\n\n\n\n\nLanzamiento de dos monedas juntas\n\n\n\n\n\nConsideremos un experimento aleatorio que consiste en lanzar dos monedas juntas. El espacio muestral es \\(\\Omega = \\{ HH, HT, TH, TT \\}\\), donde:\nSea \\(\\mathcal{F} = \\{\\emptyset, \\{HH, HT\\}, \\{TH, TT\\}, \\Omega\\}\\), que es una colección de subconjuntos de \\((\\Omega)\\). Se quiere demostrar que \\((\\mathcal{F})\\) es una \\(\\sigma-\\text{álgebra}\\).\nPara ello, verificamos las tres condiciones:\n\\(\\Omega \\in \\mathcal{F}\\), lo cual es cierto ya que \\(\\Omega = \\{HH, HT, TH, TT\\}\\) está incluido en \\(\\mathcal{F}\\).\nSi \\(A \\in \\mathcal{F}\\), entonces \\(A^c\\) también debe estar en \\(\\mathcal{F}\\). Por ejemplo, el complemento de \\(\\{HH, HT\\}\\) es \\(\\{TH, TT\\}\\), que también pertenece a \\(\\mathcal{F}\\). De manera similar, el complemento de \\(\\{TH, TT\\}\\) es \\(\\{HH, HT\\}\\), lo que también está en \\(\\mathcal{F}\\), y el complemento de \\(\\emptyset\\) es \\(\\Omega\\), que también está en \\(\\mathcal{F}\\).\nLa unión infinita (o finita) de conjuntos en \\(\\mathcal{F}\\) pertenece a \\(\\mathcal{F}\\). Por ejemplo, \\(\\{HH, HT\\} \\cup \\{TH, TT\\} = \\Omega\\), que está en \\(\\mathcal{F}\\).\nDe manera similar, \\(\\emptyset \\cup \\{HH, HT\\} = \\{HH, HT\\}\\), que también está en \\(\\mathcal{F}\\).\nPor lo tanto, \\(\\mathcal{F}\\) es una \\(\\sigma-\\text{álgebra}\\) sobre \\(\\Omega\\).\n\n\n\n\n\nDefinición 2.11 (Medida de probabilidad) Una función \\(P\\), definida sobre una \\(\\sigma-\\text{álgebra}\\) \\(\\mathfrak{F}\\) y con valores en el intervalo \\([0, 1]\\) es una medida de probabilidad si satisface,\n\n\\(P(\\Omega) = 1\\) y\nEs \\(\\sigma-\\text{aditiva}\\).\n\n\n\nEsto significa que para cualquier \\(A_1,A_2, \\dots , A_n \\in \\mathfrak{F}\\) sean mutuamente excluyentes, es decir, \\(A_i ∩ A_j = \\emptyset\\) para \\(i \\neq j\\) se cumple que\n\\[\n\\displaystyle P \\left( \\bigcup_{i=1}^{\\infty} A_i \\right) = \\displaystyle   \\sum_{i=1}^{\\infty} P (A_i)\n\\]\n\n\nDefinición 2.12 (Espacio de Probabilidad) Un espacio de probabilidad es una terna \\((\\Omega, \\mathfrak{F}, P)\\), en donde \\(\\Omega\\) es un conjunto arbitrario,\\(\\mathfrak{F}\\) es una colección subconjunto de \\(\\Omega\\) asumida como una \\(\\sigma-\\text{álgebra}\\) de eventos, y \\(P\\) es una función de probabilidad con dominio \\(\\mathfrak{F}\\), una variable aleatoria \\(X\\).\nA la pareja \\((\\Omega, \\mathfrak{F})\\) se llama espacio medible.\n\n\nEjemplo 2.2  \n\n\n\n\n\n\nEjemplo de lanzamiento de un dado\n\n\n\n\n\nConsideremos lanzar un dado de seis caras y observar el número que aparece. El espacio muestral \\(\\Omega\\) incluye todos los posibles resultados del lanzamiento de un dado\n\\[\\Omega = \\{1,2,3,4,5,6 \\}\\] La \\(\\sigma-\\text{álgebra}\\) es el conjunto de todos los eventos que podemos observar, lo que incluye cualquier subconjunto del espacio muestral \\(\\Omega\\). En este caso, \\(\\mathfrak{F}\\) incluiría:\n\\[\n\\mathfrak{F} = \\{ \\{\\emptyset\\},\\{1\\},\\{2\\},\\{1,2\\},\\dots,\\{1,2,3\\},\\dots,\\{1,2,3,4,5\\},\\Omega\\}\n\\]\n\\(\\mathfrak{F}\\) contiene todos los subconjuntos posibles de \\(\\Omega\\), como eventos de un solo número \\((\\{1,2\\})\\), combinaciones de varios números \\((\\{1,2,3,\\dots\\})\\), o el evento completo \\(\\Omega\\) , que representa cualquier resultado.\nLa medida de probabilidad \\(P\\) asigna una probabilidad a cada subconjunto de \\(\\mathfrak{F}\\). Como el dado es justo, cada número tiene la misma probabilidad de ocurrir. Entonces, para un evento elemental \\(\\{i\\}\\), la probabilidad se asigna de la siguiente manera: \\[\nP(\\{i\\})= \\dfrac{1}{6} \\ \\ \\text{para todo} \\ \\  i \\in \\Omega.\n\\tag{2.5}\\]\nAdemás,la probabilidad de obtener un número par, es decir, el evento \\((\\{2,4,6\\})\\),se calcula sumando las probabilidades individuales de cada uno de estos resultados. Como en (2.5) cada número tiene la misma probabilidad de ocurrir, por lo que, \\[P({2,4,6}) = P(\\{2\\}) + P(\\{4\\}) + P(\\{6\\}) = \\frac{1}{6} + \\frac{1}{6} +\\frac{1}{6} = \\frac{3}{6} = \\frac{1}{2} \\]\nPor lo tanto, el espacio de probabilidad para el lanzamiento de un dado de seis caras es: \\(( \\{1,2,3,4,5,6 \\},\\mathfrak{F},P)\\)",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Nociones basicas de Probabilidad</span>"
    ]
  },
  {
    "objectID": "Probabilidad.html#sec-VA",
    "href": "Probabilidad.html#sec-VA",
    "title": "2  Nociones basicas de Probabilidad",
    "section": "2.3 Variable aleatoria",
    "text": "2.3 Variable aleatoria\n\nUna variable aleatoria permite asignar valores numéricos a los resultados de un experimento aleatorio, mapeando el espacio de resultados a los números reales. Su definición garantiza que la probabilidad asociada a cualquier subconjunto de resultados posibles esté bien definida. A continuación, se formaliza esta idea dentro de un espacio de probabilidad.\n\n\n\n\nDefinición 2.13 (Variable aleatoria) Para un espacio de probabilidad un \\((\\Omega, \\mathcal{F}, P)\\). Una variable aleatoria real es una función \\(X: \\Omega \\to \\mathbb{R}\\) tal que, para todo \\(A \\in \\mathcal{F}\\), se cumple que \\(X^{-1}(A) \\in \\mathcal{F}\\), donde \\(\\mathcal{F}\\) es una \\(\\sigma\\)-álgebra sobre \\(\\mathbb{R}\\).\n\nLas variables aleatorias pueden ser discretas o continuas. Las variables aleatorias discreta son aquellas que pueden tomar un número finito o numerable de valores distintos. Por ejemplo, el número de caras al lanzar tres monedas (puede ser \\(0, 1, 2\\) ó \\(3\\)). Por otro lado, las variables aleatorias continuas toman cualquier valor dentro de un intervalo de la recta real \\(\\mathbb{R}\\). Un ejemplo de variable aleatoria continua es la temperatura de una ciudad, medida en grados Celsius.\nLa función de distribución describe la probabilidad de que una variable aleatoria real tome un valor menor o igual a un cierto número. A continuación, se presenta la función de distribución para una variable aleatoria \\(X\\), definida sobre un espacio de probabilidad.\n\n\n2.3.1 Función de distribución\nSea \\(X\\) una variable aleatoria real definida sobre el espacio de probabilidad \\((\\Omega, \\mathfrak{F}, P)\\). La función \\(F_x(\\cdot)\\) definida sobre \\(\\mathbb{R}\\) a través de \\[\nF_X(x) := P_X((-\\infty, x]) = P(X \\leq x)\n\\tag{2.6}\\]\n\n\nEjemplo 2.3  \n\n\n\n\n\n\nLanzamiento de un dado\n\n\n\n\n\nSea \\(X\\) es una variable aleatoria discreta que representa el resultado de lanzar un dado justo de 6 caras. El conjunto de valores posibles es: \\[ D =\\{ 1,2,3,4,5,6 \\}.\\]\nLa función de densidad de probabilidad \\(f_X (x)\\) se define como: \\[ f_X (x) =\n    \\left\\{ \\begin{array}{lcc} \\frac{1}{6} & \\text{si } \\ \\ \\ x \\in D \\\\ \\\\ 0 & \\text{en otro caso}  \\end{array} \\right . \\]\nEsto significa que cada cara del dado tiene una probabilidad de \\(\\frac{1}{6}\\), y cualquier valor fuera del conjunto \\(D\\) tiene probabilidad \\(0\\).\nLa función de distribución acumulada \\(F_X (x)\\) se determina sumando las probabilidades de todos los valores menores o iguales a \\(x\\). Por lo tanto, \\[ F_X (x) =\n    \\left\\{ \\begin{array}{lcc} 0, & \\text{si } \\ \\ \\ x &lt; 1 \\\\\n    \\frac{1}{6}, & \\text{si } \\ \\ \\ 1  \\leq x &lt;2 \\\\ \\\\\n    \\frac{1}{6}, & \\text{si } \\ \\ \\ 2 \\leq x &lt; 3 \\\\ \\\\\n     \\frac{1}{6}, & \\text{si } \\ \\ \\ 3 \\leq x &lt;4 \\\\  \\\\\n     \\frac{1}{6}, & \\text{si } \\ \\ \\ 4 \\leq x &lt;5 \\\\  \\\\\n     \\frac{1}{6}, & \\text{si } \\ \\ \\  x \\geq 6 \\\\ \\\\\n     \\end{array} \\right . \\]\n\n\n\n\n\n\n\n\n\n2.3.2 Variable aleatoria discreta\nUna variable aleatoria \\(X\\) se dice que es discreta si su conjunto de valores posibles es un conjunto numerable.\n\n2.3.2.1 Funcion de distribución de una variable aleatoria discreta\n\nDefinición 2.14 Para una variable aleatoria \\(X\\) la función de densidad, se denota por \\(f_X(\\cdot)\\) y esta definida sobre el conjunto de valores posibles \\(D =\\{x_1,x_2,\\dots,x_n\\}\\) de la siguiente manera,\n\\[\nf_X(x)= \\begin{cases}P(X=x) & \\text{ si } x \\in D ,\\\\\n          0 & \\text{ cualquier otro caso. }\\end{cases}\n\\]\nSi \\(X\\) es una variable aleatoria , la función \\(f_X (\\cdot)\\) es la derivada de \\(F_X\\), definida en el conjunto de los números reales, si cumple las siguientes condiciones:\n\nLa función de distribución \\(F_X()\\) es creciente, es decir, si \\(x&lt;y\\) entonces se cumple que \\(F_X (x) \\leq F_X (y).\\)\nLa función \\(F_X (\\cdot)\\) es continua por la derecha, es decir, \\(F_X(x^+) = \\lim_{h \\to \\ 0^+} F_X ( x + h) = F_X ( x )  \\ \\ \\text{para todo x en }  \\ \\ \\mathbb{R}.\\)\nLa función de distribución tiene límites bien definidos en los extremos de su dominio: \\(F_X(x^+) = \\lim_{h \\to \\ \\infty} F_X ( x ) = 1 \\ \\ \\text{y} \\  \\  F_X(x) = \\lim_{h \\to \\ -\\infty} F_X ( x ) = 0.\\)\n\n\n\nDefinición 2.15 (Variable aleatoria continua) La variable aleatoria real \\(X\\), se dice que es absolutamente continua si y solo si existe una función real no negativa e integrable \\(f_X(\\cdot)\\) tal que, para todo \\(x \\in \\mathbb{R}\\), se cumple que: \\[\nF_X(x) = \\int_{-\\infty}^{x} f_X(u) \\, du.\n\\tag{2.7}\\]\nLa función \\(f_X(\\cdot)\\) en (2.7) se denomina función de densidad de probabilidad, o simplemente, función de densidad de la variable aleatoria continua \\(X\\).\n\n\n\n2.3.2.2 Función de distribución de una variable aleatoria continua.\n\nSea \\(X\\) una variable aleatoria continua con función de densidad \\(f_X (\\cdot)\\), se define la función de distribución, \\(F_X (\\cdot)\\), como:\n\\[\nF_X (x) =  \\int_{-\\infty}^{x} f_X (u) \\ \\ du.\n\\]\n\n\nUn vector aleatorio es una generalización del concepto de variable aleatoria a múltiples dimensiones.\n\n\nDefinición 2.16 (Vector aleatorio) Sean \\(X_1,X_2,\\dots ,X_n\\) variables aleatorias reales definidas sobre el mismo espacio de probabilidad \\((\\Omega, \\mathfrak{F}, P)\\). Un vector aleatorio es una función definida para cada \\(\\omega \\in \\Omega\\), \\[\nX(\\omega) := (X_1(\\omega),X_2(\\omega),\\dots,X_n(\\omega))\n\\tag{2.8}\\]\n\n\nEjemplo 2.4  \n\n\n\n\n\n\nEjemplo de un vector aleatorio\n\n\n\n\n\nSea \\(X\\) un vector aleatorio de dimensión \\(n = 4\\), donde cada componente sigue una distribución uniforme entre 0 y 1. Es decir,\n\\[ X =\\begin{bmatrix}\nX_1 \\\\\nX_2 \\\\\nX_3 \\\\\nX_4\n\\end{bmatrix}, \\ \\ X_i \\backsim U(0,1) \\ \\ \\ \\text{para} \\ \\ i=1,2,3,4.\\]\nAl generar este vector en R se obtiene,\n\n\nCódigo\nset.seed(123)\nvector_aleatorio &lt;- runif(4)\nprint(vector_aleatorio)\n# [1] 0.2875775 0.7883051 0.4089769 0.8830174\n\n\nPor lo tanto, \\[\nX =\\begin{bmatrix}\n0.2875775 \\\\\n0.7883051 \\\\\n0.4089769 \\\\\n0.8830174\n\\end{bmatrix}\n\\]\n\n\n\n\n\nEn el caso de vector aleatorio \\(X = (X_1,X_2, \\dots, X_n)\\), el valor esperado se define como un vector de expectativas \\(E[X] = (E[X_1],E[X_2], \\dots, E[X_n]).\\) Por otro lado, la varianza y la covarianza de \\(X\\) se describen mediante la matriz de covarianza, \\(\\text{Cov}(X),\\) la cual es una matriz simétrica que captura la variabilidad conjunta entre las componentes del vector.\nEste enfoque permite analizar y modelar estructuras multivariadas en diversos contextos probabilísticos y estadísticos (Casella y Berger 2002).\n\n\n\n\n2.3.3 Distribución de un vector aleatorio\nSea \\(X\\) un vector aleatorio. La medidad probabilidad de un vector aleatorio se define de la siguiente manera: \\[\nP_X(B) := P((X_1,\\dots, X_n) \\in B )\n\\] donde \\(B \\subseteq \\mathbb{R^n}\\) y se conoce como distribución de un vector aleatorio \\(X\\).\n\n\n2.3.4 Función de distribución conjunta\nSea \\(X\\) un vector aleatorio. La función de distribución conjunta de un vector aleatorio \\(X\\) está dada por : \\[\nF_X(x_1,\\dots, x_n) := P(X_1 \\leq x_1,X_2 \\leq x_2, \\dots, X_n \\leq x_n).\n\\] esto es para todo \\((x_1,x_2,\\dots, x_n) \\in \\mathbb{R^n}\\), en la literatura es conocida como la función de distribución conjunta de las variables aleatorias \\(X_1,\\dots,X_n\\), o simplemente como la función de distribución del vector aleatorio \\(X\\).\n\n\n\n\n\nCasella, G, y R Berger. 2002. «Statistical Inference. 2aed». Estados Unidos: Thompson Learning.\n\n\nCharles, M, J Grinstead, y L Snell. 1997. «Introduction to probability». American Mathematical Society.\n\n\nRoss, Sheldon M. 2014. Introduction to probability models. Academic press.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Nociones basicas de Probabilidad</span>"
    ]
  },
  {
    "objectID": "Estadistica.html",
    "href": "Estadistica.html",
    "title": "3  Algunas nociones de Estadística",
    "section": "",
    "text": "3.0.0.1 Muestra aleatoria\nEn estadística, una población se refiere al conjunto completo de observaciones que son de interés para un estudio o investigación. Sin embargo, en muchos casos, es imposible o poco práctico obtener datos de cada elemento de la población. Lo que lleva a definir el concepto de una muestra.\nSean \\(X_1,\\dots, X_n\\) variables aleatorias independientes, cada una con la misma distribución de probabilidad conjunta \\(f(x)\\). Entonces se define \\(X_1,\\dots, X_n\\) como una muestra aleatoria con su distribución de probabilidad conjunta como\n\\[\nf(x_1,x_2,\\cdot, x_n) = f(x_1)f(x_2) \\dots f(x_n)\n\\]\nLas técnicas para generalizar desde una muestra hasta una población se congregan dentro de la rama de la disciplina llamada estadística inferencial.\nPara que las inferencias que hacemos sobre una población a partir de una muestra sean válidas, es crucial que la muestra sea representativa de esa población. El sesgo en una muestra ocurre cuando ésta no refleja adecuadamente las características del conjunto total, lo que puede llevar a conclusiones incorrectas. Para evitar este problema, es esencial seleccionar una muestra aleatoria, ya que este método garantiza que todos los elementos de la población tengan la misma probabilidad de ser elegidos, asegurando la independencia de las observaciones y minimizando el riesgo de sesgo.\nPor ejemplo, la media muestral, considerada como estadístico (antes de seleccionar una muestra o realizar un experimento), está denotada por \\(\\bar{X}\\); el valor calculado de este estadístico es \\(\\mu\\).\nEl propósito al seleccionar muestras aleatorias consiste en obtener información acerca de los parámetros desconocidos de la población. A partir de estas muestras aleatorias se obtiene un único valor que sirve como una estimación puntual. Se denotará este parámetro puntual con la letra griega \\(\\theta\\).",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "Estadistica.html#medidas-de-tendencia-central",
    "href": "Estadistica.html#medidas-de-tendencia-central",
    "title": "3  Algunas nociones de Estadística",
    "section": "3.1 Medidas de tendencia central",
    "text": "3.1 Medidas de tendencia central\n\nDefinición 3.3 (Media) Sea \\(X\\) una variable aleatoria discreta con distribución de probabilidad \\(f_X(x)\\). La media o valor esperado de \\(X\\), se denota por \\(\\mu\\) o \\(E[X]\\), y se define como, \\[\\mu = E[X] = \\sum x_i f_x (x_i). \\] Con función de probabilidad \\(f_X(x_i)\\) .\nPara una variable aleatoria continua \\(X\\), con función de densidad \\(f(x)\\), se define como, \\[\\mu = \\mathrm E[X]=\\int_{-\\infty}^\\infty x f(x)dx .\\]\n\n\nDefinición 3.4 (Cuantil) Para una variable aleatoria \\(X\\), o su distribución acumulada correspondiente, se denomina cuantil \\(q-\\text{ésimo}\\), simbolizado como \\(\\xi_q\\), al valor mínimo \\(\\xi\\) que satisface la condición \\(F_x(\\xi_q) \\geq q\\).\n\n\nDefinición 3.5 (Mediana) La mediana de una variable aleatoria \\(X\\), notada como \\(\\text{med}_X\\) o \\(\\xi_{0.5}\\) , corresponde al cuantil \\(0.5\\).\n\n\nEjemplo 3.1  \n\n\n\n\n\n\nIngresos mensuales\n\n\n\n\n\nUn investigador analiza los ingresos mensuales (en miles de dólares) de una población: \\(X=\\{2,3,3,4,5,8,10,12,15,18\\}\\).\nLa media es el promedio de los datos:\n\\[\\mu  = \\dfrac{2 + 3 + 3 + 4 + 5 + 8 + 10 +12 + 15 + 18}{10} = \\dfrac{80}{10} = 8.\\] El ingreso promedio de la población es 8 mil dólares mensuales.\nLa mediana se determina ordenando los datos de menor a mayor. En el caso de un conjunto con un número par de elementos \\((N=10)\\), se calcula como el promedio de los dos valores centrales.\n\\[\\text{Mediana} = \\dfrac{5 + 8}{2} \\ \\ = \\ \\ 6.5.\\]\nEl ingreso central en la población es \\(6.5\\) mil dólares.\n\n\n\n\n\nMediante el muestreo, se busca obtener algunos estimadores de ciertos estadísticos poblacionales, como la media y la varianza, a través de la media muestral y la varianza muestral. Estos estimadores se calculan a partir de los datos de una muestra y sirven para hacer inferencias sobre la población.\n\n\nDefinición 3.6 (Media muestral) Sean \\(x_1,x_2, \\dots, x_n\\) muestras aleatorias. Se define la media muestral como,\n\\[ \\bar{X}  =\\frac{1}{n}\\sum_{i=1}^n x_i. \\]\n\n\nDefinición 3.7 (Mediana muestral) Sea \\(X\\) una muestra aleatoria de tamaño \\(n\\) y \\(x_i\\) los valores de los datos ordenados de menor a mayor. La mediana \\(\\tilde{x}\\) es el valor que satisface: \\[\n\\tilde{x}= \\begin{cases} x_{\\frac {(n+1)}{2}} & \\text{ si } n \\text{ es par}  ,\\\\ \\frac{1}{2} \\left(x_{\\frac{n}{2}} +  x_{\\frac{n}{2} +1} \\right)  & \\text{ si } n \\text{ es impar}\n  \\end{cases}.\n\\tag{3.1}\\]\n\n\nEjemplo 3.2  \n\n\n\n\n\n\nSelección de una muestra aleatoria\n\n\n\n\n\nAl selecciona una muestra aleatoria de 5 elementos: \\(X_\\text{muestra} = \\{ 3,5,8,10,15 \\}.\\)\nLa media muestral se calcula como:\n\\[\\bar{X} = \\frac{3 + 5 + 8 + 10 + 15 }{5} = \\frac{41}{5} = 8.2. \\]\nEl ingreso promedio estimado para esta muestra es \\(8.2\\) mil dólares.\nLa mediana de la muestra se encuentra directamente porque hay un número impar de elementos \\((n = 5).\\)\n\\(\\text{Mediana muestral} = 8\\).\nEl ingreso central es 8 mil dólares.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "Estadistica.html#medidas-de-localización",
    "href": "Estadistica.html#medidas-de-localización",
    "title": "3  Algunas nociones de Estadística",
    "section": "3.2 Medidas de localización",
    "text": "3.2 Medidas de localización\n\nLa varianza de una variable aleatoria es una medida de dispersión que refleja, en promedio, qué tan alejados están los valores de la variable respecto a su media.\n\n\nDefinición 3.8 (Varianza) La varianza de una variable aleatoria \\(X\\), se denota por \\(\\mathrm{Var}(X)\\) o \\(\\sigma_x^2\\), se define como la siguiente esperanza, si está existe, \\[ \\mathrm{Var}[X]=  (E[X]-E[X])^2.\\]\nCuando \\(X\\) es una variable aleatoria discreta con función de probabilidad \\(f(x)\\) y esperanza finita \\(\\mu\\), entonces la varianza se define por, \\[ \\mathrm{Var}[X]=  \\sum_i (x_i - \\mu)^2.\\]\nSi \\(X\\) es una variable aleatoria absolutamente continua con función de probabilidad \\(f(x)\\) y esperanza finita \\(\\mu\\), entonces la varianza se define para los puntos \\(x= \\{x_1,x_2,\\dots x_n\\}\\) por,\n\\[\\mathrm{Var}[X]= \\int_{-\\infty}^\\infty (x-\\mu)^2 f(x) dx.\\]\n\n\nObservación. Para calcular la varianza se necesita conocer primero la esperanza.\n\n\nEl siguiente teorema presenta algunas propiedades que cumple la varianza.\n\n\n\nTeorema 3.1 Sean \\(X\\) una variable aleatoria con varianza finita, y sea \\(c \\in \\mathbb{R}\\) . Entonces:\n\n\\(\\mathrm{Var}[X] \\geq 0.\\)\n\\(\\mathrm{Var}[c] = 0.\\)\n\\(\\mathrm{Var}[cX] = c^2 \\mathrm{Var}[X].\\)\n\\(\\mathrm{Var}[X+c] =  \\mathrm{Var}[X].\\)\n\\(\\mathrm{Var}[X] = 0 \\ \\ \\text{si y solo si} \\ \\ P(X= E[X])=1 .\\)\n\n\n\nPrueba. Ver (Castañeda, Arunachalam, y Dharmaraja 2012).\n\n\nDefinición 3.9 (Desviación estándar) A la raíz cuadrada positiva de \\(\\mathrm{Var}[X]\\) se le llama desviación estándar, y se le denota naturalmente por \\(\\sigma_X\\) o por \\(+ \\sqrt{\\mathrm{Var}[X]}\\).\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de Rentabilidades Anuales\n\n\n\n\n\nUn analista financiero estudia las rentabilidades anuales de una acción dadas en porcentaje para una población:\n\\(X= \\{ 2, 4, 6, 8, 10 \\}\\)\nLa media poblacional es:\n\\[\\mu = \\dfrac{ 2 + 4 + 6 + 8 + 10 }{ 5 } = 6.\\]\nDiferencias respecto a la media:\n\\((2-6)^2 = 16, \\ \\  (4-6)^2 = 4, \\ \\  (6-6)^2 = 0, \\ \\  (8-6)^2 = 4, \\ \\ (10-6)^2 = 16.\\)\nPor lo tanto, la varianza esta dada por,\n\\[ \\sigma^2 = \\dfrac{16 + 4 + 0 + 4 + 16   }{5} = \\dfrac{40}{5} = 8. \\] La varianza poblacional de las rentabilidades es \\(8\\), lo que indica una dispersión moderada respecto a la media.\nLa desviación estándar es,\n\\[\n\\sigma \\ \\ = \\ \\ \\sqrt{8}  \\ \\  \\thickapprox \\ \\ 2.83.\n\\] La desviación estándar indica que, en promedio, las rentabilidades se desvían \\(2.83\\) puntos porcentuales de la media.\n\n\n\n\n\nDefinición 3.10 (Varianza muestral) Sean \\(X_1,X_2, \\dots, X_n\\) muestras aleatorias. Se define la varianza muestral para \\(n&gt;1\\), \\[ S_n^2=S^2=\\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\bar{X})^2   .\\]\n\n\nObservación. La media y la varianza muestral tienen la característica de ser estimadores insesgados para la media y la varianza, respectivamente, de una distribución cualquiera.\n\n\nDefinición 3.11 (Desviación estándar muestral) La desviación estándar muestral es la raíz cuadrada de la varianza muestral. Y se denota por \\[s = \\sqrt{s_n^2}. \\]\n\n\nObservación. La varianza muestral es un estimador insesgado de la varianza, ya que su valor esperado coincide con la varianza. Sin embargo, la desviación estándar muestral no es un estimador insesgado de la desviación estándar poblacional. Aunque se calcula a partir de un estimador insesgado (la varianza muestral), al tomar la raíz cuadrada se introduce un sesgo, especialmente notable en muestras pequeñas. Existen métodos adicionales para corregir parcialmente este sesgo en la desviación estándar, pero suelen ser más complejos y dependen del tamaño de la muestra.\n\n\n\n\n\n\n\n\nAnálisis de Rentabilidades Anuales\n\n\n\n\n\nAl seccionar una muestra aleatoria de rentabilidades:\n\\(X_\\text{muestra} = \\{4,6,10 \\}.\\) La media muestral es: \\[\\bar{X} = \\dfrac{4 + 6 + 10}{3} =  6.67.\\]\nDiferencias respecto a la media: \\[(4- 6.67)^2 = 7.11, \\ \\ (6- 6.67)^2 = 0.44, \\ \\ (10- 6.67)^2 \\thickapprox  11.11.\\]\nLa varianza muestral,\n\\[s^2 = \\dfrac{7.11 + 0.44 + 11.11 }{ 2} =  \\frac{18.66 }{2} \\thickapprox 9.33 .\\]\nLa desviación estándar muestral es,\n\\[ s = \\sqrt{9.33} \\thickapprox 3.05 .\\]\nLas rentabilidades de la muestra se desvían en promedio 3.05 puntos porcentuales de la media muestral.\n\n\n\n\n\nLa distribución empírica es una representación de los datos observados en la muestra, organizada para mostrar cómo se distribuyen los valores de una variable en dicha muestra. Esta distribución se basa exclusivamente en los datos reales recopilados, sin asumir ningún modelo teórico o de probabilidad. Es una forma de visualizar cómo se comportan los datos en la muestra y ayuda a calcular los estimadores muestrales.\nSin embargo, los estimadores muestrales no son valores fijos; varían de una muestra a otra. La distribución muestral de un estadístico (como la media muestral o la varianza muestral) describe cómo se distribuyen los valores del estadístico en múltiples muestras extraídas de la misma población. Esta distribución muestral depende de varios factores, como la distribución de la población, el tamaño de las muestras y el método de selección de las muestras.\n\nLos estimadores muestrales permiten inferir información sobre la población basándonos en la muestra, y a continuación se presentan los principales estimadores muestrales como la media muestral y la varianza muestral, que son ejemplos claves en la estimación de parámetros poblacionales.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "Estadistica.html#medidas-de-dispersión-de-una-muestra",
    "href": "Estadistica.html#medidas-de-dispersión-de-una-muestra",
    "title": "3  Algunas nociones de Estadística",
    "section": "3.3 Medidas de dispersión de una muestra",
    "text": "3.3 Medidas de dispersión de una muestra\n\n3.3.1 Rango muestral.\n\nSea \\(X\\) una variable aleatoria y \\(x_1 , \\dots , x_n\\) una muestra de los valores observados de \\(X\\), el rango muestral \\(R\\) se define como: \\[\nR = x_\\mathrm{max} - x_\\mathrm{min},\n\\] donde \\(x_\\mathrm{max}\\) es el valor máximo de la muestra y \\(x_\\mathrm{min}\\) es el valor mínimo.\n\n\n\n\n\n\nLos datos multivariados se refieren a conjuntos de datos que incluyen más de una variable aleatoria. Por ello, se definen a continuación algunas propiedades que relacionan dos o mas variables aleatorias.\n\nLa covarianza, \\(\\gamma_{XY}\\), y la correlación, \\(\\rho_{XY}\\), son parámetros que miden la relación lineal entre dos variables. Se definen a continuación.\n\nDefinición 3.12 (Covarianza) Para dos variables aleatorias \\(X\\) y \\(Y\\) con medias \\(\\mu_X = E[X]\\) y \\(\\mu_Y= E[Y]\\), la covarianza de \\(X\\) e \\(Y\\) se denota por \\(\\mathrm{Cov}[X,Y]\\), se define como: \\[\n\\gamma_{XY}=\\mathrm E[(X-\\mu_X)(Y-\\mu_Y)].\n\\tag{3.2}\\] siempre que las esperanzas \\(E[X]\\), \\(E[Y]\\) y \\(E[XY]\\) son finitas.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "Estadistica.html#sec-correlacion",
    "href": "Estadistica.html#sec-correlacion",
    "title": "3  Algunas nociones de Estadística",
    "section": "3.4 Correlación",
    "text": "3.4 Correlación\n\nPara dos variables aleatorias \\(X\\) y \\(Y\\), la covarianza de notada por \\(\\rho_{XY}\\) se define por, \\[\n\\rho_{XY} = \\dfrac{\\gamma_{XY}}{\\sigma_X \\sigma_Y}.\n\\tag{3.3}\\] donde es la a covarianza entre \\(X\\) y \\(Y\\) definido en (3.2), \\(\\sigma_X\\) es la desviación estándar de la variable \\(X\\) y \\(\\sigma_Y\\) desviación estándar de la variable \\(Y\\).\n\nLa covarianza es el valor esperado o promedio teórico del producto cruzado. Representa cómo dos variables se relacionan. Sin embargo, interpretar su magnitud puede es complicado, ya que la covarianza depende de las unidades de las variables involucradas.\nPara hacer la interpretación más sencilla, se utiliza la correlación, que es una versión estandarizada de la covarianza. El coeficiente de correlación tiene la ventaja de ser adimensional y siempre toma valores \\(-1 \\leq \\rho_{XY} \\leq 1,\\) independientemente de las unidades de las variables. Esto facilita la comparación y comprensión de la relación entre dos variables aleatorias \\(X\\) e \\(Y\\).\n\n\nDefinición 3.13 (Coeficiente de correlación) Dado un conjunto de datos bivariados, el coeficiente de correlación de muestra, denotado por \\(r_{XY},\\) se define por,\n\\[\nr_{XY} = \\frac{ \\sum_{i=1}^{n} (X_i - \\overline{X})(Y_i - \\overline{Y}) }{\\sqrt{\\sum_{i=1}^{n} (X_i - \\overline{X})^2} \\cdot \\sqrt{\\sum_{i=1}^{n} (Y_i - \\overline{Y})^2}} \\ \\ .\n\\tag{3.4}\\]\nLos valores de \\(r_{X,Y}\\) comparten la propiedad con el coeficiente de correlación de población, \\(-1 \\leq r_{XY} \\leq 1.\\)\n\n\nLa correlación puede ser positiva, negativa o nula:\n\nCorrelación positiva: A medida que una variable aumenta, la otra variable también tiende a aumentar.\nCorrelación negativa: A medida que una variable aumenta, la otra variable tiende a disminuir.\nCorrelación nula: No hay una relación lineal evidente entre las dos variables.\n\nUn diagrama de dispersión es una representación gráfica en la que pares ordenados se muestran como puntos en un plano cartesiano \\((x_1,y_2),(x_2,y_2),\\dots, (x_n,x_n).\\) La Figura 3.1 ilustra varios ejemplos de diagramas de dispersión para diferentes pares de variables. En la Figura 3.1 a) se observa una fuerte correlación lineal positiva entre a medida que aumenta, tiende a aumentar también, y viceversa.\nLos datos de la Figura 3.1 a) sugieren una correlación positiva moderada entre \\(X\\) e \\(Y\\), similar a la relación observada en la Figura 3.1 a). Sin embargo, a diferencia de la correlación más fuerte en la Figura 3.1 a), en este caso, para un valor dado de \\(x\\), existe una mayor dispersión en los valores plausibles de \\(y\\), lo que indica que la relación entre las variables es menos predecible y presenta mayor variabilidad.\nA diferencia de las Figura 3.1 a) y Figura 3.1 b), la Figura 3.1 c) presenta un ejemplo de una correlación negativa notablemente fuerte, donde los valores altos de \\(X\\) se asocian con valores bajos de \\(Y\\), y viceversa. Se observa que la mayoría de los puntos se encuentran en los cuadrantes superior izquierdo e inferior derecho, lo que refuerza la relación inversa entre ambas variables. La Figura 3.1 d) muestra un ejemplo en el que no parece haber correlación detectable entre \\(X\\) e \\(Y\\).\nLa Figura 3.1 e) muestra un ejemplo de una relación lineal positiva, donde todos los puntos se alinean exactamente sobre una línea recta. Por último, la Figura 3.1 f) presenta una situación distinta en la que existe una relación entre \\(X\\) e \\(Y\\), pero no es lineal. En este caso, los valores de Y tienden a ser altos cuando los valores de \\(X\\) son extremos, ya sea muy bajos o muy altos. Sin embargo, para valores de X cercanos al centro del rango (es decir, alrededor de cero), los valores de Y tienden a ser bajos.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) (a) X e Y correlacionados positivamente\n\n\n\n\n\n\nFigura 3.1: (a)-(f) son diagramas de dispersión con una variedad de estructuras de correlación.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "Estadistica.html#estandarización",
    "href": "Estadistica.html#estandarización",
    "title": "3  Algunas nociones de Estadística",
    "section": "3.5 Estandarización",
    "text": "3.5 Estandarización\n\nLa estandarización de datos en estadística es un proceso esencial para comparar y analizar datos provenientes de diferentes fuentes o escalas. Este procedimiento transforma los datos a una escala común sin distorsionar las diferencias en los rangos de valores. La estandarización de una variable aleatoria es el proceso de transformar una variable aleatoria \\(X\\) con media \\(\\mu\\) y desviación estándar \\(\\sigma\\) en una nueva variable aleatoria \\(Z\\) que tenga una media de 0 y una desviación estándar de 1. El proceso de estandarización se realiza utilizando la siguiente fórmula:\n\\[ Z =  \\dfrac{X - \\mu}{\\sigma} . \\tag{3.5}\\]\nEl proceso usando (3.5) es particularmente útil en varias aplicaciones estadísticas y de aprendizaje automático. En el ámbito del aprendizaje automático, existen algoritmos de clasificación y de regresión donde asumen que los datos están estandarizados. Esto es importante porque la mayoría de estos algoritmos utilizan distancias euclidianas entre puntos en su procesamiento. Si los datos no están estandarizados, las características con escalas más grandes pueden dominar la medida de distancia y, en consecuencia, podría negativamente el rendimiento del modelo.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "Estadistica.html#normalización",
    "href": "Estadistica.html#normalización",
    "title": "3  Algunas nociones de Estadística",
    "section": "3.6 Normalización",
    "text": "3.6 Normalización\n\nLa normalización de datos en estadística es un proceso que ajusta los valores de diferentes variables a una escala común, facilitando la comparación directa y el análisis adecuado. Este procedimiento es relevante cuando se trabaja con datos que tienen diferentes unidades o rangos, ya que permite que todas las variables contribuyan equitativamente en análisis y modelos estadísticos.\nExisten varios métodos de normalización, pero uno de los más comunes es la normalización min-max. Este método transforma los valores de una variable para que se ubiquen dentro de un rango específico, típicamente entre 0 y 1. La fórmula para la normalización min-max es la siguiente:\n\\[ X_i^\\prime = \\dfrac{X_i- X_{min}}{X_{\\max} - X_{\\min}}, \\ \\ \\ \\ \\ \\ \\ \\  i=1,...,n. \\tag{3.6}\\]\nLa normalización min-max en (3.6) es útil en aplicaciones donde se necesita preservar las relaciones entre los valores originales, como en algoritmos de aprendizaje automático que utilizan distancias entre datos. Otro método de normalización es la normalización z-score, también conocida como estandarización.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "Estadistica.html#sec-colab",
    "href": "Estadistica.html#sec-colab",
    "title": "3  Algunas nociones de Estadística",
    "section": "3.7 Entorno para el manejo de recursos computacionales en Ciencia de Datos",
    "text": "3.7 Entorno para el manejo de recursos computacionales en Ciencia de Datos\n\nLa computación en la nube es un entorno basado en servicios de internet que permite acceder a software, datos y servicios desde cualquier lugar, siempre se tenga un dispositivo con conexión a la web. Debido a los altos recursos que ofrece el uso de esta tecnología, destaca en particular Google Colab.\nGoogle Colab, también conocido como Colaboratory, es un entorno gratuito basado en Jupyter Notebook que se ejecuta en los servidores de Google en la nube. No requiere instalación ni configuración de Python. Además, ofrece acceso gratuito a hardware como CPU, GPU y TPU. El código se puede compartir de manera similar a Google Drive.\n\n\n\n\n\n\nFigura 3.2: Google Colab\n\n\n\nPara acceder a Google Colab, ingresa a https://colab.research.google.com/ con una cuenta de gmail.\n\n\n\n\n\nCastañeda, Liliana Blanco, Viswanathan Arunachalam, y Selvamuthu Dharmaraja. 2012. Introduction to probability and stochastic processes with applications. John Wiley & Sons.\n\n\nPütter, Johann Stephan, y Gottfried Achenwall. 1750. Elementa iuris naturae. Schmidt.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Algunas nociones de Estadística</span>"
    ]
  },
  {
    "objectID": "series.html",
    "href": "series.html",
    "title": "4  Series de tiempo",
    "section": "",
    "text": "4.0.1 Serie de tiempo",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#sec-autocorrelación",
    "href": "series.html#sec-autocorrelación",
    "title": "4  Series de tiempo",
    "section": "4.1 Autocorrelación",
    "text": "4.1 Autocorrelación\n\nDentro del interés de las series de tiempo, como el análisis de la media y la varianza para dos variables aleatorias \\(X(t_1)\\) y \\(X(t_2)\\) para \\(t_1,t_2 \\in T.\\) Es la forma en que se relacionan dos valores dentro de la misma serie de tiempo esto se refiere a la correlación que se puede ver en la misma serie con la autocorrelación y denota por la expresión (4.2).\n\\[\n\\gamma(t_1,t_2):=\\mathrm{E}[(X(t_1)-\\mu(t_1))(X(t_2)-\\mu(t_2))]\n\\tag{4.1}\\] y \\[\n\\rho(t_1,t_2):= \\frac{\\gamma(t_1,t_2)}{\\sigma(t_1)\\sigma(t_2)}\n\\tag{4.2}\\] donde la expresión en (4.1) calcula la autocovarianza.\n\n\n\n\n\n\n\n\nAutocorrelación : Datos sobre el lince canadiense\n\n\n\n\n\nLa Figura 4.2 (a) muestra la cantidad anual de linces canadienses atrapados en el distrito del río Mackenzie en el noroeste de Canadá durante el período \\(1821-1934\\). Las autocorrelaciones de la población de los linces canadienses se presentan en la Figura 4.2 (b).\n\n\n\n\n\n\n\n\n\n\n\n(a) Datos sobre el lince canadiense\n\n\n\n\n\n\n\n\n\n\n\n(b) Autocorrelación de la muestra\n\n\n\n\n\n\n\nFigura 4.2: Gráfico de autocorrelaciones de la población de linces (1820 - 1934).",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#sec-series-estacionales",
    "href": "series.html#sec-series-estacionales",
    "title": "4  Series de tiempo",
    "section": "4.2 Series de tiempo estacionales",
    "text": "4.2 Series de tiempo estacionales\n\nLas series de tiempo, al ser procesos estocásticos, poseen sus mismas propiedades, como es el caso de las estacionalidad. En consecuencia, se define en seguida un proceso estrictamente estacionario.\n\n\nDefinición 4.3 (Proceso estrictamente estacionario) Un proceso es estrictamente estacionario si la distribución conjunta de cualquier conjunto de observaciones es invariante bajo desplazamientos en el tiempo. Para cualquier \\(t_1,t_2, \\dots,t_n\\) y cualquier desplazamiento \\(h\\), la distribución conjunta de \\((X_{t_1},X_{t_2},\\dots,X_{t_n})\\) es la misma que \\((X_{t_1+h},X_{t_2+h},\\dots,X_{t_n+h})\\)\n\n\nDefinición 4.4 (Estacionariedad por covarianza) La serie de tiempo \\(\\{X(t)\\}\\) donde \\(t \\in T\\) se considera estacionaria por covarianza si\n\n\\(\\mu_{_{X_t}}=\\mathrm E[X(t)] = \\mu\\) (media constante para todo \\(t\\)).\n\\(\\sigma^2_{_{X_t}}=\\mathrm{Var}[X(t)] = \\sigma^2 &lt; \\infty\\) (es decir, una constante finita para todo \\(t\\)).\n\\(\\gamma_{_{X_{t_1},X_{t_2}}}\\) y \\(\\rho_{_{X_{t_1},X_{t_2}}}\\) depende solo de \\(t_2 − t_1\\).",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#sec-ruidob",
    "href": "series.html#sec-ruidob",
    "title": "4  Series de tiempo",
    "section": "4.3 Proceso de ruido blanco",
    "text": "4.3 Proceso de ruido blanco\n\nUn proceso de ruido blanco es clave en el análisis de series de tiempo, ya que representa un proceso completamente aleatorio donde no hay correlación entre observaciones en diferentes tiempos. Esto implica que no existen patrones o dependencias temporales dentro de la serie, lo que lo convierte en un punto de referencia importante en la construcción de modelos.\n\n\nDefinición 4.5 (Proceso de ruido blanco) Se dice que un proceso \\(X_t\\) es ruido blanco si se cumplen las siguientes condiciones:\n\nCada \\(X_t\\) tiene media cero y varianza finita \\(\\sigma^2_X\\).\n\\(X_{t_1}\\) y \\(X_{t_2}\\) no son correlacionadas si \\(t_1=t_2\\).\n\n\n\nUn proceso de ruido blanco no tiene memoria, lo que significa que el valor en un tiempo \\(t\\) no ofrece ninguna información sobre los valores en otros tiempos.\nRepresentación gráfica de los datos y comprobación del ruido blanco.\nSiempre que se ajusta un modelo a un conjunto de datos, primero se debe representar gráficamente los datos y las autocorrelaciones de muestra. Algo que se debe comprobar en estos gráficos es si los datos son simplemente ruido blanco o si muestran una estructura no estacionaria evidente. Una prueba rápida de ruido blanco se basa en los siguientes hechos sobre las autocorrelaciones de muestra de los datos de ruido blanco.\n\\[\nE\\left[ \\hat{\\rho}_k \\right] \\approx 0 \\quad \\text{para} \\quad k \\neq 0.\n\\]\nEl error estándar de \\(\\hat{\\rho}_k\\) es aproximadamente \\(1/\\sqrt{n}\\), \\(k \\neq 0\\), por lo que para \\(n\\) moderadamente grande, los \\(\\hat{\\rho}_k\\) deberían ser pequeños. \\(\\hat{\\rho}_{k_1}\\) y \\(\\hat{\\rho}_{k_2}\\) son esencialmente no correlacionados cuando \\(k_1 \\neq k_2\\).  Es común acompañar las gráficas de autocorrelaciones muéstrales que podrían provenir de ruido blanco con líneas límite \\((95\\%)\\) en \\(\\pm 2/\\sqrt{n}\\).\n\n\n\n\n\n\n\n\nRepresentacion grafica de un ruido blanco\n\n\n\n\n\nLa Figura 4.4 muestra una realización de longitud \\(n = 150\\) a partir de un proceso de ruido blanco generado por la librería (tswge) en R.\n\nCódigo\n  library(tswge)\n  # Generar una realización de ruido blanco\n  set.seed(147)\n  x = gen.arma.wge(n = 150, phi = 0, theta = 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 4.3: Gráfica de un ruido blanco\n\n\n\nLa Figura 4.4 es coherente con el ruido blanco en el sentido de que no hay patrones cíclicos ni desviaciones y los datos simplemente parecen ser aleatorios sin correlación con otros valores.",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#densidad-espectral",
    "href": "series.html#densidad-espectral",
    "title": "4  Series de tiempo",
    "section": "4.4 Densidad espectral",
    "text": "4.4 Densidad espectral\n\nPara identificar el contenido en frecuencias de una serie temporal estacionaria, se utiliza el espectro, o en su forma estandarizada, la densidad espectral. Esta herramienta es fundamental para detectar el comportamiento subyacente de las frecuencias en los datos de series temporales estacionarias.\n\n\nDefinición 4.6 (Especto) Sea \\(( X_t )\\) una serie temporal estacionaria con autocovarianza \\(( \\gamma_k )\\) y autocorrelación \\((\\rho_k)\\). Entonces para \\(|f| \\leq 0.5\\) :\nEl espectro de \\(( X_t )\\) está definido por, \\[\n    P_X(f) = \\sum_{k=-\\infty}^{\\infty} e^{-2\\pi ifk} \\gamma_k.\n\\tag{4.3}\\]\n\n\nDefinición 4.7 (Densidad espectral) Sea \\(( X_t )\\) una serie temporal estacionaria con autocovarianza \\(( \\gamma_k )\\) y autocorrelación \\(( \\rho_k )\\). Entonces para \\(|f| \\leq 0.5\\) :\nLa densidad espectral de \\(( X_t )\\) está definido por \\[\n    S_X(f) = \\sum_{k=-\\infty}^{\\infty} e^{-2\\pi ifk} \\rho_k.\n\\tag{4.4}\\]\n\n\nFormula de Euler. El espectro y la densidad espectral de una serie temporal se definen como funciones de frecuencia. A continuación se indican algunas fórmulas trigonométricas y de variables complejas importantes para completar:\n\n\\(\\sin(- \\theta) = - \\sin (\\theta)\\)\n\\(\\cos( \\theta) = \\cos (- \\theta)\\)\n\\(e^{i \\theta} = \\cos (\\theta) + i \\sin (\\theta)\\)\n\\(e\\^{-i \\theta} = \\cos (\\theta) - i \\sin (\\theta)\\)\n\nUtilizando la fórmula de Euler, se obtienen las fórmulas : \\[\nP_X(f) = \\sigma_X^2 + 2 \\sum_{k=1}^{\\infty} \\gamma_k \\cos(2\\pi fk),\n\\tag{4.5}\\] y \\[\nS_X(f) = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k \\cos(2\\pi fk).\n\\tag{4.6}\\]\nEstas fórmulas enfatizan que el espectro y la densidad espectral son funciones de valores reales, lo cual no es evidente a partir de las ecuaciones (4.3) y (4.4).\n\n\n4.4.1 Estimación de la densidad espectral\n\nDada una realización de longitud \\(n\\) de una serie temporal, no se dispone con suficiente información para calcular la densidad espectral “real” descrita en la ecuación (4.6), que requiere una suma infinita de autocorrelaciones. Además, en un conjunto real de datos de series temporales, las autocorrelaciones “real” no son conocidas. Aunque la ecuación (4.6) involucra una suma infinita de autocorrelaciones \\(\\rho_k\\), solo se cuenta con estimaciones \\(\\hat{\\rho}_k\\) definidas en (3.12). Según (3.10), para una realización de longitud \\(n\\), se puede calcular \\(\\hat{\\rho}_k\\) para \\(k = 1, 2, ..., n-1\\).\n\n\n4.4.1.1 La densidad espectral de la muestra\nLa estimación natural de la densidad espectral se obtiene al sustituir las autocorrelaciones de la muestra en la fórmula para \\(S_X(f)\\). Usando\n\\[\n\\hat{S}_X(f) = 1 + 2 \\sum_{k=1}^{n-1} \\hat{\\rho}_k \\cos(2\\pi f k), \\quad |f| \\leq 0.5\n\\tag{4.7}\\]\nLa estimación en (4.7) es llamada estimación de la densida espectral.",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#sec-AR",
    "href": "series.html#sec-AR",
    "title": "4  Series de tiempo",
    "section": "4.5 Modelo Autorregresivo",
    "text": "4.5 Modelo Autorregresivo\n\n\nDefinición 4.8 (Modelo AR(1)) Se dice que la serie temporal, \\(X_t,\\) satisface un modelo AR(1) si, \\[\nX_t = \\beta + \\phi_1 X_{t-1} + a_t\n\\tag{4.8}\\]\n\ndonde \\(\\phi_1\\) es una constante real distinta de cero y \\(a_t\\) es un proceso de ruido blanco con varianza finita \\(\\sigma_a^2.\\) La constante \\(\\beta = (1- \\phi_1) \\mu\\), se denomina constante de media móvil. En esencia, el modelo AR(1) especifica que el valor del proceso en el momento \\(t\\) depende del valor del proceso en el momento \\(t −1\\), más un componente de ruido aleatorio \\(a_t\\), y una constante \\(\\beta\\).\n\nTeorema 4.1 (Estacionareidad de un AR(1)) Un proceso AR(1) es estacionario si y solo si \\(\\phi_1 &lt; 1\\).\n\n\nPrueba. Vea Woodward, Gray, y Elliott (2017).\n\n\n\n4.5.1 Operador de retroceso de un AR(1)\n\nEl modelo AR(1) se expresa a veces utilizando el operador de retroceso definido por \\(BX_t  = X_{t−1}.\\) Nótese que \\(B_c = c\\) para una constante \\(c\\). El modelo AR(1) mostrado en la ecuación (4.8) se puede escribir como:\n\\[\nX_t= (1-\\phi) \\mu + \\phi X_{t-1} + a_t\n\\tag{4.9}\\]\nLa ecuación (4.8) también se puede expresar de la siguiente forma:\n\\[\nX_t-\\mu - \\phi_1(X_{t-1} - \\mu) = a_t\n\\tag{4.10}\\]\nO , en la notación del operador de desplazamiento hacia atrás:\n\\[\n(1-\\phi_1 B)(X_t-\\mu) = a_t\n\\tag{4.11}\\]\nAlternativamente, también puede ser definido como:\n\\[\n\\phi(B)(X_t - \\mu) = a_t\n\\tag{4.12}\\]\nDonde \\(\\phi (B)\\) es el operado definido como \\(\\phi (B) = 1- \\phi_1 B.\\)\n\n\nObservación. Si un proceso AR(1) \\(X_t\\) tiene media \\(\\mu\\), se puede crear un proceso de media cero \\(\\tilde{X}_t\\) , definiéndolo como \\(\\tilde{X}_t = X_t - \\mu.\\)",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#densidad-espectral-de-un-modelo-ar1",
    "href": "series.html#densidad-espectral-de-un-modelo-ar1",
    "title": "4  Series de tiempo",
    "section": "4.6 Densidad espectral de un modelo AR(1)",
    "text": "4.6 Densidad espectral de un modelo AR(1)\nEn el caso del modelo AR(1), la densidad espectral está dada por,\n\\[\n\\begin{split}\n  S_X(f) &= \\frac{\\sigma_a^2}{\\gamma_0} \\frac{1}{\\left| 1 - \\phi_1 e^{-2 \\pi i f} \\right|^2} \\\\\n        &= \\frac{1 - \\phi_1^2}{\\left| 1 - \\phi_1 e^{-2 \\pi i f} \\right|^2}.\n\\end{split}\n\\tag{4.13}\\]\nUsando la fórmula de Euler, \\(e^{-2\\pi if} = \\cos 2 \\pi if - i \\sin 2\\pi if\\) , el denominador de la ecuación (4.13) se convierte en\n\\[\n\\begin{split}\n  \\left| 1 - \\phi_1 e^{-2 \\pi i f} \\right|^2 &= \\left| 1 - \\phi_1 \\left( \\cos 2 \\pi f - i \\sin 2 \\pi f     \\right) \\right|^2\\\\\n  &= \\left| (1 - \\phi_1 \\cos 2 \\pi f) - i \\phi_1 \\sin 2 \\pi f \\right|^2\\\\\n  &= (1 - \\phi_1 \\cos 2 \\pi f)^2 + (\\phi_1 \\sin 2 \\pi f)^2.\n\\end{split}\n\\tag{4.14}\\]\nporque \\(|a + bi|^2 = a^2 + b^2\\), así, la ecuación (4.13) se puede escribir como,\n\\[\nS_X(f) = \\frac{1 - \\phi_1^2}{(1 - \\phi_1 \\cos 2 \\pi f)^2 + (\\phi_1 \\sin 2 \\pi f)^2}.\n\\tag{4.15}\\]\nEn la ecuación (4.15) hemos simplificado la fórmula para \\(S_X (f )\\) en la ecuación (4.13) para enfatizar el hecho de que \\(S_X( f)\\) es un número real.",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#modelos-ar1-con-raíces-cercanas-a-1",
    "href": "series.html#modelos-ar1-con-raíces-cercanas-a-1",
    "title": "4  Series de tiempo",
    "section": "4.7 Modelos AR(1) con raíces cercanas a +1",
    "text": "4.7 Modelos AR(1) con raíces cercanas a +1\n\nLa Figura 4.4 muestra realizaciones de dos modelos AR(1) con raíces cercanas a uno en valor absoluto. Específicamente, se mostraron realizaciones de modelos AR(1) \\((1 - \\phi_1 B)(X_t - 10) = a_t\\), con \\(\\phi_1 = 0.95\\) y \\(\\phi_1 = 0.99.\\)  Esto se describe indicando que, para \\(\\phi_1 = 0.95\\) y \\(0.99,\\) las autocorrelaciones, \\(\\rho_k = \\phi_1^k,\\) son fuertes (o persistentes). Es decir, las autocorrelaciones siguen siendo sustanciales incluso cuando \\(k\\) es moderadamente grande. Como ejemplo, para \\(\\phi_1 = 0.99,\\) sorprendentemente \\(\\rho_{50} = 0.99^{50} = 0.61.\\) Lo que significa que existe una correlación de \\(0.61\\) entre observaciones separadas por 50 periodos de tiempo.\nEl comportamiento de deambular sostenido aumenta a medida que los valores de \\(\\phi_1\\) se acercan a \\(\\phi_1 = 1.\\) Para \\(\\phi_1 = 1,\\) el modelo no es un modelo AR(1) estacionario porque el valor absoluto de la raíz es igual a uno en lugar de mayor a uno.\n\n\n\n\n\n\n\n\n\n\n\n(a) Realización con φ1 = .95\n\n\n\n\n\n\n\n\n\n\n\n(b) Realización φ1 = .99\n\n\n\n\n\n\n\nFigura 4.4: Grafica de dos modelos AR(1) con raíces cercanas a uno en valor absoluto.",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#descomposición-de-series-de-tiempo",
    "href": "series.html#descomposición-de-series-de-tiempo",
    "title": "4  Series de tiempo",
    "section": "4.8 Descomposición de series de tiempo",
    "text": "4.8 Descomposición de series de tiempo\n\nSe ha identificado que las series de tiempo pueden presentar estacionalidad, una componente que se añade o se multiplica con otras componentes como la tendencia y la aleatoriedad. En el análisis de series temporales, los expertos suelen enfocarse en dos categorías principales de modelos estacionales:\nDatos estacionales aditivos.\nEn estos modelos, los datos \\(x_t\\) en el tiempo \\(t\\) se consideran como una suma de tres componentes: Un componente de tendencia a largo plazo \\((tr_t)\\), Un componente de estacional \\((s_t)\\) y, Un componente de variabilidad aleatoria \\((z_t)\\).\nLa ecuación que representa este modelo es:\n\\[\nx_t = s_t + tr_t + z_t.\n\\tag{4.16}\\]\nDatos estacionales multiplicativos.\nEn este enfoque, los datos \\(x_t\\) en el tiempo \\(t\\) se expresan como el producto de las mismas tres componentes mencionadas y se representa en la ecuación:\n\\[\nx_t = s_t \\times tr_t \\times z_t\n\\tag{4.17}\\]\n\n\n4.8.1 Conjunto de datos de series temporales\n\n4.8.1.1 Datos Ciclicos\n\nMuchos conjuntos de datos de series temporales presentan patrones cíclicos, caracterizados por fluctuaciones que se repiten de manera regular o casi regular a lo largo del tiempo. A este tipo de datos se les suele denominar pseudoperiódicos, un término que utilizaremos de manera intercambiable con cíclicos para describir su comportamiento.\nLos datos verdaderamente periódicos presentan un comportamiento que se repite de manera exacta a lo largo de un intervalo de tiempo fijo. Un ejemplo claro de este tipo de datos es la curva sinusoidal. En contraste, los datos pseudoperiódicos o cíclicos son aquellos que tienden a repetir patrones, pero sin una regularidad exacta. Los datos de temperatura mensual de Dallas-Ft. Worth (DFW) de la Figura 4.5 son un ejemplo de datos cíclico.\n\n\nEjemplo 4.2  \n\n\n\n\n\n\nDatos de temperatura para Dallas-Ft. Worth (DFW)\n\n\n\n\n\nLa Figura 4.5 presenta la temperatura promedio mensual en Dallas-Ft. Worth (DFW) desde Enero de 1900 hasta Diciembre de 2020. Aunque los detalles pueden no ser evidentes a simple vista, las temperaturas siguen el patrón estacional esperado, con valores más bajos en invierno y, en el caso de DFW, temperaturas notablemente altas durante el verano.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 4.5: Temperatura media mensual en Dallas-Ft. Worth desde Enero de 1900 hasta Diciembre de 2020\n\n\n\nAl observar los datos de la Figura 4.5, se puede apreciar nuevamente el valor de enfocarse en un fragmento de tiempo específico, que en este caso corresponde a los años 1979 a 1986. Para los propósitos del estudio, se define un ciclo como la cantidad de meses entre el mes más caluroso de cada año. En DFW, se identifica que el mes más caluroso es julio o agosto. Es importante notar que los datos de temperatura muestran una progresión suave desde el verano al invierno y viceversa, con temperaturas promedio similares durante el otoño y la primavera. El patrón general que resulta es, de alguna manera, sinusoidal o pseudosinusoidal.\nEs útil observar que habrá variaciones aleatorias (ruido) en los datos. El mes más cálido de 1979 a 1981 fue Julio. El mes más cálido de 1982 fue Agosto, por lo que el tercer ciclo en el gráfico tiene una duración de 13 meses. Agosto también fue el mes más cálido de 1983 a 1985, por lo que los tres ciclos siguientes tienen una duración de 12 (Agosto a Agosto). Finalmente, en 1986 el mes más cálido fue Julio, por lo que la duración del ciclo correspondiente es de 11 meses. Si bien las duraciones de los ciclos no fueron todas iguales a 12 meses, tenga en cuenta que siempre que ocurre un ciclo de 13 meses, siempre es seguido por un ciclo de 12 meses o de 11 meses para “mantenerse en sincronía o volver a sincronizarse”. Es decir, supongamos que el mes más cálido de un año es Julio y luego los dos años siguientes tuvieron ciclos de temperatura con una duración de 13. Eso indicaría que el mes más cálido del tercer año fue Septiembre, que nunca ha sido el mes más cálido en DFW en el conjunto de datos disponible desde septiembre de 1898.\nLos datos de temperatura de DFW en Figura 4.5 son un ejemplo de datos cíclicos con una duración de ciclo fija. En este caso, el ciclo de 12 meses tiene una causa física: el movimiento regular y predecible de la Tierra alrededor del Sol. Debido a que los ciclos de temperatura están relacionados con el año calendario, los datos de temperatura se denominan datos estacionales.\n\nObservación. La diferencia clave entre los datos de manchas solares y los datos de temperatura es que, mientras que las duraciones de los ciclos de manchas solares tienden a variar aleatoriamente entre 9 y 13 años, las duraciones de los ciclos de temperatura son fijas hasta el punto de que permanecen “sincronizadas” con el año de 12 meses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 4.6: Temperatura media mensual en Dallas, Texas, correspondiente al periodo de 1979 a 1986, extraído de un fragmento de Figura 4.5.\n\n\n\n\nObservación. La duración de los ciclos de temperatura es fija hasta el punto de que se mantienen “sincronizados” con el año de 12 meses.\n\n\n\n\n\n\n\n4.8.1.2 Tendencia\n\nUna tendencia (Trends) es una tendencia de los datos a aumentar (o disminuir) de manera constante a lo largo del tiempo.\nLos datos que presentan una tendencia o un comportamiento de deambulación aleatoria no son de naturaleza cíclica. A menudo se les denomina aperiódicos (no periódicos), ya que no exhiben un patrón regular de ascensos y descensos.\nUna tendencia lineal representa una inclinación de los datos a aumentar o disminuir de manera constante a lo largo del tiempo (ver Figura 4.7 (a)). Por otro lado, las tendencias pueden seguir una curva, como ocurre con la tendencia exponencial mostrada en la Figura 4.7 (b). La Figura 4.7 (c) ilustra una serie temporal con una tendencia descendente, aunque más irregular en comparación con las tendencias observadas en las Figura 4.7 (a) y Figura 4.7 (b). Un patrón común en los conjuntos de datos es el comportamiento deambulante, como el mostrado en la Figura 4.7 (d), que parece moverse sin una dirección clara. Es decir, pueden presentarse varias tendencias, tanto cortas como largas, a menudo en direcciones opuestas.\n\n\n\n\n\n\n\nFigura 4.7: Gráficos que muestran (a) una tendencia lineal, (b) una tendencia exponencial, (c) una tendencia irregular descendente y (d) un patrón de deambulación.",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#sec-KPSS",
    "href": "series.html#sec-KPSS",
    "title": "4  Series de tiempo",
    "section": "4.9 La prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS)",
    "text": "4.9 La prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS)\n\nLa prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) es una prueba estadística utilizada para determinar la estacionariedad de una serie temporal. Evalúa la estacionariedad de una serie temporal mediante el examen de la varianza de los errores acumulados a lo largo del tiempo las hipótesis del tes KPSS son las siguientes:\n\nLa hipótesis nula \\((H_0) :\\) el modelo es estacionaria.\nHipótesis alternativa \\((H_1)\\) el modelo tiene una raíz unitaria y por tanto no es estacionaria.\n\nEl nivel de significancia, se denota por \\(\\alpha\\) y representa la probabilidad de rechazar \\(H_0\\).\nLa hipótesis nula de la prueba KPSS se rechaza cuando el valor estadístico de la prueba es mayor que el valor crítico correspondiente a un nivel de significancia determinado como \\(\\alpha = 0.01\\) \\((1 \\%)\\), \\(\\alpha = 0.05 (5 \\%)\\), o \\(\\alpha = 0.10 (10 \\%)\\). El valor más utilizado es \\(\\alpha = 0.05\\). Esto indica que hay suficiente evidencia estadística para concluir que la serie no es estacionaria y, por lo tanto, tiene una raíz unitaria.\nPara calcular la estadística de prueba KPSS se utiliza la siguiente fórmula:\n\\[ KPSS = \\dfrac{1}{ \\hat{\\sigma}^2 T } \\sum_{t=1}^T \\left(    \\sum_{i = 1}^t  \\hat{u_i}   \\right)^2.\\]",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "series.html#evaluación-de-la-precisión-de-los-pronósticos",
    "href": "series.html#evaluación-de-la-precisión-de-los-pronósticos",
    "title": "4  Series de tiempo",
    "section": "4.10 Evaluación de la precisión de los pronósticos",
    "text": "4.10 Evaluación de la precisión de los pronósticos\nLa evaluación de la precisión de los pronósticos es un paso fundamental para determinar la calidad de un modelo predictivo. Para obtener una cuantificación global de la eficacia de las predicciones, es esencial medir qué tan bien coinciden los valores pronosticados \\((y_t)\\) con los valores reales observados \\((x_t)\\) en cada instante de tiempo \\(t\\). Algunas métricas que se han introducido, permiten resumir de manera concisa e informativa la precisión de las predicciones, proporcionando una visión clara sobre el rendimiento general del modelo. A continuación, se describen algunas de las métricas de rendimiento más utilizadas en este ámbito.\n\n4.10.1 MSE\nMean Squared Error (MSE), o Error Cuadrático Medio, es una métrica que se utiliza para medir la precisión de un modelo de regresión. Se calcula como el promedio de los cuadrados de las diferencias entre los valores predichos \\(y_t\\) y los valores observados \\(x_t\\). La fórmula para calcular MSE es:\n\\[\nMSE = \\frac{1}{n} \\sum_{t=1}^{n} (x_t - y_t)^2.\n\\tag{4.18}\\]\n\n\n4.10.2 RMSE\n\nEl Error Cuadrático Medio (RMSE) es una medida de la magnitud de los errores entre los valores predichos \\(y_t\\) y los valores observados \\(x_t\\). Es ampliamente utilizado en la evaluación de la precisión de los modelos de predicción de series temporales debido a su capacidad para interpretar errores grandes y proporcionar una medida clara de la exactitud del modelo.\nLa fórmula para el cálculo de RMSE es la siguiente:\n\\[ RMSE = \\sqrt{  \\dfrac{\\sum_{t=1}^{n} (y_t - x_t)^2}{n }}.\n\\tag{4.19}\\]\n\n\n\n\n\nBowley, Arthur Lyon. 1926. Elements of statistics. 8. King.\n\n\nKolmogorov, Andrey. 1941. «Interpolation and extrapolation of stationary random sequences». Izvestiya Rossiiskoi Akademii Nauk. Seriya Matematicheskaya 5: 3.\n\n\nWoodward, Wayne A, Henry L Gray, y Alan C Elliott. 2017. Applied time series analysis with R. CRC press.",
    "crumbs": [
      "Series de tiempo",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Series de tiempo</span>"
    ]
  },
  {
    "objectID": "herramientas.html",
    "href": "herramientas.html",
    "title": "5  Herramientas de inteligencia artificial",
    "section": "",
    "text": "5.1 Machine Learning",
    "crumbs": [
      "Herramientas de inteligencia artificial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Herramientas de inteligencia artificial</span>"
    ]
  },
  {
    "objectID": "herramientas.html#machine-learning",
    "href": "herramientas.html#machine-learning",
    "title": "5  Herramientas de inteligencia artificial",
    "section": "",
    "text": "El aprendizaje automático o aprendizaje de máquinas, más conocido en el mundo actual como el machine learning, que es un subcampo de las ciencias de la computación y una rama de la inteligencia artificial cuya finalidad es desarrollar técnicas que permitan a las computadoras aprender, convirtiéndose en un pilar fundamental para el trato de datos a gran escala.\n\n\n5.1.1 Tipos de aprendizaje automático\n\nAprendizaje supervizado\nEn este tipo de aprendizaje los modelos matemáticos (o máquina) que se entrenan predicen un conjunto de datos en base a resultados ya conocidos. La máquina va aprender a través del ajuste en la calibración de los datos de entrenamiento, estableciendo reglas para nuevos datos de salida. Cuando se tengan nuevos datos sin entrenar, el algoritmo será capaz de predecir el resultado deseado. Un resumen reciente sobre esta área puede consultarse en Burkart y Huber (2021) .\nEn el aprendizaje supervisado se recomienda en dos grandes casos :\n\nProcesos de clasificación.\nLos modelos de clasificación predicen las clases o grupos categóricos a los que pertenece cada dato. En este caso son valores discretos.\nModelos de regresión.\nLos modelos de regresión predicen un valor numérico a partir de las características de entrada.\n\nAprendizaje no supervisado\nEste tipo de aprendizaje también conocido como automático, se diferencia del supervisado porque no está compartiendo sus salidas con datos de entrenamiento. En este caso, la máquina vá a actuar por su cuenta y no necesita de datos de aprendizaje (o datos para la calibración de parámetros y reducción de un error definido previamente), que en algunos casos pueden dar mejores resultados.",
    "crumbs": [
      "Herramientas de inteligencia artificial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Herramientas de inteligencia artificial</span>"
    ]
  },
  {
    "objectID": "herramientas.html#deep-learnig",
    "href": "herramientas.html#deep-learnig",
    "title": "5  Herramientas de inteligencia artificial",
    "section": "5.2 Deep learnig",
    "text": "5.2 Deep learnig\n\nSon modelos de inteligencia artificial de aprendizaje supervisado que implementan algoritmos de larga ejecución. El aprendizaje profundo permite que los modelos computacionales que se componen de múltiples capas de procesamiento aprendan representaciones de datos con múltiples niveles de abstracción.",
    "crumbs": [
      "Herramientas de inteligencia artificial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Herramientas de inteligencia artificial</span>"
    ]
  },
  {
    "objectID": "herramientas.html#funcionamiento-de-una-estación-meteorológica",
    "href": "herramientas.html#funcionamiento-de-una-estación-meteorológica",
    "title": "5  Herramientas de inteligencia artificial",
    "section": "6.1 Funcionamiento de una Estación Meteorológica",
    "text": "6.1 Funcionamiento de una Estación Meteorológica\n\nLas estaciones meteorológicas son instalaciones equipadas con instrumentos y sensores para medir diversas variables atmosféricas como temperatura, humedad, presión atmosférica, velocidad y dirección del viento, precipitación y radiación solar. Estas estaciones pueden ser automáticas o manuales. Las estaciones automáticas utilizan sensores electrónicos para recopilar datos de manera continua, transmitiéndolos en tiempo real a través de redes de comunicación a centros de datos para su análisis. Las estaciones manuales requieren la intervención humana para leer y registrar las mediciones. Los datos recogidos son fundamentales para la previsión del tiempo, la investigación climática y la gestión de recursos naturales. Las estaciones meteorológicas están ubicadas estratégicamente en tierra, océanos y en altitudes elevadas para obtener una cobertura representativa de las condiciones atmosféricas globales.",
    "crumbs": [
      "Herramientas de inteligencia artificial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Herramientas de inteligencia artificial</span>"
    ]
  },
  {
    "objectID": "herramientas.html#recopilación-para-el-análisis-de-datos-en-una-estación-meteorológica",
    "href": "herramientas.html#recopilación-para-el-análisis-de-datos-en-una-estación-meteorológica",
    "title": "5  Herramientas de inteligencia artificial",
    "section": "6.2 Recopilación para el análisis de datos en una estación meteorológica",
    "text": "6.2 Recopilación para el análisis de datos en una estación meteorológica\n\nEn el caso de la estación climática ubicada en Jena, Alemania los instrumentos están sujetos a un mástil de 10 metros de altura el cual se ubican en sitios estratégicos al descubierto. Este mástil es también utilizado para llevar temporalmente otros instrumentos para comparaciones o calibraciones.\nLos sistemas de adquisición de datos, fuentes de energía, laptops y dispositivos similares se ubican dentro de lo que llaman casillero modular, de la compañía llamda Rittal pueden estar sujetos a un costado de la base del mástil.\nEn la Tabla 6.1 se muestran algunas variables recopiladas con su correspondiente instrumento y la compañía que lo produce.\n\n\n\nTabla 6.1: Mediciones.\n\n\n\n\n\n\n\n\n\n\nVariable\nInstrumento\nMarca\n\n\n\n\nTemperatura del Aire\nKPK1/5-ME\nMela Sensortechnik\n\n\nHumedad Relativa del Aire\nKPK1/5-ME\nMela Sensortechnik\n\n\nPresión de Aire\nPTB101B\nVaisala\n\n\nVelocidad del Viento\nA100R\nVector Instrumen\n\n\nDirección del Viento\nW200P\nVector Instruments\n\n\nRadiación entrante de Onda Corta\nCM11\nKipp & Zonen\n\n\nRadiación Activa Fotosintética\nPAR Lite\nKipp & Zonen\n\n\nCantidad de Precipitación\n5.4032.35.008\nThies\n\n\nPrecipitación si/no\n5.4105.00.000\nThies\n\n\nConcentración de CO2\nLI6262\nLicor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara adquirir las señales de los instrumentos mencionados, se emplea un dispositivo conocido como datalogger CR10X de Campbell Scientific. LoggerNet de Campbell Scientific es un software de recopilación y gestión de datos diseñado para comunicarse con una amplia variedad de dataloggers y dispositivos de medición de Campbell Scientific. Permite la configuración de dataloggers, la recopilación automática de datos, el almacenamiento y la visualización de información en tiempo real. Este software es utilizado en aplicaciones como meteorología, hidrología, estudios ambientales y agricultura de precisión, entre otras. LoggerNet no es gratuito; es un software comercial que requiere la compra de una licencia para su uso.\nEste datalogger realiza lecturas de los sensores cada 10 segundos, promedia los valores totales y máximos de las variables en intervalos de 10 minutos, y almacena estos cálculos internamente en su memoria. Además, el programa LoggerNet de Campbell Scientific se ejecuta en una computadora separada dentro de la red local del instituto. Este programa se conecta al datalogger cada 10 minutos para descargar los datos recientes o aquellos que aún no han sido descargados.\n\n\n\n\n\nBurkart, Nadia, y Marco F Huber. 2021. «A survey on the explainability of supervised machine learning». Journal of Artificial Intelligence Research 70: 245-317.\n\n\nMoor, James. 2006. «The Dartmouth College artificial intelligence conference: The next fifty years». Ai Magazine 27 (4): 87-87.",
    "crumbs": [
      "Herramientas de inteligencia artificial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Herramientas de inteligencia artificial</span>"
    ]
  },
  {
    "objectID": "redes.html",
    "href": "redes.html",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "",
    "text": "6.1 Inspiración Biológica de las Redes neuronales Artificiales",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#inspiración-biológica-de-las-redes-neuronales-artificiales",
    "href": "redes.html#inspiración-biológica-de-las-redes-neuronales-artificiales",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "",
    "text": "Se parte del estudio de los seres vivos que poseen cerebro uno de los órganos más complejos del cuerpo humano, el cual hace parte de un sistema nervioso central. Funciona como el centro de control de todas nuestras actividades, tanto conscientes como inconscientes, regulando funciones esenciales como la respiración, el ritmo cardíaco y la digestión, así como procesos más complejos como el pensamiento, la memoria y las emociones.\nEl cerebro está compuesto por miles de millones de células nerviosas llamadas neuronas. Una imagen de una neurona real se puede observar en Figura 6.1. Estas neuronas se comunican entre sí a través de conexiones especializadas llamadas sinapsis, formando una extensa red de comunicación.\n\n\n\n\n\n\nFigura 6.1: Imagen de una neurona biologica.\n\n\n\nCuando una neurona recibe suficientes estímulos de otras neuronas a través de sus dendritas y alcanza un umbral, se dispara un impulso eléctrico conocido como potencial de acción. Este impulso viaja a lo largo del axón de la neurona y provoca la liberación de neurotransmisores en la sinapsis, los cuales estimulan a las neuronas receptoras. La cantidad de información procesada y almacenada depende de los niveles de estímulos recibidos y de la eficiencia de estas conexiones sinápticas esto se puede ver visualmente en la Figura 6.2. A través de este complejo sistema de señales, el cerebro puede procesar información, aprender de experiencias, tomar decisiones y coordinar acciones.\n\n\n\n\n\n\n\n\n\n\n\nFigura 6.2: Estructura básica de una neurona biológica.\n\n\n\nLa adaptación de la estructura de las redes neuronales biológicas fue fundamental para desarrollar un modelo matemático de neuronas artificiales, introducido en la década de 1940. Warren McCulloch y Walter Pitts (McCulloch y Pitts 1943), en su modelo no solo abarcaba los conceptos básicos de una neurona artificial, sino que también incorporaba la combinación lineal de entradas y la función de activación. Sin embargo, Frank Rosenblatt expandió este concelto de las redes neuronales artificiales con la introducción del perceptrón. En su trabajo (Rosenblatt 1958), describió cómo este tipo de red neuronal podía aprender a clasificar patrones ajustando los pesos de las conexiones neuronales.\nEn la emulación de dicho sistema neuronal biológico, por medio de un sistema neuronal artificial, se puede establecer una estructura jerárquica similar a la existente en el cerebro. El elemento esencial será la neurona artificial, la cual se organizará en capas. Varias capas constituirán una red neuronal. Finalmente, una red neuronal junto con los interfaces de entrada y salida constituirá el sistema global del proceso.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#modelo-de-red-neuronal-artificial",
    "href": "redes.html#modelo-de-red-neuronal-artificial",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "6.2 Modelo de red neuronal Artificial",
    "text": "6.2 Modelo de red neuronal Artificial\n\nLas Redes Neuronales Artificiales (RNA) son un modelo computacional inspirado en el modelo que componen las redes neuronales biológicas. Consta de un conjunto de unidades, neuronas artificiales interconectadas y permite la transmisión de señales. Estas señales pasan a través de la red neuronal en la que se encuentran después de pasar por diferentes operaciones generan el valor final de salida. Estas redes se distinguen por su capacidad de aprendizaje. Los problemas del mundo real, como la asociación, la evaluación o el reconocimiento de patrones, encuentran una resolución óptima a través de estas redes neuronales, de manera análoga a la efectividad que los seres humanos demuestran al abordar este tipo de razonamiento, clasificación y otros desafíos.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#arquitectura-de-una-red-neuronal-artificial",
    "href": "redes.html#arquitectura-de-una-red-neuronal-artificial",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "6.3 Arquitectura de una Red Neuronal Artificial",
    "text": "6.3 Arquitectura de una Red Neuronal Artificial\n\nLa arquitectura de una red neuronal artificial se compone de nodos (neurona) que se organizan por capas. Estas capas se interconectan entre sí generando la similitud de la sinápsis que se presenta entre las neuronas biológicas. El comportamiento de ambas redes está determinado por la estructura de conexiones sinápticas. Estas conexiones sinápticas pueden ser direccionales, es decir, la información solamente puede propagarse en un único sentido (desde la neurona presináptica a la pos-sináptica). El conjunto de una o más capas constituye la red neuronal.\nEs posible dar una clasificación de estas capas:\nCapa de entrada: también denominada sensorial, está compuesta por neuronas que reciben datos o señales procedentes del entorno.\nCapas ocultas: no tiene una conexión directa con el entorno, es decir, no se conecta directamente ni a órganos sensores ni a efectores. Este tipo de capa oculta proporciona grados de libertad a la red neuronal gracias a los cuales es capaz de representar más fehacientemente determinadas características del entorno que trata de modelar.\nCapa de salida: proporciona la respuesta a las señales de la entrada.\nGeneralmente, las conexiones son entre neuronas pertenecientes a diferentes capas aunque son posibles las conexiones intercapas o de realimentación, aquellas que no siguen el sentido de entrada-salida sino que están conectadas entre capas anteriores o mismas neuronas de la capa.\nEstas capas se pueden observar en la Figura 6.3. La capa de entrada está compuesta por 7 neuronas, representadas en color morado, la cual es seguida de una capa oculta con 4 neuronas mostradas en color salmón. Finalmente, la capa de salida está representada en color rosa.\n\n\n\n\n\n\n\nFigura 6.3: Arquitectura de una RNA.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#elementos-de-una-red-natural-artificial",
    "href": "redes.html#elementos-de-una-red-natural-artificial",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "6.4 Elementos de una Red Natural Artificial",
    "text": "6.4 Elementos de una Red Natural Artificial\n\nDentro de la arquitectura de una RNA se pueden distinguir los siguientes elementos:\nEn la capa de entrada ingresa el conjunto de entradas (datos) \\(x_j\\) que es recibida por la neurona del sistema sensorial externo u otras neuronas con las que tiene conexión. Cada neurona de cualquier capa (o nodo) posee un peso sináptico \\(w_{ij}\\), con \\(j=1, \\dotsc , n.\\) Este se modifica dependiendo de la información recibida emulando la sinapsis entre las neuronas biológicas.\nCada neurona tiene una regla de propagación \\(h_i\\) definida a partir del conjunto de entradas y los pesos sinápticos. Es decir: \\[h_i  =  \\sum_{i=1}^{n} w_{ij} x_j .\\] Suele ser habitual añadir al conjunto de pesos de la neurona un parámetro adicional \\(\\theta_i\\), que se denomina umbral, el cual se acostumbra a restar al potencial pos-sináptico. Es decir: \\[h_i =  \\sum_{i=1}^{n} w_{ij} x_j - \\theta_i .\\]\nEn la Figura 6.4 se presenta un modelo de red neuronal artificial que incorpora los componentes fundamentales antes presentados para este modelo.\n\n\n\n\n\n\nFigura 6.4: Modelo de una neurona artificial.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#funciones-de-activación",
    "href": "redes.html#funciones-de-activación",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "6.5 Funciones de activación",
    "text": "6.5 Funciones de activación\n\nUna función de activación es una asignación que establece la relación entre la salida de la capa de entrada y una capa oculta en un Red Neuronal Artificial (RNA) permitiendo a la red aprender. Normalmente los valores de la salida están comprendidos en un rango \\((0,1)\\) o \\((-1,1)\\).\nPor ejemplo, dada una entrada \\((x_i)\\) y un conjunto de pesos \\((w_i)\\), la función de activación toma una combinación lineal de estos (generalmente en forma de \\((z = \\sum_i w_i x_i + b)\\), donde \\((b)\\) es el sesgo) y aplica una transformación no lineal. Esta transformación permite que la red neuronal aprenda y adopte una capacidad eficaz al modelar los datos.\n\n\nDe todas las funciones de activación que hay en la literatura, se van a considerar aquellas que generen menor costo computacional. Algunas de ellas son:\n\n\n6.5.1 ReLU (Rectified Lineal Unit)\n\nLa función ReLU transforma los valores introducidos, anulando los valores negativos y dejando los positivos tal y como entran.\n\\[\nf(x) = \\max(0,x) =\n\\left\\{\n\\begin{array}{ll}\n0 & \\text{si } x &lt; 0 \\\\\nx & \\text{si } x \\geq 0\n\\end{array}\n\\right .\n\\]\n\n\n\n6.5.2 Sigmoid (Sigmoide)\n\nLa función sigmoide transforma los valores introducidos a una escala (0,1), donde los valores altos tienen de manera asintótica a 1 y mientras que los valores muy bajos lo hacen al valor 0.\n\\[ f(x)= \\dfrac{1}{1- e^{-x}} .\\]\n\n\n\n6.5.3 Tangente hiperbólica (Tangent Hyperbolic )\n\nLa función tangente hiperbólica realiza la misma tranformación anterior pero a una escala \\((-1,1)\\).\n\\[ f(x) =\\dfrac{2}{1+e^{-2x}} -1 .\\]\n\n\n\n6.5.4 Softmax\n\nLa función Softmax transforma las salidas a una representación en forma de probabilidades, de tal manera que el sumatorio de todas las probabilidades de las salidas de 1.\n\\[f(z)= \\dfrac{e^{z_j}}{\\displaystyle \\sum_{k=1}^{K} e^z} .\\]\n\n\n\n6.5.5 ReLU con fugas\n\nLa función ReLU con fugas (Leaky ReLU) se distingue de la función ReLU simple por permitir un pequeño gradiente para los valores de entrada negativos. Esto se logra mediante un parámetro escalar \\(a\\), cuyo valor se encuentra dentro del rango de 0 a 1. La expresión matemática de esta función de activación es la siguiente:\n\\[ f(x) =\n    \\left\\{ \\begin{array}{lcc} 0 & si & x \\leq 0 \\\\ \\\\ a x & si & x \\geq  0  \\end{array} \\right . \\]\n\n\nDentro de la literatura existen más funciones de activación y pueden consultarse con detalle en Apicella et al. (2021).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) ReLu\n\n\n\n\n\n\n\n\n\n\n\n(b) Sigmoide\n\n\n\n\n\n\n\n\n\n\n\n(c) Tangente hiperbólica\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Softmax\n\n\n\n\n\n\n\n\n\n\n\n(e) ReLu con fugas\n\n\n\n\n\n\n\n\n\n\n\n(f) ReLu\n\n\n\n\n\n\n\nFigura 6.5: Funciones de activación.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#sec-Adam",
    "href": "redes.html#sec-Adam",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "6.6 Optimizador Adam",
    "text": "6.6 Optimizador Adam\n\nEl optimizador Adam (Adaptive Moment Estimation) es uno de los algoritmos de optimización más populares y efectivos en el campo del aprendizaje automático y la optimización de redes neuronales. Fue propuesto por por D.P. Kingma y J.Ba en el articulo (Kingma y Ba 2014). El nombre “Adam” proviene de “Adaptive Moment Estimation,” reflejando su método para estimar momentos adaptativos durante la optimización.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#sec-función-de-perdida",
    "href": "redes.html#sec-función-de-perdida",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "6.7 Función de Pérdida",
    "text": "6.7 Función de Pérdida\n\nLas funciones de costo, pérdida u objetivo son conceptos fundamentales en el campo del aprendizaje automático y la optimización matemática. Estas funciones permiten evaluar la calidad de un modelo al cuantificar el error o la discrepancia entre las predicciones del modelo y los valores reales.\nPara evaluar el rendimiento del modelo se utiliza la función de costo. Esta proporciona una métrica cuantitativa que permite evaluar la precisión de las predicciones. Un valor bajo de la función de costo indica que el modelo está haciendo predicciones cercanas a los valores reales, mientras que un valor alto indica lo contrario.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "redes.html#algunos-tipos-de-red-neuronal-artificial",
    "href": "redes.html#algunos-tipos-de-red-neuronal-artificial",
    "title": "6  Redes neuronales Biológicas y artificiales",
    "section": "6.8 Algunos tipos de Red Neuronal Artificial",
    "text": "6.8 Algunos tipos de Red Neuronal Artificial\n\n6.8.1 Perceptrón Simple\n\nEl perceptrón simple fue introducido por Rosenblatt (1958), donde la arquitectura más simple, es una red en la que la capa de entrada está directamente relacionada con la capa de salida a través de una red ponderada (sin capas ocultas). Es un modelo unidireccional compuesto por dos capas de neuronas, una de entrada y otra de salida. La operación en un perceptrón simple que consta de \\(n\\) neuronas de entrada y \\(m\\) neuronas de salida se puede expresar como:\n\\[ y_i = f \\left(  \\sum_{j=1}^{n}  w_{ij} x_j - \\theta_i \\right) ,\\] con \\(i=1, \\dots , n .\\)\n\n\n\nArquitectura y función de activación de un perceptrón simple\n\n\n\n\n\n6.8.2 Red Neuronal Recurrente\n\nUna red neuronal recurrente es una red neuronal que contiene capas internas que realimentan la red, generando así memoria.\nA finales de los años 80, varios investigadores, entre ellos Rumelhart, Hinton, y Williams (1986), introdujeron redes neuronales simples parcialmente recurrentes para aprender cadenas de caracteres.\nLas redes neuronales recurrentes han sido un foco importante de investigación y desarrollo durante la década de 1990.\nUna red recurrente según Fontoura Costa y Travieso (1996) es una red neuronal con conexiones. retroalimentadas (bucle cerrado). Los ejemplos, de acuerdo con lo citado por Hecht-Nielsen (1990), incluyen los modelos de redes BAM, Hopfield, la máquina de Boltzmann y las redes de retropropagación recurrentes.\nSu arquitectura varía según estén totalmente interconectadas (Figura 6.6), hasta redes parcialmente conectadas (Figura 6.7), incluidas redes de avance multicapa con distintas capas de entrada y salida. Las redes completamente conectadas no tienen capas de entrada de nodos distintas y cada nodo tiene entradas de todos los demás nodos.\nEn este tipo de redes neuronales es posible enviar retroalimentación al propio nodo.\n\n\n\n\n\n\nFigura 6.6: Ejemplo de una capa de RNA recurrente totalmente conectada.\n\n\n\nEn este caso se han utilizado redes neuronales simples parcialmente recurrentes (Figura 6.7) para aprender cadenas de caracteres.\n\n\n\n\n\n\nFigura 6.7: Ejemplo de una conexión entre capas de una RNA recurrente simple.\n\n\n\nEn esta red algunos nodos son parte de una estructura de retroalimentación, otros nodos proporcionan el contexto secuencial y reciben retroalimentación de otros nodos.\nLos pesos (C1 y C2) se procesan como los de las unidades de entrada, por ejemplo, mediante retropropagación. Los nodos reciben retroalimentación retardada en el tiempo desde, en el caso de la (Figura 6.7), las unidades de segunda capa.\nLos datos de entrenamiento constan de entradas y sus salidas sucesoras deseadas. La red puede entrenarse para predecir la siguiente letra en una cadena de caracteres y validar una cadena de caracteres.\n\n\n\n6.8.3 Red Neuronal LSTM\n\nLa red neuronal con memoria a corto y largo plazo (LSTM, por su sigla en inglés) es una red neuronal recurrente con una memoria de estado y una estructura de red multicapa.\nLas redes de memoria a corto y largo plazo (LSTM), son un tipo especial de RNN, capaz de aprender dependencias a largo plazo. Fueron introducidos por Schmidhuber, Hochreiter, et al. (1997) .\nLos LSTM están diseñados explícitamente para evitar el problema de dependencia a largo plazo. Recordar información durante largos períodos de tiempo es prácticamente su comportamiento predeterminado.\nEl primer paso en para construir una arquitectura LSTM es decidir qué información será descartada del estado de la celda. Esta decisión la toma una capa sigmoidea llamada “capa de puerta de olvido” esto se puede ver en la Figura 6.8.\n\n\n\n\n\n\nFigura 6.8: Celda de estado\n\n\n\n\n\n\n6.8.4 Red neuronal Convolucional (CNN)\n\n\nLas redes convolucionales (LeCun et al. 1989), también conocidas como redes neuronales convolucionales o en ingles, Convolutional Neural Network (CNN), son un tipo de red neuronal que esta diseñado principalmente para procesar datos de imagenes. \nLa red neuronal se basa en la comprensión de Hubel y Wiesel (1959) sobre cómo funciona el procesamiento de imágenes en el cerebro de los gatos y bajo la hipótesis de que su campo visual parece estimular ciertas neuronas.\nLas redes neuronales convolucionales están diseñadas para funcionar con entradas estructuradas en cuadrícula, que tienen fuertes dependencias espaciales en regiones locales de la red. Un ejemplo común de datos generados por una cuadrícula es bidimensional. Este tipo de material exhibe dependencia espacial porque las áreas adyacentes de la imagen se parecen a los colores de los píxeles. Las dimensiones adicionales capturan diferentes colores, creando un volumen de entrada tridimensional. Por lo tanto, las redes neuronales convolucionales parecen depender de la distancia. Otras formas de datos secuenciales como texto, series de tiempo y secuencias también pueden considerarse casos especiales de estructuras estructuradas en cuadrícula. La mayoría de las aplicaciones de redes neuronales artificiales se centran en imágenes, aunque estas redes también se pueden utilizar sobre cualquier tipo de datos espaciales y temporales.\n\n\n6.8.4.1 Capas de una red neuronal convolucional (CNN)\n\n\nLa arquitectura de una red neuronal convolucional (CNN) se compone de múltiples bloques de construcción, conocidos como capas. A continuación se describen algunos de estos bloques y su papel en la arquitectura de la CNN como se muestra en la Figura 6.9.\n\n\n\n\n\n\n\nFigura 6.9: Esquema de Red Neuronal Convolucional\n\n\n\n\n\n6.8.4.2 Capa convolucional\n\nLa capa convolucional es el componente más importante de cualquier arquitectura CNN. Contiene un conjunto de núcleos convolucionales (también llamados filtros), que convolucionan con la imagen de entrada (métricas N-dimensionales) para generar un mapa de características de salida.\n\n\n\n6.8.4.3 Kernel\n\nUn kernel, núcleo o filtro en la convolución de una CNN es una una matriz de \\(n \\times n\\) que contiene valores o números discretos, donde cada valor se conoce como el peso de este núcleo.\nDurante el inicio del proceso de entrenamiento de un modelo CNN, se asignan los pesos en el kernel de manera especifica o aleatoria dependiendo del enfoque. Luego, con cada época del entrenamiento, se ajustan los pesos y el núcleo aprende a extraer características significativas.\n\n\n\n6.8.4.4 Proceso de convolución\n\nLas capas de redes neuronales tradicionales utilizan la multiplicación de matrices por una matriz de parámetros con un parámetro separado que describe la interacción entre cada unidad de entrada y cada unidad de salida. Esto significa que cada unidad de salida interactúa con cada unidad de entrada. Sin embargo, las redes convolucionales suelen tener interacciones escasas (también denominadas conectividad dispersa o pesos dispersos). Esto se logra haciendo el kernel más pequeño que la entrada.\nPara comprender la operación de convolución en una imagen en escala de grises de \\(n \\times  n\\) de diámetro y un núcleo de \\(m \\times m\\) con pesos inicializados aleatoriamente se sigue el siguiente proceso:\nDeslizamiento del núcleo.\nSe toma el núcleo de \\(m \\times m\\) y se desliza sobre toda la imagen completa de \\(n \\times  n\\) tanto horizontal como verticalmente.\nProducto escalar.\nEn cada posición, se calcula el producto escalar entre el núcleo y la imagen de entrada. Esto se realiza multiplicando los valores correspondientes del núcleo y la imagen, y luego sumando estos productos.\nGeneración del valor de salida.\nLa suma resultante de los productos se convierte en un valor de escala en el mapa de características de salida. Este proceso continúa hasta que el núcleo ya no puede deslizarse más sobre la imagen.\nEste procedimiento permite generar un mapa de características de la imagen original, facilitando así la extracción de características relevantes.\nLa fórmula para encontrar el tamaño del mapa de características de salida después de la operación de convolución:\n\\[  \\displaystyle h^\\prime = \\lfloor  \\dfrac{h-f+p}{s} +1 \\rfloor ,\\]\n\\[  \\displaystyle w^\\prime = \\lfloor  \\dfrac{w-f+p}{s} + 1 \\rfloor, \\]\nDonde \\(h^\\prime\\) denota la altura del mapa de características de salida, \\(w^\\prime\\) denota el ancho del mapa de características de salida, \\(h^\\prime\\) denota la altura de la imagen de entrada, \\(w\\) denota el ancho de la imagen de entrada, \\(f\\) es el tamaño del filtro, \\(p\\) denota el relleno de la operación de convolución y \\(s\\) denota el paso de la operación de convolución. \\[ \\lfloor \\cdot \\rfloor \\] denota la operación de piso (floor), que redondea el resultado hacia abajo al entero más cercano.\n\n\n\n6.8.4.5 Capas de Agrupación (Pooling layer)\n\nLas capas de agrupación (pooling layer) se utilizan para submuestrear los mapas de características (producidos después de operaciones de convolución), es decir, toma los mapas de características de mayor tamaño y los reduce a mapas de características de menor tamaño. Al reducir los mapas de características, siempre se conserva la características (o información) más dominantes en cada paso del grupo. La operación de agrupación se realiza especificando el tamaño de la región agrupada y el ritmo de la operación, similar a la operación de convolución.\nLa fórmula para encontrar el tamaño del mapa de características de salida después de la operación de agrupación:\n\\[ h^\\prime = \\lfloor \\dfrac{h-f}{s} \\rfloor \\] \\[w^´ = \\lfloor \\dfrac{w-f}{s} \\rfloor ,\\]\nDonde \\(h^\\prime\\) denota la altura del mapa de características de salida, \\(w^\\prime\\) denota el ancho de la mapa de características de salida, \\(h\\) denota la altura del mapa de características de entrada, \\(w\\) denota el ancho del mapa de características de entrada, \\(f\\) es el tamaño de la región de agrupación y \\(s\\) denota el paso de la operación de agrupación. \\[ \\lfloor \\cdot \\rfloor ,\\] denota la operación de piso.\nExisten diversas técnicas de agrupación empleadas en diferentes capas de redes neuronales, entre las cuales se incluyen a agrupación máxima (Max pooling), la agrupación mínima, la agrupación promedio, las agrupaciones cerradas y las agrupaciones de árboles, entre otras. Max Pooling es la técnica de agrupación más popular y utilizada para CNN.\n\n\n6.8.4.5.1 Máxima agrupacion (Max-Pooling)\n\nEsta operación consiste en aplicar una matriz de núcleo de tamaño \\(m \\times m\\) y quedarse con el valor máximo en ella, por lo que el resultado de esta aplicación pasaría a tener una única dimensión y podría ser la entrada de la capa de salida.\n\n\n\n\n\n\n\nFigura 6.10: Operación maxpooling, donde el tamaño de la región de agrupación es \\(2 \\times 2\\) (que se muestra en color naranja, en el mapa de características de entrada) y la zancada es 1 y el correspondiente calculado valor en el mapa de características de salida (que se muestra en verde)\n\n\n\n\n\n6.8.4.5.2 Aplanamiento en una red neuronal Convolucional (CNN)\n\nLas capas completamente conectadas, a diferencia de las capas convolucionales, no pueden procesar datos directamente con información espacial (alto, ancho). El aplanamiento, como se describe en el artículo (He et al. 2016), transforma los mapas de características (típicamente tensores 3D) en un vector 1D, permitiendo su integración en las capas completamente conectadas.\nEl aplanamiento (o Flattering) en una red neuronal convolucional (CNN) se refiere al proceso de transformar la salida de capas convolucionales y de agrupación de un tensor multidimensional (que contiene información espacial) en un vector unidimensional con se ve en la Figura 6.11. Esto permite que la red aprenda las relaciones entre características extraídas de diferentes ubicaciones espaciales en la entrada.\n\n\n\n\n\n\nFigura 6.11: Aplananimeto después de una capa de Agrupación en CNN.",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Redes neuronales Biológicas y artificiales</span>"
    ]
  },
  {
    "objectID": "metodologia.html",
    "href": "metodologia.html",
    "title": "7  Metodología.",
    "section": "",
    "text": "En esta sección se describe el enfoque metodológico empleado para evaluar la eficacia de los pronósticos mediante modelos estadísticos y computacionales avanzados, tales como la red neuronal LSTM y la red neuronal convolucional (CNN).\nEl proceso metodológico se divide en las siguientes etapas:\n\n\n7.0.1 Recolección de datos.\n\nLa recopilación de datos históricos, se llevó a cabo mediante una rigurosa selección en los datos mas relevantes para el estudio. Se priorizó la elección de aquellos conjuntos que reflejaran adecuadamente el fenómeno en cuestión, proporcionando una base sólida para la evaluación de los modelos de pronóstico.\n\n\n\n7.0.2 Limpieza y procesamiento de datos.\n\nLos datos recopilados fueron sometidos a un proceso exhaustivo de limpieza y preprocesamiento. Este paso incluyó la eliminación de datos inconsistentes o erróneos, así como la estandarización y normalización de variables relevantes en intervalos de tiempo adecuados. El propósito fue asegurar la integridad y la calidad de los datos para el análisis subsiguiente.\n\n\n\n7.0.3 Implementación del modelo.\n\nSe evaluaron diversos modelos predictivos, tales como la red neuronal LSTM y la red neuronal convolucional (CNN), los cuales, fueron implementados utilizando herramientas computacionales sofisticadas. Se configuraron los parámetros en la arquitectura de los modelos y se ajustaron los modelos de acuerdo a los datos históricos utilizados para su estudio. Es importante resaltar la dificultad de ajuste para evitar el sobreentrenamiento de las redes y obtener pronósticos aceptables. Esta etapa implicó la prueba de diferentes tamaños de conjunto de datos históricos y del tamaño de los pronósticos.\n\n\n\n\n\n7.0.4 Comparación de resultados.\n\nLos resultados obtenidos de los modelos fueron comparados entre sí para determinar su eficacia predictiva relativa. Se utilizó el Error Cuadrático Medio (RMSE) como métrica de evaluación para cada modelo. Además, se analizaron las fortalezas y debilidades de cada modelo en función de su desempeño en la predicción de las variables de interés. Este análisis permitió identificar qué modelos ofrecían mejores resultados y en qué aspectos específicos presentaban limitaciones.\n\n\n\n7.0.5 Análisis y conclusión.\nFinalmente, se realizó un análisis profundo y detallado de los resultados lo cual permitió llegar a las conclusiones del estudio.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodología.</span>"
    ]
  },
  {
    "objectID": "estudio.html",
    "href": "estudio.html",
    "title": "8  Estudio de caso",
    "section": "",
    "text": "8.1 Descripción del problema\nLa modelación de las variables climaticas permite el entendimiento y la generación del pronóstico climático de una región para la planificación territorial, agricultura, ecología, análisis y la conservación de los recursos naturales.\nEn el presente estudio, se utilizó un conjunto de datos climáticos que fueron consultados del 01 de Enero del 2009 al 01 de Enero del 2012. Con la finalidad de comprobar la utilidad y eficacia de dos modelos adecuados de redes neuronales: LTSM y la red neuronal convolucional (CNN). Para el pronóstico de datos climáticos modelados como series de tiempo.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "estudio.html#descripción-del-problema",
    "href": "estudio.html#descripción-del-problema",
    "title": "8  Estudio de caso",
    "section": "",
    "text": "8.1.1 Origen de los datos\n\nSe emplea un conjunto de datos con información climática que fue grabada con el objetivo de ser analizada en la estación climática en el Instituto de Biogeoquimica Max Planck en Jena, Alemania. El mismo contiene todas las variables medidas con su correspondiente instrumento (tal como temperatura del aire, presión atmosférica, humedad, dirección del viento, etc) grabadas cada 10 minutos, a lo largo de varios años. El cual está disponible para su descarga en https://www.bgc-jena.mpg.de/wetter/weather_data.html .\nDe los 14 datos diferentes, se seleccionan 5 teniendo en cuenta factores como su rango y sus patrones estacionales.\nLas variables seleccionadas son las siguientes:\n\n\\(p( mbar )\\) - Presión del aire.\n\\(T( ° C )\\) - Temperatura del aire.\n\\(rh( \\% )\\) - Humedad relativa.\n\\(rho(g/m^3\\)) - Densidad del aire\n\\(wv(m/s)\\) - Velocidad del viento.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "estudio.html#limpieza-y-procesamiento-de-datos",
    "href": "estudio.html#limpieza-y-procesamiento-de-datos",
    "title": "8  Estudio de caso",
    "section": "8.2 Limpieza y procesamiento de datos",
    "text": "8.2 Limpieza y procesamiento de datos\n\nLos datos recopilados fueron sometidos a un proceso exhaustivo de limpieza y preprocesamiento.  En este paso se detectó el intervalo de tiempo en el que mejor se comportarán los datos históricos, por ello se asignó un conjunto de datos históricos omitiendo los primeros 7 días, así como la estandarización y normalización de las 5 variables mas relevantes. Esto con el objetivo de obtener un mejor pronóstico de los datos a futuro.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "estudio.html#pronóstico-mediante-red-neuronales",
    "href": "estudio.html#pronóstico-mediante-red-neuronales",
    "title": "8  Estudio de caso",
    "section": "8.3 Pronóstico mediante red neuronales",
    "text": "8.3 Pronóstico mediante red neuronales\n\n8.3.1 Modelamiento y pronóstico mediante redes neuronales para series de tiempo unidimensionales\n\nSe presentan las gráficas de los datos históricos de las 5 variables elegidas.\n\n\nCódigo\nTemp&lt;-df_clima$T..degC.\nTemp &lt;-Temp +273.15\nDatos_historicos &lt;- Temp \nX&lt;- df_clima$Date.Time\nfig &lt;- plot_ly() %&gt;%\n  add_trace(x = ~X, y = ~Datos_historicos, type = \"scatter\", mode = \"lines\", name = \"Temperatura\", line = list(color = '#63B8FF')) %&gt;%\n  layout(title = \" \",\n         xaxis = list(title = \" \"),\n         yaxis = list(title = \"Temperatura (°F)\")) \nfig\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.1: Serie de tiempo de la Temperatura (° F) del 01 de Enero del 2009 al 01 de Enero del 2012.\n\n\n\n\nCódigo\np_aire &lt;-df_clima$p..mbar. #presion del aire\nX&lt;- df_clima$Date.Time\nfig &lt;- plot_ly() %&gt;%\n  add_trace(x = ~X, y = ~p_aire, type = \"scatter\", mode = \"lines\", name = \"presión aire\", line = list(color = '#63B8FF')) %&gt;%\n  layout(title = \" \",\n         xaxis = list(title = \" \"),\n         yaxis = list(title = \"mbar\")) \nfig\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.2: Serie de tiempo de la presión del aire p (mbar) del 01 de Enero del 2009 al 01 de Enero del 2012.\n\n\n\n\nCódigo\nh_relativa&lt;-df_clima$rh.... #humedad relativa\nX&lt;- df_clima$Date.Time\nfig &lt;- plot_ly() %&gt;%\n  add_trace(x = ~X, y = ~h_relativa, type = \"scatter\", mode = \"lines\", name = \"Humedad relativa\", line = list(color = '#63B8FF')) %&gt;%\n  layout(title = \" \",\n         xaxis = list(title = \" \"),\n         yaxis = list(title = \"Porcentaje\")) \nfig\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.3: Serie de tiempo de la humedad relativa rh (%) del 01 de Enero del 2009 al 01 de Enero del 2012.\n\n\n\n\nCódigo\nd_aire&lt;-df_clima$rho..g.m..3. # Densidad del aire \nX&lt;- df_clima$Date.Time\nfig &lt;- plot_ly() %&gt;%\n  add_trace(x = ~X, y = ~d_aire, type = \"scatter\", mode = \"lines\", name = \"Humedad relativa\", line = list(color = '#63B8FF')) %&gt;%\n  layout(title = \" \",\n         xaxis = list(title = \" \"),\n         yaxis = list(title = \"g /m³\")) \nfig\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.4: Serie de tiempo de la densidad del aire rho (\\(g /m^3\\)) del 01 de Enero del 2009 al 01 de Enero del 2012.\n\n\n\n\nCódigo\nv_viento &lt;-df_clima$wv..m.s. # Velocidad del viento\nX&lt;- df_clima$Date.Time\nfig &lt;- plot_ly() %&gt;%\n  add_trace(x = ~X, y = ~v_viento, type = \"scatter\", mode = \"lines\", name = \"Humedad relativa\", line = list(color = '#63B8FF')) %&gt;%\n  layout(title = \" \",\n         xaxis = list(title = \" \"),\n         yaxis = list(title = \"g/m\")) \nfig\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.5: Serie de tiempo de la velocidad del viento wv (\\(m/s\\)) del 01 de Enero del 2009 al 01 de Enero del 2012.\n\n\n\n\n8.3.1.1 Estacionalidad\n\nCon el propósito de llevar a cabo una inspección visual y analítica de los datos y al mismo tiempo una descripción preliminar, se busca identificar los patrones de estacionalidad anual y diaria. Esto se puede apreciar claramente en los gráficos de autocorrelación. Para calcular la autocorrelación en R se utiliza la función acf(). Esta función proporciona estimaciones gráficamente de la autocorrelación que se puede representar el conjunto de datos históricos de la Temperatura (° F).\n\n\nCódigo\nacf(df_clima$T..degC., lag.max = 200, \n    main = \"Autocorrelación de Temperatura\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.6: Autocorrelación de los primeros 200 datos correspondiente a la Temperatura (° F) en su serie temporal.\n\n\n\n\nEn Figura 8.6 se observa que la autocorrelación los primeros 200 datos correspondiente a la Temperatura (° F) vistas como serie temporal. Teniendo en cuenta que el intervalo temporal entre observaciones es de 10 minutos, el patrón cíclico que se observa cada 144 observaciones corresponde al transcurso de 24 horas.\n\n\nCódigo\nacf(df_clima$T..degC., lag.max = 1000, \n    main = \"Autocorrelación de Temperatura\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.7: Autocorrelación de los primeros 1000 datos correspondiente a la Temperatura (° F) en su serie temporal.\n\n\n\n\nEn Figura 8.6 se observa que la autocorrelación los primeros 1000 datos correspondiente a la Temperatura (° F) en su serie temporal.\n\n\nCódigo\nacf(df_clima$T..degC., lag.max = 100000, \n    main = \"Autocorrelación de Temperatura\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.8: Autocorrelación de los primeros 100000 datos correspondiente a la Temperatura (° F) en su serie temporal.\n\n\n\n\nEn la Figura 8.8 podemos deducir que los datos históricos siguen un patrón cíclico que se observa es aproximadamente cada 52000 observaciones, es decir, corresponde al transcurso de un año.\n\n\n\n8.3.1.2 Prueba KPSS (Kwiatkowski-Phillips-Schmidt-Shin)\n\nA continuación, se emplea la prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) para examinar la presencia de estacionariedad en la serie temporal. Este test fué utilizado con la finalidad de identificar la existencia de raices unitarias en la serie, lo cual permite inferir la presencia o ausencia de estacionariedad en los datos analizados.\n\nLa hipótesis nula y la alternativa para la prueba KPSS son:\n\\[H_0:  El \\ modelo \\ es \\ estacionario\n\\ \\ \\qquad H_1: El \\  modelo \\  no \\ es \\  estacionario\\]\n\n\nCódigo\n#library(tseries)\nTemperatura_ts &lt;-datos_clima$`T (degC)`[1:105120] #Temperatura\nkpss.test(Temperatura_ts, null = \"Trend\")\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Temperatura_ts\nKPSS Trend = 21.053, Truncation lag parameter = 22, p-value = 0.01\n\n\n\nLa hipótesis nula \\(H_0\\) no asume la presencia de raíces unitarias, lo que indica no estacionariedad en la serie, al obtener un KPSS estadístico superior que el nivel de significancia establecido el cual es de \\(5 \\%\\) (\\(0.05\\)), se rechaza la hipótesis nula, sugiriendo la ausencia de estacionariedad en la serie de tiempo de Temperatura (° F). Por lo que vamos a utilizar técnicas para obtener la estacionariedad de la serie de tiempo.\nLuego, para hacer estacionarios los datos se aplicaron las siguientes transformaciones:\n\n\n\n8.3.1.3 Diferenciación\n\nSe aplicó las diferencias a los datos de Temperatura (° F) para buscar la estacionalidad de la serie de Tiempo.\n\n\nCódigo\n#library(tswge)\nd_Temperatura = artrans.wge(Temperatura_ts,phi.tr= 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.9: Diferencias de los datos de Temperatura (° F) en su serie temporal.\n\n\n\n\nEn la Figura 8.9 se observa que después de aplicar diferencias a los datos de Temperatura (° F) observamos que la serie presenta estacionalidad.\n\n\n\n\nCódigo\n#library(tseries)\n#d2_Temperatura = artrans.wge(d_Temperatura,phi.tr= 1)\nkpss.test(d_Temperatura, null = \"Trend\")\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  d_Temperatura\nKPSS Trend = 0.0026708, Truncation lag parameter = 22, p-value = 0.1\n\n\n\nAl aplicar la prueba KPSS a las diferencias a los datos de Temperatura (°F) en su serie de tiempo, se obtiene un kpss estadístico menor devuelto por el test, no se rechaza la hipótesis nula, confirmando la estacionariedad en la serie de tiempo de la Temperatura (°F).\n\n\n\n8.3.1.4 Estandarización\n\nPara que los datos sean comparables, es necesario estandarizarlos. Se ajustan los datos históricos en su serie de tiempo para que su media sea 0 y su desviación estándar sea 1.\n\n\n\n  [1] -1.555912e+00 -3.988778e-01  7.980539e-01  1.596903e-01  8.778494e-01\n  [6]  1.715702e+00  9.944162e-05 -1.156935e+00 -2.074582e+00 -1.316525e+00\n [11] -4.786733e-01  1.197926e-01  7.989489e-02  6.783608e-01  9.944162e-05\n [16] -1.594915e-01 -4.387755e-01 -1.195937e-01 -3.988778e-01  9.944162e-05\n [21]  3.192812e-01 -5.185710e-01 -2.392869e-01 -7.180596e-01 -1.037241e+00\n [26] -3.979828e-02  5.985653e-01 -4.786733e-01 -6.382642e-01 -1.594915e-01\n [31] -3.979828e-02 -8.776505e-01 -3.979828e-02  1.596008e+00 -6.382642e-01\n [36]  3.192812e-01  1.755599e+00  9.576448e-01 -5.185710e-01 -1.555912e+00\n [41]  1.037440e+00  1.835395e+00  6.384630e-01  5.985653e-01  3.990767e-01\n [46]  6.783608e-01  1.197926e-01 -1.594915e-01  3.192812e-01  4.389744e-01\n [51]  8.379517e-01  6.783608e-01 -3.589801e-01 -1.993892e-01  5.985653e-01\n [56]  1.077338e+00  5.586676e-01  5.187699e-01 -7.969601e-02  3.999717e-02\n [61] -4.786733e-01 -4.387755e-01 -3.190824e-01 -3.979828e-02 -2.392869e-01\n [66] -2.791846e-01  3.990767e-01  6.783608e-01  1.995881e-01  5.187699e-01\n [71]  6.384630e-01  3.990767e-01  2.793835e-01  3.591790e-01  3.990767e-01\n [76]  1.197031e+00  1.276827e+00  2.394858e-01  2.793835e-01 -5.584687e-01\n [81] -2.791846e-01  3.591790e-01 -2.392869e-01  3.990767e-01  3.192812e-01\n [86]  3.999717e-02 -3.979828e-02  1.197926e-01  1.596903e-01  6.384630e-01\n [91] -1.594915e-01  5.586676e-01  4.389744e-01 -1.594915e-01 -1.594915e-01\n [96]  3.591790e-01  1.197926e-01 -1.594915e-01  1.197926e-01 -1.594915e-01\n\n\n\n\n8.3.1.5 Normalización\n\nEsta transformación modifica la escala de los datos a un nuevo rango entre 0 y 1.\n\n\n\n  [1] 0.1326531 0.4285714 0.7346939 0.5714286 0.7551020 0.9693878 0.5306122\n  [8] 0.2346939 0.0000000 0.1938776 0.4081633 0.5612245 0.5510204 0.7040816\n [15] 0.5306122 0.4897959 0.4183673 0.5000000 0.4285714 0.5306122 0.6122449\n [22] 0.3979592 0.4693878 0.3469388 0.2653061 0.5204082 0.6836735 0.4081633\n [29] 0.3673469 0.4897959 0.5204082 0.3061224 0.5204082 0.9387755 0.3673469\n [36] 0.6122449 0.9795918 0.7755102 0.3979592 0.1326531 0.7959184 1.0000000\n [43] 0.6938776 0.6836735 0.6326531 0.7040816 0.5612245 0.4897959 0.6122449\n [50] 0.6428571 0.7448980 0.7040816 0.4387755 0.4795918 0.6836735 0.8061224\n [57] 0.6734694 0.6632653 0.5102041 0.5408163 0.4081633 0.4183673 0.4489796\n [64] 0.5204082 0.4693878 0.4591837 0.6326531 0.7040816 0.5816327 0.6632653\n [71] 0.6938776 0.6326531 0.6020408 0.6224490 0.6326531 0.8367347 0.8571429\n [78] 0.5918367 0.6020408 0.3877551 0.4591837 0.6224490 0.4693878 0.6326531\n [85] 0.6122449 0.5408163 0.5204082 0.5612245 0.5714286 0.6938776 0.4897959\n [92] 0.6734694 0.6428571 0.4897959 0.4897959 0.6224490 0.5612245 0.4897959\n [99] 0.5612245 0.4897959\n\n\n\nLuego del ajuste preliminar de los datos históricos en su serie de tiempo, se realizó una separación de los datos en dos grupos. Uno para entrenamiento y otro para testeo.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "estudio.html#sec-implementación-de-la-red-neuronal-lstm",
    "href": "estudio.html#sec-implementación-de-la-red-neuronal-lstm",
    "title": "8  Estudio de caso",
    "section": "8.4 Implementación de la red neuronal LSTM",
    "text": "8.4 Implementación de la red neuronal LSTM\n\nEn esta parte, se realizó el siguiente ajuste para su implementación en lenguaje Python dentro del alterno Colaboratory de los servicios gratuitos de google.\n\n\n8.4.1 Pronóstico mediante técnica rodante\nDe las los 144 datos por día. En cada paso, se actualiza la secuencia de entrada eliminando el valor más antiguo y agregando el último pronóstico como el valor más reciente. Esto se ilustra esquemáticamente en la Figura 8.10, donde \\(n\\) es la longitud rodante de la secuencia de entrada y \\(T\\) es la longitud de la serie Temporal.\n\n\n\n\\[\n\\begin{split}\ny:\\text{Observado}\\quad &\\quad \\hat{y}:\\text{Pronosticado}\\\\\ny_{T-n+1}\\quad y_{T-n+2}\\quad y_{T-n+3}\\quad&\\cdots\\quad y_{T-2}\\quad y_{T-1}\\quad y_T\\quad \\to\\quad \\color{orange}{\\hat{y}_{T+1}}\\\\\ny_{T-n+2}\\quad y_{T-n+3}\\quad y_{T-n+4}\\quad&\\cdots\\quad y_{T-1}\\quad y_{T}\\quad \\color{orange}{\\hat{y}_{T+1}}\\quad \\to\\quad \\color{orange}{\\hat{y}_{T+2}}\\\\\ny_{T-n+3}\\quad y_{T-n+4}\\quad y_{T-n+5}\\quad&\\cdots\\quad y_{T}\\quad \\color{orange}{\\hat{y}_{T+1}}\\quad \\color{orange}{\\hat{y}_{T+2}}\\quad \\to\\quad \\color{orange}{\\hat{y}_{T+3}}\\\\\ny_{T-n+4}\\quad y_{T-n+5}\\quad y_{T-n+6} \\quad & \\cdots\\quad\\color{orange}{\\hat{y}_{T+1}}\\quad\\color{orange}{\\hat{y}_{T+2}}\\quad\\color{orange}{\\hat{y}_{T+3}}  \\to\\quad \\color{orange}{\\hat{y}_{T+4}}\\\\\n&\\ddots \\\\\n\\end{split}\n\\]\n\n\nFigura 8.10\n\n\n\n\n\n8.4.2 Entrenamiento y calibración del modelo LSTM\n\nSe procede al entrenamiento del modelo LSTM. La cantidad de capas ocultas son 3. La primera capa LSTM, es una capas LSTM con 50 unidades (neuronas). La segunda capa LSTM posee las mismas propiedades que la capa anterior. Y la tercera capa, es una una capa densa de salida. El tamaño del lote (batch size) es de 157, indica el número de muestras que se usarán para actualizar los pesos del modelo en cada paso de entrenamiento. Esta configuración se llevó a cabo con una función de activación Adam, ejecutando 100 iteraciones para el entrenamiento de la red neuronal. La función de pérdida utilizada es el error cuadrático medio (MSE).\nA continuación se exhibe el código utilizado.\n\n\n\nCódigo\n# univariate cnn example\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.preprocessing import MinMaxScaler\npd.options.mode.chained_assignment = None\ntf.random.set_seed(0)\n\n\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Leer set de datos\nruta = '/content/drive/My Drive/Colab Notebooks/'\ndf = pd.read_csv(ruta+'datos_clima_wsu.csv')\nTimes = df['Date Time'] # Date\nTemperatura = df['T(C°)'] #Valiable\n#Tamaño de los Datos históricos\nTemperatura = Temperatura[(7*144):(22*144)] \nTemperatura = Temperatura + 273.15 \ny = pd.DataFrame({'Times': Times, 'Temperatura': Temperatura})\n# Convertir la columna 'fecha' al formato datetime de pandas\ny['Times'] = pd.to_datetime(y['Times'], format='%d.%m.%Y %H:%M:%S')\n\n# Establecer la columna 'fecha' como el índice de la serie de tiempo\ny.set_index('Times', inplace=True)\ny = y['Temperatura'].fillna(method='ffill')\ny = y.values.reshape(-1, 1)\n# Escalamos los datos\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler = scaler.fit(y)\ny = scaler.transform(y)\n\n\n\n\n\n\n\n\nFigura 8.11: Gráfica de la función de pérdida para la red neuronal LSTM\n\n\n\n\nEn la Figura 8.11 se observa la trayectoria del valor de la función de pérdida en cada época del entrenamiento en la red neuronal LSTM.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "estudio.html#sec-implementación-de-la-red-neuronal-cnn.",
    "href": "estudio.html#sec-implementación-de-la-red-neuronal-cnn.",
    "title": "8  Estudio de caso",
    "section": "8.5 Implementación de la red neuronal convolucional (CNN)",
    "text": "8.5 Implementación de la red neuronal convolucional (CNN)\n\nEn esta parte, se realizó el mismo ajuste que en la red neuronal LSTM para su implementación en Python dentro de un servidor gratuito de Colaboratory.\nSe procede al entrenamiento de la red neuronal convolucional (CNN).  La cantidad de capas ocultas son 5 capas, de las cuales, la primera capa es una capa es convolucional unidimensional, donde va aprender a través de 64 mapas de características y con un tamaño de kernel de dimensión 5. La segunda capa es una Capa Max-pooling unidimensional, la tercera capa es una capa de aplanar (flatten), la cuarta capa es una capa Densa, la quinta capa es Densa (salida). Asimismo, se eligió la función de activación ReLu, y el proceso de entrenamiento del modelo se ejecutó a lo largo de 25 iteraciones, 70 iteraciones y 100 iteraciones según los datos históricos.\nA continuación se exhibe el código utilizado.\n\n\n\nCódigo\n# univariate cnn example\nfrom numpy import array\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\nfrom tensorflow.keras.optimizers import RMSprop\nimport matplotlib.pyplot as plt\nfrom keras import backend as K\n\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.preprocessing import MinMaxScaler \n\n\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequence)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the sequence\n        if end_ix &gt; len(sequence)-1:\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\n\ndef train_and_plot_loss(model, X, y, epochs=20, verbose=1):\n    history = model.fit(X, y, epochs=epochs, verbose=verbose)\n    # Graficar el loss\n    plt.plot(history.history['loss'])\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.show()\n\n    \n    \nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n\n# Leer set de datos\nruta = '/content/drive/My Drive/Colab Notebooks/'\ndf = pd.read_csv(ruta+'datos_clima_wsu.csv')\n\nTemperatura = df['T(C°)'] #Valiable\n#Tamaño de los Datos historicos\nTemperatura = Temperatura[(7*144):(37*144)] \nTemperatura = Temperatura + 273.15 \n\n# Escalar los datos entre 0 y 1\nscaler = MinMaxScaler(feature_range=(0, 1))\nDatos_historicos = scaler.fit_transform(Temperatura.values.reshape(-1, 1))\n\n\n\n\n\n\n\n\nFigura 8.12: Gráfica de la función de pérdida obtenida mediante una CNN con el conjunto de datos históricos de la variable Temperatura (°F).\n\n\n\n\nEn la Figura 8.12 se muestra la variación del valor de la función de pérdida a lo largo del entrenamiento de la red neuronal convolucional (CNN).",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "estudio.html#comparación-de-resultados",
    "href": "estudio.html#comparación-de-resultados",
    "title": "8  Estudio de caso",
    "section": "8.6 Comparación de resultados",
    "text": "8.6 Comparación de resultados\n\nDe manera similar, la implementación de los modelos LSTM y CNN sigue la misma metodología para las cuatro variables restantes, abarcando desde la estandarización de los datos hasta el pronóstico de los días seleccionados.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "estudio.html#resultados-finales-del-estudio-de-caso",
    "href": "estudio.html#resultados-finales-del-estudio-de-caso",
    "title": "8  Estudio de caso",
    "section": "8.7 Resultados Finales del Estudio de Caso",
    "text": "8.7 Resultados Finales del Estudio de Caso\n\nLos pronósticos obtenidos de la red neuronal LSTM y la red neuronal CNN, fueron guardados en hojas de cálculo para facilitar su posterior análisis. La visualización de la similitud y la tendencia de los pronósticos con los datos históricos, se hará mediante gráficas y tablas. Las gráficas fueron realizados con Plotly, versión para R, una librería para la visualización de datos en gráficos interactivos.\n\n\nPara analizar el pronóstico, se utilizan datos históricos correspondientes a los periodos de 180 días (6 meses), 90 días (3 meses), 30 días (un mes) y 15 días. Es importante destacar que, para cada entrenamiento, se calibraron los parámetros del modelo LSTM y del modelo CNN de manera específica, teniendo en cuenta la longitud de los datos históricos utilizados.\n\n\nEl estudio del comportamiento de los próximos 7 días posteriores a los 180 días (6 meses) de datos históricos, requirió la configuración de la red neuronal convolucional, con 5 capas ocultas, se eligió la función de activación ReLu y el entrenamiento se ejecuta a 25 épocas para obtener 100 simulaciones. Por otro lado, con los mismos datos anteriores, se reconfiguró la red neuronal LSTM, con 3 capas ocultas tipo LSTM, se eligió el optimizador Adam con un tamaño de lote (batch size) de 314 y el entrenamiento se ejecuto a 25 épocas para obtener solo 10 simulaciones debido al largo tiempo de ejecución y que no se dispone de grandes recursos computacionales.\nPara el pronóstico de 4 días, se utilizaron 90 días (3 meses) de datos históricos, que en el caso de la configuración de la red neuronal convolucional, tiene 5 capas ocultas, se eligió la función de activación ReLu y fueron ejecutadas 70 épocas para obtener 50 simulaciones. En cambio, para el caso de la red neuronal LSTM se utilizaron 3 capas ocultas tipo LSTM se eligió el optimizador Adam con un tamaño de lote (batch size) de 314 y el entrenamiento se ejecutó a 70 épocas para obtener las mismas 50 simulaciones.\nDe manera similar, para ver el comportamiento de los próximos 4 días posteriores a los 30 días de datos históricos, se configuró la red neuronal convolucional con 5 capas ocultas, se eligió la función de activación ReLu y el entrenamiento se ejecutó 100 épocas con el fin de obtener 100 simulaciones. Por otro lado, la configuración de la red neuronal LSTM utiliza 3 capas ocultas tipo LSTM, se eligió el optimizador Adam con un tamaño de lote (batch size) de 157 y el entrenamiento se realizó durante 100 épocas para generar las mismas 100 simulaciones.\nPara pronosticar los próximos 2 días, se tomaron 15 días de datos históricos. La configuración de la red neuronal convolucional tiene 5 capas ocultas, se eligió la función de activación ReLu y su entrenamiento se ejecutó por 40 épocas para obtener como en el caso anterior 100 simulaciones. Por otro lado, la red neuronal LSTM tiene 3 capas ocultas tipo LSTM, se eligió el optimizador Adam con un tamaño de lote (batch size) de 157 y el entrenamiento se ejecutó a 100 épocas con el fin de obtener las mismas 100 simulaciones.\nDado que el comportamiento de cada variable en su serie de tiempo es diferente, fué necesario hacer ajustes específicos en los parámetros para que la arquitectura de los modelos implementados fuera adecuada para realizar el pronóstico. Se tomó un número apropiado de épocas para que el valor en la función de pérdida fuera lo suficientemente pequeño, evitando así el sobreentrenamiento del modelo y asegurando la precisión en los pronósticos. Manteniendo al mismo tiempo las propiedades cíclicas de los datos históricos.\n\nTodo lo anterior se resume en las siguientes gráficas Figura 8.13 , Figura 8.14 , Figura 8.16, Figura 8.15, Figura 8.17.\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.13: Predicción de 7 días, 4 días y 2 días de la Temperatura (° F) utilizando la red neuronal convolucional y la red neuronal LSTM\n\n\n\nLos resultados en la Figura Figura 8.13 de Temperatura (° F) indican que la mediana de los pronósticos a 7 días, 4 días y 2 días utilizando la red neuronal LSTM presenta una aproximación más precisa a los datos históricos que la pronosticada por la red neuronal convolucional.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.14: Predicción de 7 días, 4 días y 2 días de la presión del aire p(mbar) utilizando la red neuronal convolucional y la red neuronal LSTM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.15: Predicción de 7 días, 4 días y 2 días de la densidad del aire utilizando la red neuronal convolucional y la red neuronal LSTM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.16: Predicción de 7 días, 4 días y 2 días de la humedad relativa utilizando la red neuronal convolucional y la red neuronal LSTM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 8.17: Predicción de 7 días, 4 días y 2 días de la velocidad del viento utilizando la red neuronal convolucional y la red neuronal LSTM\n\n\n\n\n8.7.0.1 RMSE\n\nLuego de obtener los valores pronosticados por las redes propuestas, se tomó la mediana de los pronósticos y se procedió a contrastarlos con el error cuadrático medio (RMSE). Esto permitió determinar el menor valor del error y así identificar diferencias de usa los modelos de redes. Los resultados obtenidos se muestran en Tabla 8.1.\n\n\n\n\nTabla 8.1: RMSE de la mediana de los pronósticos para 5 variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRMSE\n\n\n\n\nDatos históricos\n180 días\n90 días\n30 días\n15 días\n\n\nNumero de días pronosticados\n7 días\n4 días\n4 días\n2 días\n\n\nTemperatura (CNN)\n7.748363\n12.544\n4.729259\n5.89646\n\n\nTemperatura (LSTM)\n3.035672\n7.350131\n3.267742\n4.281648\n\n\nVelocidad del viento (CNN)\n1.805565\n1.525929\n2.68279\n3.638407\n\n\nVelocidad del viento (LSTM)\n1.415952\n1.366431\n2.711044\n2.846553\n\n\nDensidad del aire (CNN)\n43.71869\n24.26363\n26.00116\n69.96927\n\n\nDensidad del aire (LSTM)\n14.33086\n43.15156\n22.59924\n38.28266\n\n\nHumedad relativa (CNN)\n23.77749\n34.24427\n21.69839\n10.64634\n\n\nHumedad relativa (LSTM)\n10.83128\n12.39585\n13.42141\n14.1402\n\n\nPresión del aire (CNN)\n9.351951\n19.09469\n17.30254\n17.22759\n\n\nPresión del aire (LSTM)\n3.638899\n3.289955\n9.254557\n22.74026\n\n\n\n\n\n\n\nA través de la Tabla 8.1, se observa inicialmente de que para estos datos meteorológicos, la red neuronal LSTM exhibe un error considerablemente menor en comparación con la red neuronal convolucional. Esto resulta en un pronóstico mas cercano a los valores reales, por lo tanto, se recomienda utilizar la red neuronal LSTM para llevar a cabo futuras predicciones.\nEn la Tabla 8.1 se observa que la red neuronal LSTM proporciona una mejor aproximación para la variable velocidad del viento, ya que el error cuadrático medio (RMSE) es significativamente menor en todos los pronóstico realizados en comparación con la red neuronal convolucional. Además, el mismo análisis en la Tabla 8.1 revela que, a medida que aumentan los datos históricos de la velocidad del viento, el RMSE tiende a disminuir.\nPor otro lado, se observa en Tabla 8.1 que el pronóstico para la densidad del aire no es tan preciso, ya que presenta el (RMSE) más alto en comparación con las demás variables. En ambos modelos, tanto la red neuronal LSTM como la red neuronal convolucional, no logran una buena predicción en los días pronosticados, comparado con la gráfica del valor real. Esta diferencia en la precisión del pronóstico podría deberse a varios factores. Uno de los factores potenciales es una posible falla en los sensores de densidad del aire. Los sensores podrían estar proporcionando datos inconsistentes, lo que afectaría la capacidad de los modelos para aprender patrones precisos y hacer predicciones confiables. Además, es posible que haya fluctuaciones no detectadas en las condiciones ambientales o interferencias externas que impacten la precisión de los sensores.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Estudio de caso</span>"
    ]
  },
  {
    "objectID": "Conclusiones.html",
    "href": "Conclusiones.html",
    "title": "Conclusiones",
    "section": "",
    "text": "El presente estudio ha abordado la complejidad en la modelación y el pronóstico de variables climáticas, mediante un análisis exhaustivo de los datos comprendidos entre el 1 de enero de 2009 y el 1 de enero de 2012. Se exploraron patrones a lo largo de intervalos de tiempo para evaluar la eficacia de distintos modelos predictivos.\nLas primeras arquitecturas de los modelos de redes neuronales LSTM y convolucional presentadas no arrojaron resultados significativos, por lo que se realizaron ajustes mediante simulaciones para calibrar los parámetros de cada variable. Esto subrayó la importancia de las predicciones generadas al compararlas con los valores reales, aunque el proceso de entrenamiento inicial tomó más tiempo de lo esperado. Sin embargo, al seleccionar los parámetros adecuados, se logró reducir tanto el tiempo de entrenamiento como el uso de recursos de memoria, optimizando así el rendimiento del modelo.\nLa implementación de los modelos de redes neuronales LSTM y convolucional se beneficiaron significativamente del uso de una GPU T4 en Google Colab. Debido a la gran cantidad de datos procesados, la ejecución en esta plataforma permitió acelerar ambos modelos, reduciendo el tiempo de procesamiento en aproximadamente un tercio en comparación con otras configuraciones de GPU normal.\nDentro de las 5 variables climáticas seleccionadas se hicieron ajustes estadísticos, debido a que en le proceso de estacionalidad, las 5 variables en los intervalos de tiempo se identificaron como no estacionales. Lo que hizo mas complejo la modelación del modelo de redes neuronales para su predicción.\nEs importante destacar que el caso de estudio se basa en el trabajo de (Fierro 2021), en el cual la adaptación de modelos de redes neuronales LSTM y convolucional permitió mejoras significativas, tanto en el tamaño del conjunto de datos utilizado para el entrenamiento como en la capacidad de pronosticar un mayor número de días. Estas mejoras son de las más relevantes dentro de esta tesis, especialmente al considerar cuidadosamente las limitaciones impuestas por los recursos computacionales disponibles. Al comparar los errores, se observó que la variable velocidad del viento presenta predicciones más cercanas a los valores mientras que la menos precisa fue la densidad del aire en comparación con otras variables climáticas.\n\n\n\n\n\nFierro, Ariel Alejandro. 2021. «Predicción de series temporales con redes neuronales». Tesis doctoral, Universidad Nacional de La Plata.",
    "crumbs": [
      "Conclusiones"
    ]
  },
  {
    "objectID": "Propuestas.html",
    "href": "Propuestas.html",
    "title": "Propuestas",
    "section": "",
    "text": "Una posible extensión de este trabajo es considerar para los pronósticos, otro modelos mas sofisticados de redes neuronales como la combinación de una red neuronal convolucional con una red neuronal con memoria a corto y largo plazo (LSTM) que seria un modelo híbrido. Así como implementar un modelo VAR (Vector AutoRegresivo) que es una extensión de los modelos autoregresivos univariados para analizar múltiples series de tiempo simultáneamente. Esto permitiría entrenar el modelo utilizando las 5 variables de estudio y poder hacer un pronostico múltiple. De poder ser implementado sería de mayor utilidad para el área geográfica que se este estudiando.",
    "crumbs": [
      "Propuestas"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Lista de obras consultadas",
    "section": "",
    "text": "Apicella, Andrea, Francesco Donnarumma, Francesco Isgrò, and Roberto\nPrevete. 2021. “A Survey on Modern Trainable Activation\nFunctions.” Neural Networks 138: 14–32.\n\n\nBowley, Arthur Lyon. 1926. Elements of Statistics. 8. King.\n\n\nBurkart, Nadia, and Marco F Huber. 2021. “A Survey on the\nExplainability of Supervised Machine Learning.” Journal of\nArtificial Intelligence Research 70: 245–317.\n\n\nCasella, G, and R Berger. 2002. “Statistical Inference.\n2aed.” Estados Unidos: Thompson Learning.\n\n\nCastañeda, Liliana Blanco, Viswanathan Arunachalam, and Selvamuthu\nDharmaraja. 2012. Introduction to Probability and Stochastic\nProcesses with Applications. John Wiley & Sons.\n\n\nCharles, M, J Grinstead, and L Snell. 1997. “Introduction to\nProbability.” American Mathematical Society.\n\n\nFierro, Ariel Alejandro. 2021. “Predicción de Series\nTemporales Con Redes Neuronales.” PhD thesis, Universidad\nNacional de La Plata.\n\n\nFontoura Costa, Luciano da, and Gonzalo Travieso. 1996.\n“Fundamentals of Neural Networks: By Laurene Fausett.\nPrentice-Hall, 1994, Pp. 461, ISBN 0-13-334186-0.” Elsevier.\n\n\nHe, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.\n“Deep Residual Learning for Image Recognition.” In\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, 770–78.\n\n\nHecht-Nielsen, Robert. 1990. “Neurocomputing, Addison.”\nWesely Publishing Company. Hornik, K. Stinchcombe, M. White,\nH.(1989). Multilayer Feedforward Networks Are Universal Approximators,\nNeural Networks 2 (359366): 3168–76.\n\n\nHubel, David H, and Torsten N Wiesel. 1959. “Receptive Fields of\nSingle Neurones in the Cat’s Striate Cortex.” The Journal of\nPhysiology 148 (3): 574.\n\n\nKingma, Diederik P, and Jimmy Ba. 2014. “Adam: A Method for\nStochastic Optimization.” arXiv Preprint\narXiv:1412.6980.\n\n\nKolmogorov, Andrey. 1941. “Interpolation and Extrapolation of\nStationary Random Sequences.” Izvestiya Rossiiskoi Akademii\nNauk. Seriya Matematicheskaya 5: 3.\n\n\nLeCun, Yann et al. 1989. “Generalization and Network Design\nStrategies.” Connectionism in Perspective 19 (143-155):\n18.\n\n\nMcCulloch, Warren S, and Walter Pitts. 1943. “A Logical Calculus\nof the Ideas Immanent in Nervous Activity.” The Bulletin of\nMathematical Biophysics 5: 115–33.\n\n\nMoor, James. 2006. “The Dartmouth College Artificial Intelligence\nConference: The Next Fifty Years.” Ai Magazine 27 (4):\n87–87.\n\n\nPütter, Johann Stephan, and Gottfried Achenwall. 1750. Elementa\nIuris Naturae. Schmidt.\n\n\nRosenblatt, Frank. 1958. “The Perceptron: A Probabilistic Model\nfor Information Storage and Organization in the Brain.”\nPsychological Review 65 (6): 386.\n\n\nRoss, Sheldon M. 2014. Introduction to Probability Models.\nAcademic press.\n\n\nRumelhart, David E, Geoffrey E Hinton, and Ronald J Williams. 1986.\n“Learning Representations by Back-Propagating Errors.”\nNature 323 (6088): 533–36.\n\n\nSchmidhuber, Jürgen, Sepp Hochreiter, et al. 1997. “Long\nShort-Term Memory.” Neural Comput 9 (8): 1735–80.\n\n\nWoodward, Wayne A, Henry L Gray, and Alan C Elliott. 2017. Applied\nTime Series Analysis with r. CRC press.",
    "crumbs": [
      "Lista de obras consultadas"
    ]
  }
]