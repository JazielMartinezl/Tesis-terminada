---
lang: es
---

# Series de tiempo

::: {style="text-align: justify"}
El surgimiento del análisis de series temporales se originó a partir de la necesidad de comprender y prever fenómenos que evolucionan con el tiempo. Este tipo de análisis tiene sus raíces en las primeras civilizaciones que registraron datos relacionados con fenómenos astronómicos y económicos. Un ejemplo de ello son los antiguos babilonios, quienes mantenían registros detallados de los movimientos planetarios, lo que les permitió identificar patrones cíclicos. De manera similar, los astrónomos griegos, como Hiparco y Ptolomeo, llevaron a cabo observaciones sistemáticas que contribuyeron al descubrimiento de ciclos en los movimientos celestes.

A inicios del siglo XX, el economista británico Sir Arthur Bowley y el estadístico ruso Andrey Kolmogorov realizaron importantes aportes al campo del análisis de series temporales. Bowley, en su obra [@bowley1926elements], utilizó gráficos para representar datos de series temporales y analizar las tendencias económicas. Por su parte, Kolmogorov, en su estudio [@kolmogorov1941interpolation], desarrolló teorías matemáticas fundamentales sobre los procesos estocásticos, que resultaron cruciales para el análisis de series temporales.

En esta sección, se iniciará presentando la definición formal de serie de tiempo como un caso particular de un proceso estocástico, junto con sus propiedades, las cuales son fundamentales para el desarrollo posterior de los temas.
:::

### Serie de tiempo

::: {#def-ts style="text-align: justify"}
Una serie de tiempo $\{X_t\}$ donde $t$ denota el tiempo, es una realización de un proceso estocástico $\{X_t(\omega)\}$ donde $\omega$ pertenece al espacio de probabilidad. Cada $X_t$ representa un valor de la variable en el tiempo $t$, y su comportamiento es determinado por una distribución de probabilidad.

El espacio parametral T puede toma valores dos formas principales dependiendo del tipo de proceso. Si $T$ es un conjunto discreto de valores, como $T= \{0,1,2,3 \}$, se dice que el proceso es de parámetro discreto. Este tipo de proceso se representa mediante $X_n$, donde $X_n$ indica el valor del proceso en el tiempo $n$.

Por otro lado, si el conjunto parametral $T$ toma valores en un intervalo continuo, como, $T=[0,\infty)$, el proceso se clasifica como un proceso de parámetro continuo y se representa mediante $\{X_t:t \geq 0\}$. En este caso, los tiempos $t$ son continuos y el proceso se define para todos los valores de $t$ en el intervalo $[0,\infty)$.
:::

### Realización

::: {#def-realizacion style="text-align: justify"}
<!-- Una realización de serie de tiempo $\{X_t\}$ es un conjunto específico de observaciones que representan un valor real, $X_t(\omega)$ para un valor fijo $\omega \in \Omega$. -->

Sea $\omega \in \Omega$. Una realización de serie de tiempo $\{X_t\}$ es un conjunto específico de observaciones que corresponde a los valores reales $X_t(\omega)$.
:::

:::: {#exm-realizacion style="text-align: justify"}
::: {.callout-caution collapse="true" icon="false"}
#### **Serie de Tiempo: Precios de las Acciones de Tesla (1 de Enero de 2020 - 30 de Abril de 2021)**

La @fig-realizacion presenta un gráfico que muestra la evolución de los precios de las acciones de Tesla desde el 1 de Enero de 2020 hasta el 30 de Abril de 2021. El análisis revela una tendencia alcista pronunciada que alcanzó su punto máximo en enero de 2021. Posteriormente, los precios permanecieron relativamente estables hasta Febrero de 2021, momento en el que experimentaron una caída. Al redactar esta sección, se observa una leve recuperación en el valor de las acciones.

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
#| label: fig-realizacion
#| fig-cap: "Precios de las acciones de Tesla desde el 1 de Enero de 2020 hasta el 30 de Abril de 2021."

library(tswge)

data(tesla)
tesla.3= ma.smooth.wge(tesla,order= 3,plot= FALSE)
tesla.8= ma.smooth.wge(tesla,order= 8,plot= FALSE)
plot(tesla)


```
:::
::::

## Autocorrelación {#sec-autocorrelación}

::: {#.remark style="text-align: justify"}
Dentro del interés de las series de tiempo, como el análisis de la media y la varianza para dos variables aleatorias $X(t_1)$ y $X(t_2)$ para $t_1,t_2 \in T.$ Es la forma en que se relacionan dos valores dentro de la misma serie de tiempo esto se refiere a la [correlación](Estadistica.qmd#sec-correlacion) que se puede ver en la misma serie con la autocorrelación y denota por la expresión ([-@eq-autocorr]).

$$
\gamma(t_1,t_2):=\mathrm{E}[(X(t_1)-\mu(t_1))(X(t_2)-\mu(t_2))]
$$ {#eq-autocov} y $$
\rho(t_1,t_2):= \frac{\gamma(t_1,t_2)}{\sigma(t_1)\sigma(t_2)} 
$$ {#eq-autocorr} donde la expresión en ([-@eq-autocov]) calcula la autocovarianza.
:::

:::: {style="text-align: justify"}
::: {.callout-caution collapse="true" icon="false"}
#### **Autocorrelación : Datos sobre el lince canadiense**

La @fig-autoc (a) muestra la cantidad anual de linces canadienses atrapados en el distrito del río Mackenzie en el noroeste de Canadá durante el período $1821-1934$. Las autocorrelaciones de la población de los linces canadienses se presentan en la @fig-autoc (b).

```{r echo=FALSE, message=FALSE, warning=FALSE,results='hide'}
#| label: fig-autoc
#| fig-cap: " Gráfico de autocorrelaciones de la población de linces (1820 - 1934)."
#| fig-subcap:
#|   - "Datos sobre el lince canadiense"
#|   - "Autocorrelación de la muestra"
#| layout-ncol: 2
    
library(tswge)
data(tswge)
plot(lynx, type = "l", main = "Número de lince canadiense(1820-1934)", ylab = "Número de linces", xlab = "Año")
acf(lynx, main = " ", ci = 0)

```
:::
::::

<!-- [correlación](Estadistica.qmd#sec-correlacion) -->

<!-- [covarianza](Estadistica.qmd#sec-covarianza) -->

## Series de tiempo estacionales {#sec-series-estacionales}

::: {style="text-align: justify"}
Las series de tiempo, al ser procesos estocásticos, poseen sus mismas propiedades, como es el caso de las estacionalidad. En consecuencia, se define en seguida un proceso estrictamente estacionario.
:::

::: {#def-pecreciente style="text-align: justify"}
#### Proceso estrictamente estacionario

Un proceso es estrictamente estacionario si la distribución conjunta de cualquier conjunto de observaciones es invariante bajo desplazamientos en el tiempo. Para cualquier $t_1,t_2, \dots,t_n$ y cualquier desplazamiento $h$, la distribución conjunta de $(X_{t_1},X_{t_2},\dots,X_{t_n})$ es la misma que $(X_{t_1+h},X_{t_2+h},\dots,X_{t_n+h})$
:::

::: {#def-estcov style="text-align: justify"}
#### Estacionariedad por covarianza

La serie de tiempo $\{X(t)\}$ donde $t \in T$ se considera estacionaria por covarianza si

i.  $\mu_{_{X_t}}=\mathrm E[X(t)] = \mu$ (media constante para todo $t$).

ii. $\sigma^2_{_{X_t}}=\mathrm{Var}[X(t)] = \sigma^2 < \infty$ (es decir, una constante finita para todo $t$).

iii. $\gamma_{_{X_{t_1},X_{t_2}}}$ y $\rho_{_{X_{t_1},X_{t_2}}}$ depende solo de $t_2 − t_1$.
:::

## Proceso de ruido blanco {#sec-ruidob}

::: {style="text-align: justify"}
Un [proceso de ruido blanco](series.qmd#sec-ruidob) es clave en el análisis de series de tiempo, ya que representa un proceso completamente aleatorio donde no hay correlación entre observaciones en diferentes tiempos. Esto implica que no existen patrones o dependencias temporales dentro de la serie, lo que lo convierte en un punto de referencia importante en la construcción de modelos.
:::

::: {#def-ruidob}
#### Proceso de ruido blanco

Se dice que un proceso $X_t$ es ruido blanco si se cumplen las siguientes condiciones:

1.  Cada $X_t$ tiene media cero y varianza finita $\sigma^2_X$.
2.  $X_{t_1}$ y $X_{t_2}$ no son correlacionadas si $t_1=t_2$.
:::

::: {style="text-align: justify"}
Un proceso de ruido blanco no tiene memoria, lo que significa que el valor en un tiempo $t$ no ofrece ninguna información sobre los valores en otros tiempos.

**Representación gráfica de los datos y comprobación del ruido blanco.**

Siempre que se ajusta un modelo a un conjunto de datos, primero se debe representar gráficamente los datos y las autocorrelaciones de muestra. Algo que se debe comprobar en estos gráficos es si los datos son simplemente ruido blanco o si muestran una estructura no estacionaria evidente. Una prueba rápida de ruido blanco se basa en los siguientes hechos sobre las autocorrelaciones de muestra de los datos de ruido blanco.

$$
E\left[ \hat{\rho}_k \right] \approx 0 \quad \text{para} \quad k \neq 0.
$$

El error estándar de $\hat{\rho}_k$ es aproximadamente $1/\sqrt{n}$, $k \neq 0$, por lo que para $n$ moderadamente grande, los $\hat{\rho}_k$ deberían ser pequeños. $\hat{\rho}_{k_1}$ y $\hat{\rho}_{k_2}$ son esencialmente no correlacionados cuando $k_1 \neq k_2$. <!-- Basándonos en los hechos anteriores, rechazamos $H_0: \rho_k = 0$ vs. $H_a: \rho_k \neq 0$ al nivel de significancia del $5\%$ si $$ \| \hat{\rho}\_k \| \> 1.96 \left( \frac{1}{\sqrt{n}} \right). $$ --> Es común acompañar las gráficas de autocorrelaciones muéstrales que podrían provenir de ruido blanco con líneas límite $(95\%)$ en $\pm 2/\sqrt{n}$.
:::

::::: {style="text-align: justify"}
:::: {.callout-caution collapse="true" icon="false"}
#### **Representacion grafica de un ruido blanco**

La @fig-noise muestra una realización de longitud $n = 150$ a partir de un proceso de ruido blanco generado por la librería (tswge) en R.

::: {#fig-noise}
```{r, message=FALSE}
  library(tswge)
  # Generar una realización de ruido blanco
  set.seed(147)
  x = gen.arma.wge(n = 150, phi = 0, theta = 0)
  
```

Gráfica de un ruido blanco
:::

La @fig-noise es coherente con el ruido blanco en el sentido de que no hay patrones cíclicos ni desviaciones y los datos simplemente parecen ser aleatorios sin correlación con otros valores.
::::
:::::

## Densidad espectral

::: {style="text-align: justify"}
Para identificar el contenido en frecuencias de una serie temporal estacionaria, se utiliza el espectro, o en su forma estandarizada, la densidad espectral. Esta herramienta es fundamental para detectar el comportamiento subyacente de las frecuencias en los datos de series temporales estacionarias.
:::

::: {#def-espectro}
#### Especto

Sea $( X_t )$ una serie temporal estacionaria con autocovarianza $( \gamma_k )$ y autocorrelación $(\rho_k)$. Entonces para $|f| \leq 0.5$ :

El espectro de $( X_t )$ está definido por, $$
    P_X(f) = \sum_{k=-\infty}^{\infty} e^{-2\pi ifk} \gamma_k.
$$ {#eq-espectro}
:::

::: {#def-despectral}
#### Densidad espectral

Sea $( X_t )$ una serie temporal estacionaria con autocovarianza $( \gamma_k )$ y autocorrelación $( \rho_k )$. Entonces para $|f| \leq 0.5$ :

La densidad espectral de $( X_t )$ está definido por $$
    S_X(f) = \sum_{k=-\infty}^{\infty} e^{-2\pi ifk} \rho_k.
$$ {#eq-despectral}
:::

::: {style="text-align: justify"}
**Formula de Euler.** El espectro y la densidad espectral de una serie temporal se definen como funciones de frecuencia. A continuación se indican algunas fórmulas trigonométricas y de variables complejas importantes para completar:

a)  $\sin(- \theta) = - \sin (\theta)$

b)  $\cos( \theta) = \cos (- \theta)$

c)  $e^{i \theta} = \cos (\theta) + i \sin (\theta)$

d)  $e\^{-i \theta} = \cos (\theta) - i \sin (\theta)$

Utilizando la fórmula de Euler, se obtienen las fórmulas : $$
P_X(f) = \sigma_X^2 + 2 \sum_{k=1}^{\infty} \gamma_k \cos(2\pi fk),
$$ {#eq-espectro2} y $$
S_X(f) = 1 + 2 \sum_{k=1}^{\infty} \rho_k \cos(2\pi fk).
$$ {#eq-despectral3}

Estas fórmulas enfatizan que el espectro y la densidad espectral son funciones de valores reales, lo cual no es evidente a partir de las ecuaciones ([-@eq-espectro]) y ([-@eq-despectral]).
:::

### Estimación de la densidad espectral

::: {style="text-align: justify"}
Dada una realización de longitud $n$ de una serie temporal, no se dispone con suficiente información para calcular la densidad espectral "real" descrita en la ecuación ([-@eq-despectral3]), que requiere una suma infinita de autocorrelaciones. Además, en un conjunto real de datos de series temporales, las autocorrelaciones "real" no son conocidas. Aunque la ecuación ([-@eq-despectral3]) involucra una suma infinita de autocorrelaciones $\rho_k$, solo se cuenta con estimaciones $\hat{\rho}_k$ definidas en (3.12). Según (3.10), para una realización de longitud $n$, se puede calcular $\hat{\rho}_k$ para $k = 1, 2, ..., n-1$.
:::

#### La densidad espectral de la muestra {#sec-ESDM}

La estimación natural de la densidad espectral se obtiene al sustituir las autocorrelaciones de la muestra en la fórmula para $S_X(f)$. Usando

$$
\hat{S}_X(f) = 1 + 2 \sum_{k=1}^{n-1} \hat{\rho}_k \cos(2\pi f k), \quad |f| \leq 0.5
$$ {#eq-espectralestimate}

La estimación en ([-@eq-espectralestimate]) es llamada **estimación de la densida espectral**.

::::: {.content-visible when-format="pdf"}
:::: {#exm-sampespectral}
::: {.callout-caution collapse="true" icon="false"}
#### **Estimación de la densidad de un modelo AR**

La @fig-sampleespectral (a) muestra la realización a partir de un [modelo autorregresivo](series.qmd#sec-AR) con una línea vertical en $t = 100$. La @fig-sampleespectral (b) muestra la [densidad espectral de la muestra](series.qmd#sec-ESDM) calculada usando ([-@eq-espectralestimate]) con base en los primeros 100 puntos de tiempo en la @fig-sampleespectral (a) (es decir, aquellos que ocurren antes de la línea vertical en $n = 100$). Los dos picos son visibles, pero el comportamiento de la densidad espectral de la muestra es muy errático (variable). Mientras que la densidad espectral verdadera es una curva suave, la densidad espectral de la muestra no es suave en absoluto.

A continuación, se calcula la densidad espectral de la muestra en función de la realización completa de la longitud $n = 200$ en la @fig-sampleespectral (a). La densidad espectral de la muestra resultante para la longitud de realización más larga se representa gráficamente en la @fig-sampleespectral (c). No hay una mejora aparente con respecto al gráfico de la @fig-sampleespectral (b). La mayoría de los estimadores, como la media de la muestra y la varianza de la muestra, tienden hacia los valores verdaderos a medida que aumenta el tamaño de la muestra. El comportamiento de la densidad espectral de la muestra es inusual y decepcionante.

![Gráficos que muestran Realización de un modelo AR, (b) densidad espectral de la muestra basada en los primeros 100 puntos (a la izquierda de la línea vertical) en (a), (c) densidad espectral de la muestra para toda la realización en (a); (d), (e) y (f): Estimaciones de densidad espectral de Parzen para M = 28 (valor predeterminado), 8 y 175, respectivamente, para la realización de 200 puntos en (a).](estimacion_densidad_ar.png){#fig-sampleespectral fig-align="center"}
:::
::::
:::::

## Modelo Autorregresivo {#sec-AR}

:::::: {style="text-align: justify"}
::: {#def-AR1}
#### Modelo AR(1)

Se dice que la serie temporal, $X_t,$  satisface un modelo AR(1) si, 
$$
X_t = \beta + \phi_1 X_{t-1} + a_t
$$ {#eq-ar1}
:::

donde $\phi_1$ es una constante real distinta de cero y $a_t$ es un [proceso de ruido blanco](series.qmd#sec-ruidob) con varianza finita $\sigma_a^2.$ La constante $\beta = (1- \phi_1) \mu$, se denomina **constante de media móvil**. En esencia, el modelo AR(1) especifica que el valor del proceso en el momento $t$ depende del valor del proceso en el momento $t −1$, más un componente de ruido aleatorio $a_t$, y una constante $\beta$.

::: {#thm-AR1es style="text-align: justify"}
#### Estacionareidad de un AR(1)

Un proceso AR(1) es estacionario si y solo si $\phi_1 < 1$.
:::

::: proof
Vea @woodward2017applied.
:::
::::::

### Operador de retroceso de un AR(1)

::: {style="text-align: justify"}
El modelo AR(1) se expresa a veces utilizando el operador de retroceso definido por $BX_t  = X_{t−1}.$ Nótese que $B_c = c$ para una constante $c$. El modelo AR(1) mostrado en la ecuación ([-@eq-ar1]) se puede escribir como:

$$
X_t= (1-\phi) \mu + \phi X_{t-1} + a_t
$$ {#eq-op}

La ecuación ([-@eq-ar1]) también se puede expresar de la siguiente forma:

$$
X_t-\mu - \phi_1(X_{t-1} - \mu) = a_t
$$ {#eq-op1}

O , en la notación del operador de desplazamiento hacia atrás:

$$
(1-\phi_1 B)(X_t-\mu) = a_t
$$ {#eq-op2}

Alternativamente, también puede ser definido como:

$$
\phi(B)(X_t - \mu) = a_t
$$ {#eq-op3}

Donde $\phi (B)$ es el operado definido como $\phi (B) = 1- \phi_1 B.$
:::

::: remark
Si un proceso AR(1) $X_t$ tiene media $\mu$, se puede crear un proceso de media cero $\tilde{X}_t$ , definiéndolo como $\tilde{X}_t = X_t - \mu.$
:::

## Densidad espectral de un modelo AR(1)

En el caso del modelo AR(1), la densidad espectral está dada por,

$$
\begin{split}
  S_X(f) &= \frac{\sigma_a^2}{\gamma_0} \frac{1}{\left| 1 - \phi_1 e^{-2 \pi i f} \right|^2} \\ 
        &= \frac{1 - \phi_1^2}{\left| 1 - \phi_1 e^{-2 \pi i f} \right|^2}.
\end{split}
$$ {#eq-dear1}

Usando la fórmula de Euler, $e^{-2\pi if} = \cos 2 \pi if - i \sin 2\pi if$ , el denominador de la ecuación ([-@eq-dear1]) se convierte en

$$
\begin{split}
  \left| 1 - \phi_1 e^{-2 \pi i f} \right|^2 &= \left| 1 - \phi_1 \left( \cos 2 \pi f - i \sin 2 \pi f     \right) \right|^2\\
  &= \left| (1 - \phi_1 \cos 2 \pi f) - i \phi_1 \sin 2 \pi f \right|^2\\
  &= (1 - \phi_1 \cos 2 \pi f)^2 + (\phi_1 \sin 2 \pi f)^2.
\end{split}
$$ {#eq-dear2}

porque $|a + bi|^2 = a^2 + b^2$, así, la ecuación ([-@eq-dear1]) se puede escribir como,

$$
S_X(f) = \frac{1 - \phi_1^2}{(1 - \phi_1 \cos 2 \pi f)^2 + (\phi_1 \sin 2 \pi f)^2}.
$$ {#eq-dear3}

En la ecuación ([-@eq-dear3]) hemos simplificado la fórmula para $S_X (f )$ en la ecuación ([-@eq-dear1]) para enfatizar el hecho de que $S_X( f)$ es un número real.

<!--  

## Modelos AR(1) con raíces positivas de la ecuación característica.

::: {style="text-align: justify"}
Considere el modelo AR(1) $$
X_t - 0.9 X_{t-1} = a_t.
$$ {#eq-AR1root} y $$
X_t - 0.7 X_{t-1} = a_t.
$$ {#eq-AR1root1} donde $a_t$ es ruido blanco de media cero con varianza $\sigma_a^2$.

:::

-->

## Modelos AR(1) con raíces cercanas a +1

::: {style="text-align: justify"}
La @fig-noise muestra realizaciones de dos modelos AR(1) con raíces cercanas a uno en valor absoluto. Específicamente, se mostraron realizaciones de modelos AR(1) $(1 - \phi_1 B)(X_t - 10) = a_t$, con $\phi_1 = 0.95$ y $\phi_1 = 0.99.$ <!-- Observando que la media teórica del modelo del que se generaron estas realizaciones es $\mu = 10$ (que se traza como una línea horizontal en las gráficas), se puede ver que hay un considerable deambular, aperiodico y sin dirección por encima y por debajo de la media, especialmente para $\phi_1 = 0.99$. --> Esto se describe indicando que, para $\phi_1 = 0.95$ y $0.99,$ las autocorrelaciones, $\rho_k = \phi_1^k,$ son fuertes (o persistentes). Es decir, las autocorrelaciones siguen siendo sustanciales incluso cuando $k$ es moderadamente grande. Como ejemplo, para $\phi_1 = 0.99,$ sorprendentemente $\rho_{50} = 0.99^{50} = 0.61.$ Lo que significa que existe una correlación de $0.61$ entre observaciones separadas por 50 periodos de tiempo.

El comportamiento de deambular sostenido aumenta a medida que los valores de $\phi_1$ se acercan a $\phi_1 = 1.$ Para $\phi_1 = 1,$ el modelo no es un modelo AR(1) estacionario porque el valor absoluto de la raíz es igual a uno en lugar de mayor a uno.

```{r echo=FALSE, message=FALSE, warning=FALSE,results='hide'}
#| label: fig-noise
#| fig-cap: "Grafica de dos modelos AR(1) con raíces cercanas a uno en valor absoluto."
#| fig-subcap:
#|   - "Realización con  φ1 = .95"
#|   - "Realización  φ1 = .99"
#| layout-ncol: 2
    
library(tswge)
x=gen.arma.wge(n = 150, phi = 0.95, sn = 305)
y=gen.arma.wge(n = 150, phi = 0.99, sn = 404)
#plot(x)
#plot(y)
```
:::

::::: {.content-visible when-format="pdf"}
:::: {#exm-DOW}
::: {.callout-caution collapse="true" icon="false"}
#### **Ejemplo Dow Jones Stock Market Data**

La @fig-DOW (a) muestra los promedios mensuales de cierre del Dow Jones desde Marzo de 1985 hasta Diciembre de 2020, utilizando el conjunto de datos`dow1985.ts` de la librería `tswge`. En este análisis, el modelo subyacente es desconocido, por lo que no disponemos de las autocorrelaciones o la densidad espectral exactas del proceso. Por lo tanto, debemos basar nuestro análisis en la realización de la serie temporal y en las estimaciones de autocorrelaciones y densidad espectral correspondientes, basadas en muestras.

Se observar que la serie temporal presenta un comportamiento errático, característico de un proceso AR(1) con $\phi_1$ positivo. Las autocorrelaciones muestrales se muestran en las Figuras ([-@fig-DOW] (b)) y ([-@fig-DOW] (c)), respectivamente. En estas, se puede ver que las autocorrelaciones se amortiguan lentamente, mientras que la densidad espectral muestra un pico en frecuencia cero.

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
#| label: fig-DOW
#| fig-cap: "(a) Promedios de cierre mensuales del Dow Jones desde Marzo de 1985 hasta Diciembre de 2020, (b) muestras de autocorrelaciones y (c) estimación de densidad espectral de Parzen."


# Cargar el conjunto de datos
data("dow1985")
# Crear secuencia de fechas desde marzo de 1985 hasta diciembre de 2020
fechas <- seq(as.Date("1985-03-01"), as.Date("2020-12-01"),
              by = "month")
fechas <- fechas[1:length(dow1985)]
par(mfrow = c(1, 3))

# a) Gráfico del Dow Jones Index
plot(fechas, dow1985, type = "l", main = "(a) DOW Jones Index", 
     xlab = "Year", ylab = "", xaxt = "n")
axis(1, at = seq(fechas[1], fechas[length(fechas)], by = "years"),
     labels = format(seq(fechas[1], fechas[length(fechas)], 
                         by = "years"), "%Y"))

# b) Gráfico de autocorrelación
acf(dow1985, main = "(b) Muestras de Autocorrelations", 
    ylab = "Autocorrelation", xlab = "Lag")

# c) Gráfico de densidad espectral
spectrum(dow1985, main = "(c) Densidad Espectral Estimada", 
         log = "no", xlim = c(0, 0.5), ylab = "dB", 
         xlab = "Frequency")
```

Al comparar la @fig-DOW (a) con la @fig-noise, es evidente que $\phi_1$ parece estar cercano a uno, lo que sugiere que el modelo es casi no estacionario, o incluso no estacionario en el caso de $\phi_1 = 1$.
:::
::::
:::::

## Descomposición de series de tiempo

::: {style="text-align: justify"}
Se ha identificado que las series de tiempo pueden presentar estacionalidad, una componente que se añade o se multiplica con otras componentes como la tendencia y la aleatoriedad. En el análisis de series temporales, los expertos suelen enfocarse en dos categorías principales de modelos estacionales:

**Datos estacionales aditivos**.

En estos modelos, los datos $x_t$ en el tiempo $t$ se consideran como una suma de tres componentes: Un componente de tendencia a largo plazo $(tr_t)$, Un componente de estacional $(s_t)$ y, Un componente de variabilidad aleatoria $(z_t)$.

La ecuación que representa este modelo es:

$$
x_t = s_t + tr_t + z_t.
$$ {#eq-daditive}

**Datos estacionales multiplicativos**.

En este enfoque, los datos $x_t$ en el tiempo $t$ se expresan como el producto de las mismas tres componentes mencionadas y se representa en la ecuación:

$$
x_t = s_t \times tr_t \times z_t
$$ {#eq-dmultiplicative}
:::

### Conjunto de datos de series temporales

#### Datos Ciclicos

::: {style="text-align: justify"}
Muchos conjuntos de datos de series temporales presentan patrones cíclicos, caracterizados por fluctuaciones que se repiten de manera regular o casi regular a lo largo del tiempo. A este tipo de datos se les suele denominar **pseudoperiódicos**, un término que utilizaremos de manera intercambiable con **cíclicos** para describir su comportamiento.

Los datos verdaderamente periódicos presentan un comportamiento que se repite de manera exacta a lo largo de un intervalo de tiempo fijo. Un ejemplo claro de este tipo de datos es la curva sinusoidal. En contraste, los datos pseudoperiódicos o cíclicos son aquellos que tienden a repetir patrones, pero sin una regularidad exacta. Los datos de temperatura mensual de Dallas-Ft. Worth (DFW) de la @fig-dfw son un ejemplo de datos cíclico.
:::

:::::::: {#exm-DFW style="text-align: justify"}
::::::: {.callout-caution collapse="true" icon="false"}
#### **Datos de temperatura para Dallas-Ft. Worth (DFW)**

La @fig-dfw presenta la temperatura promedio mensual en Dallas-Ft. Worth (DFW) desde Enero de 1900 hasta Diciembre de 2020. Aunque los detalles pueden no ser evidentes a simple vista, las temperaturas siguen el patrón estacional esperado, con valores más bajos en invierno y, en el caso de DFW, temperaturas notablemente altas durante el verano.

::: {#fig-dfw}
```{r echo=FALSE, message=FALSE}
  library(tswge)
  # Crear una secuencia de fechas desde 1900 hasta 2020 (mensual)
  years <- seq(from = 1900, to = 2020 + 11/12, by = 1/12) 
  # Graficar la serie temporal con el eje X adecuado
  plot(years, dfw.mon, type = "l", 
       main = " ", 
       xlab = "Años", 
       ylab = "Temperatura (°F)",
       ylim = c(40, 90))
```

Temperatura media mensual en Dallas-Ft. Worth desde Enero de 1900 hasta Diciembre de 2020
:::

Al observar los datos de la @fig-dfw, se puede apreciar nuevamente el valor de enfocarse en un fragmento de tiempo específico, que en este caso corresponde a los años 1979 a 1986. Para los propósitos del estudio, se define un ciclo como la cantidad de meses entre el mes más caluroso de cada año. En DFW, se identifica que el mes más caluroso es julio o agosto. Es importante notar que los datos de temperatura muestran una progresión suave desde el verano al invierno y viceversa, con temperaturas promedio similares durante el otoño y la primavera. El patrón general que resulta es, de alguna manera, **sinusoidal** o **pseudosinusoidal**.

Es útil observar que habrá variaciones aleatorias (ruido) en los datos. El mes más cálido de 1979 a 1981 fue Julio. El mes más cálido de 1982 fue Agosto, por lo que el tercer ciclo en el gráfico tiene una duración de 13 meses. Agosto también fue el mes más cálido de 1983 a 1985, por lo que los tres ciclos siguientes tienen una duración de 12 (Agosto a Agosto). Finalmente, en 1986 el mes más cálido fue Julio, por lo que la duración del ciclo correspondiente es de 11 meses. Si bien las duraciones de los ciclos no fueron todas iguales a 12 meses, tenga en cuenta que siempre que ocurre un ciclo de 13 meses, siempre es seguido por un ciclo de 12 meses o de 11 meses para "mantenerse en sincronía o volver a sincronizarse". Es decir, supongamos que el mes más cálido de un año es Julio y luego los dos años siguientes tuvieron ciclos de temperatura con una duración de 13. Eso indicaría que el mes más cálido del tercer año fue Septiembre, que nunca ha sido el mes más cálido en DFW en el conjunto de datos disponible desde septiembre de 1898.

Los datos de temperatura de DFW en @fig-dfw son un ejemplo de datos cíclicos con una duración de ciclo fija. En este caso, el ciclo de 12 meses tiene una causa física: el movimiento regular y predecible de la Tierra alrededor del Sol. Debido a que los ciclos de temperatura están relacionados con el año calendario, los datos de temperatura se denominan datos estacionales.

::: remark
La diferencia clave entre los datos de manchas solares y los datos de temperatura es que, mientras que las duraciones de los ciclos de manchas solares tienden a variar aleatoriamente entre 9 y 13 años, las duraciones de los ciclos de temperatura son fijas hasta el punto de que permanecen "sincronizadas" con el año de 12 meses.
:::

::: {#fig-dfwtem}
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tswge)
  data(dfw.mon)
  # Crear una secuencia de fechas desde enero de 1900 hasta diciembre de 2020 (mensual)
  years <- seq(from = 1900, to = 2020 + 11/12, by = 1/12) 
  # Filtrar los datos para el período de 1979 a 1986
  years_filtered <- years[years >= 1979 & years <= 1986]
  dfw_filtered <- dfw.mon[which(years >= 1979 & years <= 1986)]
  # Graficar la serie temporal de 1979 a 1986
  plot(years_filtered, dfw_filtered, type = "o", pch = 19, 
       main = " ", 
       xlab = "Años ", 
       ylab = "  Fahrenheit",
       ylim = c(40, 90))
  # Añadir las líneas verticales para dividir los años
  abline(v = 1979, col = "black", lty = 2)
  abline(v = 1980, col = "black", lty = 2)
  abline(v = 1981, col = "black", lty = 2)
  abline(v = 1982, col = "black", lty = 2)
  abline(v = 1983, col = "black", lty = 2)
  abline(v = 1984, col = "black", lty = 2)
  abline(v = 1985, col = "black", lty = 2)
  abline(v = 1986, col = "black", lty = 2)

```

Temperatura media mensual en Dallas, Texas, correspondiente al periodo de 1979 a 1986, extraído de un fragmento de @fig-dfw.
:::

::: remark
La duración de los ciclos de temperatura es fija hasta el punto de que se mantienen “sincronizados” con el año de 12 meses.
:::
:::::::
::::::::

#### Tendencia

::: {style="text-align: justify"}
Una tendencia (Trends) es una tendencia de los datos a aumentar (o disminuir) de manera constante a lo largo del tiempo.

Los datos que presentan una tendencia o un comportamiento de deambulación aleatoria no son de naturaleza cíclica. A menudo se les denomina aperiódicos (no periódicos), ya que no exhiben un patrón regular de ascensos y descensos.

Una tendencia lineal representa una inclinación de los datos a aumentar o disminuir de manera constante a lo largo del tiempo (ver @fig-trend (a)). Por otro lado, las tendencias pueden seguir una curva, como ocurre con la tendencia exponencial mostrada en la @fig-trend (b). La @fig-trend (c) ilustra una serie temporal con una tendencia descendente, aunque más irregular en comparación con las tendencias observadas en las @fig-trend (a) y @fig-trend (b). Un patrón común en los conjuntos de datos es el comportamiento deambulante, como el mostrado en la @fig-trend (d), que parece moverse sin una dirección clara. Es decir, pueden presentarse varias tendencias, tanto cortas como largas, a menudo en direcciones opuestas.
:::

![Gráficos que muestran (a) una tendencia lineal, (b) una tendencia exponencial, (c) una tendencia irregular descendente y (d) un patrón de deambulación.](trends.png){#fig-trend fig-align="center"}

## La prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) {#sec-KPSS}

::: {style="text-align: justify"}
La prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS) es una prueba estadística utilizada para determinar la estacionariedad de una serie temporal. Evalúa la estacionariedad de una serie temporal mediante el examen de la varianza de los errores acumulados a lo largo del tiempo las hipótesis del tes KPSS son las siguientes:

-   La hipótesis nula $(H_0) :$ el modelo es estacionaria.

-   Hipótesis alternativa $(H_1)$ el modelo tiene una raíz unitaria y por tanto no es estacionaria.

El nivel de significancia, se denota por $\alpha$ y representa la probabilidad de rechazar $H_0$.

La hipótesis nula de la prueba KPSS se rechaza cuando el valor estadístico de la prueba es mayor que el valor crítico correspondiente a un nivel de significancia determinado como $\alpha = 0.01$ $(1 \%)$, $\alpha = 0.05 (5 \%)$, o $\alpha = 0.10 (10 \%)$. El valor más utilizado es $\alpha = 0.05$. Esto indica que hay suficiente evidencia estadística para concluir que la serie no es estacionaria y, por lo tanto, tiene una raíz unitaria.

Para calcular la estadística de prueba KPSS se utiliza la siguiente fórmula:

$$ KPSS = \dfrac{1}{ \hat{\sigma}^2 T } \sum_{t=1}^T \left(    \sum_{i = 1}^t  \hat{u_i}   \right)^2.$$
:::

## Evaluación de la precisión de los pronósticos

La evaluación de la precisión de los pronósticos es un paso fundamental para determinar la calidad de un modelo predictivo. Para obtener una cuantificación global de la eficacia de las predicciones, es esencial medir qué tan bien coinciden los valores pronosticados $(y_t)$ con los valores reales observados $(x_t)$ en cada instante de tiempo $t$. Algunas métricas que se han introducido, permiten resumir de manera concisa e informativa la precisión de las predicciones, proporcionando una visión clara sobre el rendimiento general del modelo. A continuación, se describen algunas de las métricas de rendimiento más utilizadas en este ámbito.

### MSE {#sec-MSE}

Mean Squared Error (MSE), o Error Cuadrático Medio, es una métrica que se utiliza para medir la precisión de un modelo de regresión. Se calcula como el promedio de los cuadrados de las diferencias entre los valores predichos $y_t$ y los valores observados $x_t$. La fórmula para calcular MSE es:

$$
MSE = \frac{1}{n} \sum_{t=1}^{n} (x_t - y_t)^2.
$$ {#eq-fmse}

### RMSE {#sec-RMSE}

::: {style="text-align: justify"}
El Error Cuadrático Medio (RMSE) es una medida de la magnitud de los errores entre los valores predichos $y_t$ y los valores observados $x_t$. Es ampliamente utilizado en la evaluación de la precisión de los modelos de predicción de series temporales debido a su capacidad para interpretar errores grandes y proporcionar una medida clara de la exactitud del modelo.

La fórmula para el cálculo de RMSE es la siguiente:

$$ RMSE = \sqrt{  \dfrac{\sum_{t=1}^{n} (y_t - x_t)^2}{n }}.
$$ {#eq-frmse}
:::
