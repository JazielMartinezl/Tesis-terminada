---
lang: es
---

# Nociones basicas de Probabilidad

::: {style="text-align: justify"}
Una de las herramientas esenciales en estadística es la probabilidad, es una rama que se dedica al estudio de fenómenos aleatorios y a la predicción de eventos en condiciones de incertidumbre. Surgida en el siglo XVII, inicialmente impulsada por problemas relacionados con los juegos de azar, la probabilidad ha evolucionado hasta convertirse en un recurso crucial en diversas áreas, como la física, la economía, la inteligencia artificial, y muchos otros campos que requieren el análisis de la incertidumbre y la variabilidad [@charles1997introduction].

Uno de los conceptos más importantes en probabilidad es el espacio muestral, que representa el conjunto de todos los resultados posibles de un experimento aleatorio. Un evento, por su parte, es un subconjunto de este espacio muestral, y la probabilidad de un evento mide cuán probable es que dicho evento ocurra [@ross2014introduction].
:::

::: {#def-EM style="text-align: justify"}
#### Espacio muestral

El espacio muestral, denotado por $\Omega$, es la colección completa de todos los posibles resultados de un experimento aleatorio en cuestión. Al elemento $w \in \Omega$ se denomina resultado o punto muestral.
:::

En ocasiones, no solo se analizan los resultados individuales de un espacio muestral $\Omega$, sino también distintas agrupaciones o combinaciones de dichos resultados, que son precisamente los **eventos**. En lugar de enfocarse en un resultado específico del espacio muestral, puede ser de mayor interés la ocurrencia de ciertos eventos relacionados con el experimento.

::: {#def-EP style="text-align: justify"}
#### Evento

Un evento $A$ es subconjunto de $\Omega$, es un conjunto de todos los posibles resultados del experimento. Un evento es **simple** si consiste en exactamente un resultado y **compuesto** si consiste en más de un resultado.
:::

::: {style="text-align: justify"}
Un evento puede ser un subconjunto que abarque todo el espacio muestral $\Omega$, o bien, un subconjunto de $\Omega$ denominado **conjunto vacío**,denotado por $\emptyset$, el cual no contiene ningún elemento. Se utilizarán las operaciones complemento, unión e intersección para crear eventos nuevos a partir de eventos dados.
:::

::: {#def-complemento style="text-align: justify"}
#### Complemento

El complemento de un evento $A$ respecto de $\Omega$ es el subconjunto de todos los elementos de $\Omega$ que no están en $A$, se denota por $A^\subset$.
:::

::: {#def-union style="text-align: justify"}
#### Unión

La unión de dos eventos $A$ y $B$, denotada por $A \cup B$, es el conjunto de todos los elementos que contiene todo los elementos pertenecientes a $A$, a $B$, o ambos.
:::

::: {#def-intersec style="text-align: justify"}
#### Intersección

La intersección de dos eventos $A$ y $B$, denotada por $A \cap B$, es el conjunto de todos los elementos que son comunes en ambos eventos $A$ y $B$.
:::

::: {#def-disjuntos style="text-align: justify"}
#### Eventos disjuntos

Dos eventos $A$ y $B$ son mutuamente excluyentes o disjuntos si no tienen elementos en común, es decir, si su intersección es el conjunto vacío y se denota por $A \cap B = \emptyset$
:::

## Probabilidad condicional

::: {style="text-align: justify"}
En ocasiones resulta relevante describir la probabilidad de que ocurra un evento dado que ya se conoce la ocurrencia de otro evento, en la teoría de probabilidad es lo que se conoce como la probabilidad condicional.

<!-- En el ámbito de las variables climáticas, en lugar de analizar la probabilidad general de que ocurra una tormenta en una región determinada, podría ser más útil estudiar dicha probabilidad bajo ciertas condiciones, como cuando la temperatura supera los 30 grados y la humedad relativa está por encima del $70\%$. Este enfoque permite entender mejor cómo se comportan ciertos fenómenos climáticos en escenarios específicos, lo que resulta esencial para la planificación y predicción meteorológica. -->
:::

::: {#def-pcondicional style="text-align: justify"}
#### Probabilidad condicional

Sean $A$ y $B$ dos eventos de $\mathfrak{F}$ de un espacio de probabilidad $(\Omega, \mathfrak{F}, P)$. La probabilidad de $A$ dado $B$, que se denota por $P(A/B)$, y se define como $$
P(A/B) = \dfrac{P(A \cap B ) }{P(B) } , \  \ \ \ \ \text{si} \ \ P(B)>0.
$$ {#eq-pcondicional}
:::

::: {style="text-align: justify"}
A continuación, se presentan las propiedades fundamentales de la probabilidad condicional:

Sea $(\Omega, \mathcal{F}, P)$ un espacio de probabilidad, y sea $A \in \mathcal{F}$ tal que $P(A) > 0$. Entonces:

1.  $P(A \mid A) = 1$.

2.  Si $A \cap B = \emptyset$, entonces $P(B \mid A) = 0$.

3.  $P(B \cap C \mid A) = P(B \mid A \cap C) P(C \mid A)$ si $P(A \cap C) > 0$.

4.  Si $A_1, A_2, \dots, A_n \in \mathcal{F}$ con $P(A_1 \cap A_2 \cap \dots \cap A_{n-1}) > 0$ entonces $$ P(A_1 \cap A_2 \cap \dots \cap A_n) = P(A_1) P(A_2 | A_1) P(A_3 \mid A_1 \cap A_2) \cdots P(A_n \mid A_1 \cap A_2 \cap \dots \cap A_{n-1}).$$
:::

::: {style="text-align: justify"}
En el siguiente ejemplo, se muestra cómo calcular la probabilidad condicional para dos eventos.
:::

::: {.callout-caution collapse="true" style="text-align: justify" icon="false"}
#### Ejemplo de lanzamiento simultáneo de dos dados

Se lanzan dos dados juntos una vez. Se busca calcular la probabilidad de que al menos uno de los resultados sea 6, dado que los resultados obtenidos son diferentes.

Definamos los siguientes eventos:

$A$: El evento "los resultados son diferentes".

$B$: El evento "al menos uno de los resultados es 6".

Formalmente, estos eventos se pueden describir de la siguiente manera : $$
A = \{(a, b) : a, b \in \{1, 2, \dots, 6\}, a \neq b \}
$$ y $$
B = \{(a, 6) : a \in \{1, 2, \dots, 6\}\} \cup \{(6, b) : b \in \{1, 2, \dots, 6\}\}.
$$

Para calcular la probabilidad condicionada $P(B | A)$, se utiliza la fórmula de la probabilidad condicionada:

$$
P(B | A) = \frac{P(A \cap B)}{P(A)}.
$$

Primero, se calcula el número de elementos en $A$. Como hay 6 posibles valores para cada dado, pero los resultados no deben ser iguales, el número total de resultados posibles en $A$ es:

$$
|A| = 6 \times 6 - 6 = 30.
$$

Luego,se obtiene el número de elementos en $A \cap B$, es decir, aquellos pares en los que al menos uno de los dados es un 6 y los resultados son diferentes. Hay 5 combinaciones posibles donde el primer dado no es 6 y el segundo es 6, y otras 5 donde el primer dado es 6 y el segundo no lo es. Por lo tanto, el número de elementos en $A \cap B$ es:

$$
|A \cap B| = 5 + 5 = 10.
$$

Finalmente, la probabilidad condicionada es:

$$
P(B | A) = \frac{10}{30} = \frac{1}{3}.
$$
:::

::: {style="text-align: justify"}
Si bien, la probabilidad condicional ajusta la probabilidad de un evento en función de información adicional, también proporciona una base esencial para entender la independencia de eventos. Este concepto se fundamenta en la idea de que la probabilidad de un evento no se ve afectada por la ocurrencia de otro, lo cual puede identificarse a través de la probabilidad condicional. Así, además de modificar las probabilidades en función de nueva información, la probabilidad condicional permite clarificar cuándo dos eventos son realmente independientes.
:::

## Independencia de eventos

::: {#def-indeeventos style="text-align: justify"}
#### Independecia de eventos

Se dice que dos eventos $A$ y $B$ son independientes si y solo si se cumple alguna de las siguientes condiciones:

$$
P(A|B)= P(A)
$$ {#eq-indeeventos1}

$$
P(B|A)= P(B)
$$ {#eq-indeeventos2}

$$
P(A \cap B) = P(A) P(B)
$$ {#eq-indeeventos3}
:::

::: {style="text-align: justify"}
Por el contrario, si la condiciones ([-@eq-indeeventos1]), ([-@eq-indeeventos2]), ([-@eq-indeeventos3]) no se cumple, se dice que los eventos son dependientes.

La condición $P(B|A) = P(B)$ significa que el evento $B$ es independiente del evento $A$, lo que representa que la probabilidad de que ocurra $B$ no cambia aunque se sepa que ha ocurrido $A$. Esta independencia implica que el conocimiento de uno de los eventos no proporciona información sobre el otro.

La condición en ([-@eq-indeeventos2]) implica que $P(A|B) = P(A)$, y viceversa.
:::

::: {#def-indevarios style="text-align: justify"}
#### Independencia de varios eventos

Para un espacio de probabilidad dado $(\Omega, \mathfrak{F}, P)$, sean $A_1,A_2, \cdot , A_n$ Los eventos $A_1,A_2, \cdot , A_n$ de $\mathfrak{F}$. Se definen como independientes si y solo si $$P\left(\bigcap\limits_{i=1}^n A_i\right)=\prod\limits_{i=1}^n P(A_i).
 $$
:::

::: {#def-sigmaa style="text-align: justify"}
#### sigma-álgebra

Dada una colección $\mathcal{F}$ de subconjuntos de $\Omega$ se llama una $\sigma-\text{álgebra}$ sobre $\Omega$ si:

i)  $\Omega \in \mathcal{F}$.
ii) Si $A \in \mathcal{F}$, entonces $A^c \in \mathcal{F}$.
iii) Si $A_1, A_2, \dots \in \mathcal{F}$, entonces $\bigcup_{i=1}^{\infty} A_i \in \mathcal{F}$.
:::

Los elementos de $\mathcal{F}$ se llaman eventos.

:::: {#exm-ELmonedas style="text-align: justify"}
::: {.callout-caution collapse="true" icon="false"}
#### Lanzamiento de dos monedas juntas

Consideremos un experimento aleatorio que consiste en lanzar dos monedas juntas. El espacio muestral es $\Omega = \{ HH, HT, TH, TT \}$, donde:

\begin{itemize}
  \item $\{HH\}$ representa obtener cara en ambas monedas.

  \item $\{HT\}$ representa obtener cara en la primera moneda y cruz en la segunda.

  \item $\{TH\}$ representa obtener cruz en la primera moneda y cara en la segunda.

  \item $(TT)$ representa obtener cruz en ambas monedas.

\end{itemize}

Sea $\mathcal{F} = \{\emptyset, \{HH, HT\}, \{TH, TT\}, \Omega\}$, que es una colección de subconjuntos de $(\Omega)$. Se quiere demostrar que $(\mathcal{F})$ es una $\sigma-\text{álgebra}$.

Para ello, verificamos las tres condiciones:

$\Omega \in \mathcal{F}$, lo cual es cierto ya que $\Omega = \{HH, HT, TH, TT\}$ está incluido en $\mathcal{F}$.

Si $A \in \mathcal{F}$, entonces $A^c$ también debe estar en $\mathcal{F}$. Por ejemplo, el complemento de $\{HH, HT\}$ es $\{TH, TT\}$, que también pertenece a $\mathcal{F}$. De manera similar, el complemento de $\{TH, TT\}$ es $\{HH, HT\}$, lo que también está en $\mathcal{F}$, y el complemento de $\emptyset$ es $\Omega$, que también está en $\mathcal{F}$.

La unión infinita (o finita) de conjuntos en $\mathcal{F}$ pertenece a $\mathcal{F}$. Por ejemplo, $\{HH, HT\} \cup \{TH, TT\} = \Omega$, que está en $\mathcal{F}$.

De manera similar, $\emptyset \cup \{HH, HT\} = \{HH, HT\}$, que también está en $\mathcal{F}$.

Por lo tanto, $\mathcal{F}$ es una $\sigma-\text{álgebra}$ sobre $\Omega$.
:::
::::

::: {#def-medP style="text-align: justify"}
#### Medida de probabilidad

Una función $P$, definida sobre una $\sigma-\text{álgebra}$ $\mathfrak{F}$ y con valores en el intervalo $[0, 1]$ es una medida de probabilidad si satisface,

1.  $P(\Omega) = 1$ y

2.  Es $\sigma-\text{aditiva}$.
:::

::: {style="text-align: justify"}
Esto significa que para cualquier $A_1,A_2, \dots , A_n \in \mathfrak{F}$ sean mutuamente excluyentes, es decir, $A_i ∩ A_j = \emptyset$ para $i \neq j$ se cumple que

$$
\displaystyle P \left( \bigcup_{i=1}^{\infty} A_i \right) = \displaystyle   \sum_{i=1}^{\infty} P (A_i)
$$
:::

::: {#def-espacioP style="text-align: justify"}
#### Espacio de Probabilidad

Un espacio de probabilidad es una terna $(\Omega, \mathfrak{F}, P)$, en donde $\Omega$ es un conjunto arbitrario,$\mathfrak{F}$ es una colección subconjunto de $\Omega$ asumida como una $\sigma-\text{álgebra}$ de eventos, y $P$ es una función de probabilidad con dominio $\mathfrak{F}$, una variable aleatoria $X$.

A la pareja $(\Omega, \mathfrak{F})$ se llama espacio medible.
:::

:::: {#exm-ELDADO style="text-align: justify"}
::: {.callout-caution collapse="true" icon="false"}
#### Ejemplo de lanzamiento de un dado

Consideremos lanzar un dado de seis caras y observar el número que aparece. El espacio muestral $\Omega$ incluye todos los posibles resultados del lanzamiento de un dado

$$\Omega = \{1,2,3,4,5,6 \}$$ La $\sigma-\text{álgebra}$ es el conjunto de todos los eventos que podemos observar, lo que incluye cualquier subconjunto del espacio muestral $\Omega$. En este caso, $\mathfrak{F}$ incluiría:

$$
\mathfrak{F} = \{ \{\emptyset\},\{1\},\{2\},\{1,2\},\dots,\{1,2,3\},\dots,\{1,2,3,4,5\},\Omega\}
$$

$\mathfrak{F}$ contiene todos los subconjuntos posibles de $\Omega$, como eventos de un solo número $(\{1,2\})$, combinaciones de varios números $(\{1,2,3,\dots\})$, o el evento completo $\Omega$ , que representa cualquier resultado.

La medida de probabilidad $P$ asigna una probabilidad a cada subconjunto de $\mathfrak{F}$. Como el dado es justo, cada número tiene la misma probabilidad de ocurrir. Entonces, para un evento elemental $\{i\}$, la probabilidad se asigna de la siguiente manera: $$
P(\{i\})= \dfrac{1}{6} \ \ \text{para todo} \ \  i \in \Omega.
$$ {#eq-ejemploEP}

Además,la probabilidad de obtener un número par, es decir, el evento $(\{2,4,6\})$,se calcula sumando las probabilidades individuales de cada uno de estos resultados. Como en ([-@eq-ejemploEP]) cada número tiene la misma probabilidad de ocurrir, por lo que, $$P({2,4,6}) = P(\{2\}) + P(\{4\}) + P(\{6\}) = \frac{1}{6} + \frac{1}{6} +\frac{1}{6} = \frac{3}{6} = \frac{1}{2} $$

Por lo tanto, el espacio de probabilidad para el lanzamiento de un dado de seis caras es: $( \{1,2,3,4,5,6 \},\mathfrak{F},P)$
:::
::::

<!-- ::: {style="text-align: justify"} -->

<!-- Bajo la necesidad de cuantificar resultados de experimentos aleatorios para poder trabajar de manera más efectiva con estos resultados y realizar cálculos como la probabilidad de un evento o el valor esperado de un experimento, es útil traducir estos eventos a números reales. Aquí es donde entran en juego las variables aleatorias. -->

<!-- ::: -->

## Variable aleatoria {#sec-VA}

:::: {style="text-align: justify"}
Una variable aleatoria permite asignar valores numéricos a los resultados de un experimento aleatorio, mapeando el espacio de resultados a los números reales. Su definición garantiza que la probabilidad asociada a cualquier subconjunto de resultados posibles esté bien definida. A continuación, se formaliza esta idea dentro de un espacio de probabilidad.

<!-- ::: {style="text-align: justify"} -->

<!-- Para un espacio de probabilidad $(\Omega, \mathfrak{F}, P)$, donde $\Omega$ es un espacio muestral, $\mathfrak{F}$ es una colección subconjunto de $\Omega$ asumida como una sigma álgebra de eventos, y $P$ es una función de probabilidad con dominio $\mathfrak{F}$, una variable aleatoria $X$ es cualquier función de la forma: $$ X : \Omega \rightarrow \mathbb R $$ $$ \omega \in \Omega \mapsto X(\omega)$$ Las variables aleatorias pueden ser discretas o continuas. Las variables aleatorias discreta son aquellas que pueden tomar un número finito o numerable de valores distintos. Por ejemplo, el número de caras al lanzar tres monedas (puede ser 0, 1, 2 o 3). Las Variables aleatorias discretas son aquellas que pueden tomar un número finito o contable de valores distintos. Por ejemplo, el número de caras al lanzar tres monedas (puede ser 0, 1, 2 o 3). -->

<!-- ::: -->

::: {#def-VA style="text-align: justify"}
### Variable aleatoria

Para un espacio de probabilidad un $(\Omega, \mathcal{F}, P)$. Una **variable aleatoria real** es una función $X: \Omega \to \mathbb{R}$ tal que, para todo $A \in \mathcal{F}$, se cumple que $X^{-1}(A) \in \mathcal{F}$, donde $\mathcal{F}$ es una $\sigma$-álgebra sobre $\mathbb{R}$.
:::

Las variables aleatorias pueden ser discretas o continuas. Las variables aleatorias discreta son aquellas que pueden tomar un número finito o numerable de valores distintos. Por ejemplo, el número de caras al lanzar tres monedas (puede ser $0, 1, 2 ó 3$). Por otro lado, las variables aleatorias continuas toman cualquier valor dentro de un intervalo de la recta real $ \mathbb{R}$. Un ejemplo de variable aleatoria continua es la temperatura de una ciudad, medida en grados Celsius.

La función de distribución describe la probabilidad de que una variable aleatoria real tome un valor menor o igual a un cierto número. A continuación, se presenta la función de distribución para una variable aleatoria $X$, definida sobre un espacio de probabilidad.
::::

::: {style="text-align: justify"}
### Función de distribución

Sea $X$ una variable aleatoria real definida sobre el espacio de probabilidad $(\Omega, \mathfrak{F}, P)$. La función $F_x(\cdot)$ definida sobre $\mathbb{R}$ a través de $$
F_X(x) := P_X((-\infty, x]) = P(X \leq x)
$$ {#eq-cdf}
:::

:::: {#exm-LDADO style="text-align: justify"}
::: {.callout-caution collapse="true" icon="false"}
#### **Lanzamiento de un dado**

Sea $X$ es una variable aleatoria discreta que representa el resultado de lanzar un dado justo de 6 caras. El conjunto de valores posibles es: $$ D =\{ 1,2,3,4,5,6 \}.$$

La función de densidad de probabilidad $f_X (x)$ se define como: $$ f_X (x) = 
    \left\{ \begin{array}{lcc} \frac{1}{6} & \text{si } \ \ \ x \in D \\ \\ 0 & \text{en otro caso}  \end{array} \right . $$

Esto significa que cada cara del dado tiene una probabilidad de $\frac{1}{6}$, y cualquier valor fuera del conjunto $D$ tiene probabilidad $0$.

La función de distribución acumulada $F_X (x)$ se determina sumando las probabilidades de todos los valores menores o iguales a $x$. Por lo tanto, $$ F_X (x) = 
    \left\{ \begin{array}{lcc} 0, & \text{si } \ \ \ x < 1 \\ 
    \frac{1}{6}, & \text{si } \ \ \ 1  \leq x <2 \\ \\ 
    \frac{1}{6}, & \text{si } \ \ \ 2 \leq x < 3 \\ \\ 
     \frac{1}{6}, & \text{si } \ \ \ 3 \leq x <4 \\  \\ 
     \frac{1}{6}, & \text{si } \ \ \ 4 \leq x <5 \\  \\ 
     \frac{1}{6}, & \text{si } \ \ \  x \geq 6 \\ \\ 
     \end{array} \right . $$
:::
::::

<!-- Supongamos que X es una variable aleatoria real definida sobre el espacio de $(\Omega, \mathfrak{F}, P)$  y sea g una función tal que Y = g(X) es una variable aleatoria -->

<!-- definida sobre (Ù, 3 , P). Nos interesa determinar (si es posible) la -->

<!-- función de distribución de la variable aleatoria Y en términos de la -->

<!-- función de distribución de la variable aleatoria X. -->

### Variable aleatoria discreta {#sec-VAD}

Una variable aleatoria $X$ se dice que es discreta si su conjunto de valores posibles es un conjunto numerable.

#### Funcion de distribución de una variable aleatoria discreta

::: {#def-fdd style="text-align: justify"}
Para una variable aleatoria $X$ la función de densidad, se denota por $f_X(\cdot)$ y esta definida sobre el conjunto de valores posibles $D =\{x_1,x_2,\dots,x_n\}$ de la siguiente manera,

$$
f_X(x)= \begin{cases}P(X=x) & \text{ si } x \in D ,\\ 
          0 & \text{ cualquier otro caso. }\end{cases} 
$$

Si $X$ es una variable aleatoria , la función $f_X (\cdot)$ es la derivada de $F_X$, definida en el conjunto de los números reales, si cumple las siguientes condiciones:

1.  La función de distribución $F_X()$ es creciente, es decir, si  $x < y  $ entonces se cumple que $F_X (x) \leq F_X (y).$

2.  La función $F_X (\cdot)$ es continua por la derecha, es decir, $F_X(x^+) = \lim_{h \to \ 0^+} F_X ( x + h) = F_X ( x )  \ \ \text{para todo x en }  \ \ \mathbb{R}.$

3.  La función de distribución tiene límites bien definidos en los extremos de su dominio: $F_X(x^+) = \lim_{h \to \ \infty} F_X ( x ) = 1 \ \ \text{y} \  \  F_X(x) = \lim_{h \to \ -\infty} F_X ( x ) = 0.$
:::

::: {#def-vac style="text-align: justify"}
#### Variable aleatoria continua

La variable aleatoria real $X$, se dice que es absolutamente continua si y solo si existe una función real no negativa e integrable $f_X(\cdot)$ tal que, para todo $x \in \mathbb{R}$, se cumple que: $$
F_X(x) = \int_{-\infty}^{x} f_X(u) \, du.
$$ {#eq-densidadcon}

La función $f_X(\cdot)$ en ([-@eq-densidadcon]) se denomina función de densidad de probabilidad, o simplemente, función de densidad de la variable aleatoria continua $X$.
:::

#### Función de distribución de una variable aleatoria continua.

::: {style="text-align: justify"}
Sea $X$ una variable aleatoria continua con función de densidad $f_X ()$, se define la función de distribución, $F_X ()$, como:

$$
F_X (x) =  \int_{-\infty}^{x} f_X (u) \ \ du.
$$
:::

::: {style="text-align: justify"}
Un vector aleatorio es una generalización del concepto de variable aleatoria a múltiples dimensiones.
:::

::: {#def-vectorale style="text-align: justify"}
### Vector aleatorio

Sean $X_1,X_2,\dots ,X_n$ variables aleatorias reales definidas sobre el mismo espacio de probabilidad $(\Omega, \mathfrak{F}, P)$. Un vector aleatorio es una función definida para cada $\omega \in \Omega$, $$
X(\omega) := (X_1(\omega),X_2(\omega),\dots,X_n(\omega))
$$ {#eq-vectora}
:::

:::: {#exm-EVA style="text-align: justify"}
::: {.callout-caution collapse="true" icon="false"}
#### Ejemplo de un vector aleatorio

Sea $X$ un vector aleatorio de dimensión $n = 4$, donde cada componente sigue una distribución uniforme entre 0 y 1. Es decir,

$$ X =\begin{bmatrix}
X_1 \\
X_2 \\
X_3 \\
X_4
\end{bmatrix}, \ \ X_i \backsim U(0,1) \ \ \ \text{para} \ \ i=1,2,3,4.$$

Al generar este vector en R se obtiene,

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
set.seed(123)
vector_aleatorio <- runif(4)
print(vector_aleatorio)
# [1] 0.2875775 0.7883051 0.4089769 0.8830174
```

Por lo tanto, 
$$
X =\begin{bmatrix}
0.2875775 \\
0.7883051 \\
0.4089769 \\
0.8830174
\end{bmatrix}
$$
:::
::::

::: {style="text-align: justify"}
En el caso de vector aleatorio $X = (X_1,X_2, \dots, X_n)$, el valor esperado se define como un vector de expectativas $E[X] = (E[X_1],E[X_2], \dots, E[X_n]).$ Por otro lado, la varianza y la covarianza de $X$ se describen mediante la matriz de covarianza, $\text{Cov}(X),$ la cual es una matriz simétrica que captura la variabilidad conjunta entre las componentes del vector.

Este enfoque permite analizar y modelar estructuras multivariadas en diversos contextos probabilísticos y estadísticos [@casella2002statistical].
:::


::: {#def-VA style="text-align: justify"}
### Distribución de un vector aleatorio

Sea $X$ un vector aleatorio. La medidad probabilidad de un vector aleatorio se define de la siguiente manera:
 
 $$ P_X(B) := P((X_1,\dots, X_n) \in B )$$
donde $B \subseteq \mathbb{R^n}$ y se conoce como distribución de un vector aleatorio $X$.
:::

::: {#def-VA style="text-align: justify"}
### Función de distribución conjunta

Sea $X$ un vector aleatorio. La función de distribución conjunta de un vector aleatorio $X$ esta dada por :
 
 $$F_X(x_1,\dots, x_n) = P(X_1 \leq x_1,X_2 \leq x_2, \dots, X_n \leq x_n).$$
esto es para todo $(x_1,x_2,\dots, x_n) \ in \mathbb{R^n}$, en la literatura es conocida como la función de distribución conjunta de las variables aleatorias $X_1,\dots,X_n$, o simplemente como la función de distribución del vector aleatorio $X$.
 
:::