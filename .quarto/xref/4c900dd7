{"entries":[{"caption":"Ejemplo de una capa de RNA recurrente totalmente conectada.","key":"fig-Recurrente1","order":{"number":6,"section":[6,8,2,0,0,0,0]}},{"caption":"Operación maxpooling, donde el tamaño de la región de agrupación es 2 \\times 2 (que se muestra en color naranja, en el mapa de características de entrada) y la zancada es 1 y el correspondiente calculado valor en el mapa de características de salida (que se muestra en verde)","key":"fig-maxPooling","order":{"number":10,"section":[6,8,4,5,1,0,0]}},{"caption":"6.7 Función de Pérdida","key":"sec-función-de-perdida","order":{"number":3,"section":[6,7,0,0,0,0,0]}},{"caption":"Softmax","key":"fig-fact-4","order":{"number":4},"parent":"fig-fact"},{"caption":"6.6 Optimizador Adam","key":"sec-Adam","order":{"number":2,"section":[6,6,0,0,0,0,0]}},{"caption":"Funciones de activación.","key":"fig-fact","order":{"number":5,"section":[6,5,5,0,0,0,0]}},{"caption":"Tangente hiperbólica","key":"fig-fact-3","order":{"number":3},"parent":"fig-fact"},{"caption":"Arquitectura de una RNA.","key":"fig-RNA","order":{"number":3,"section":[6,3,0,0,0,0,0]}},{"caption":"Imagen de una neurona biologica.","key":"fig-neu","order":{"number":1,"section":[6,1,0,0,0,0,0]}},{"caption":"Ejemplo de una conexión entre capas de una RNA recurrente simple.","key":"fig-Recurrente2","order":{"number":7,"section":[6,8,2,0,0,0,0]}},{"caption":"Celda de estado","key":"fig-celda","order":{"number":8,"section":[6,8,3,0,0,0,0]}},{"caption":"Aplananimeto después de una capa de Agrupación en CNN.","key":"fig-flatten","order":{"number":11,"section":[6,8,4,5,2,0,0]}},{"caption":"Gráfico de errres en el proceso de entrenamiento de una RNA","key":"fig-sobren","order":{"number":1,"section":[8,0,0,0,0,0,0]}},{"caption":"Modelo de una neurona artificial.","key":"fig-elementos","order":{"number":4,"section":[6,4,0,0,0,0,0]}},{"caption":"8 Sobreentrenamiento de una RNA","key":"sec-sobreentrenamiento","order":{"number":1,"section":[8,0,0,0,0,0,0]}},{"caption":"6.8.4.5.2 Aplanamiento en una red neuronal Convolucional (CNN)","key":"sec-flatten","order":{"number":6,"section":[6,8,4,5,2,0,0]}},{"caption":"Esquema de Red Neuronal Convolucional","key":"fig-entrenamiento_cnn","order":{"number":9,"section":[6,8,4,1,0,0,0]}},{"caption":"6.8.4.3 Kernel","key":"sec-kernel","order":{"number":4,"section":[6,8,4,3,0,0,0]}},{"caption":"6.8.4.5 Capas de Agrupación (Pooling layer)","key":"sec-pooling","order":{"number":5,"section":[6,8,4,5,0,0,0]}},{"caption":"ReLu","key":"fig-fact-6","order":{"number":6},"parent":"fig-fact"},{"caption":"Estructura básica de una neurona biológica.","key":"fig-neuronas","order":{"number":2,"section":[6,1,0,0,0,0,0]}},{"caption":"Sigmoide","key":"fig-fact-2","order":{"number":2},"parent":"fig-fact"},{"caption":"6.5.1 ReLU (Rectified Lineal Unit)","key":"sec-Relu","order":{"number":1,"section":[6,5,1,0,0,0,0]}},{"caption":"ReLu con fugas","key":"fig-fact-5","order":{"number":5},"parent":"fig-fact"},{"caption":"ReLu","key":"fig-fact-1","order":{"number":1},"parent":"fig-fact"}],"headings":["inspiración-biológica-de-las-redes-neuronales-artificiales","modelo-de-red-neuronal-artificial","arquitectura-de-una-red-neuronal-artificial","elementos-de-una-red-natural-artificial","funciones-de-activación","sec-Relu","sigmoid-sigmoide","tangente-hiperbólica-tangent-hyperbolic","softmax","relu-con-fugas","sec-Adam","sec-función-de-perdida","algunos-tipos-de-red-neuronal-artificial","perceptrón-simple","red-neuronal-recurrente","red-neuronal-lstm","red-neuronal-convolucional-cnn","capas-de-una-red-neuronal-convolucional-cnn","capa-convolucional","sec-kernel","proceso-de-convolución","sec-pooling","máxima-agrupacion-max-pooling","sec-flatten","entrenamiento-de-una-rna","sec-sobreentrenamiento"],"options":{"chapters":true}}